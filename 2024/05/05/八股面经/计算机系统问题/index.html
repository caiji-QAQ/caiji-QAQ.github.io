<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="caijiQAQ">
    
    <title>
        
            计算机操作系统问题 |
        
        学习笔记
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"caiji-qaq.github.io","root":"/","language":"en"}
    KEEP.theme_config = {"toc":{"enable":false,"number":false,"expand_all":false,"init_open":false},"style":{"primary_color":"#0066cc","logo":"/images/logo.svg","favicon":"/images/logo.svg","avatar":"/images/avatar.svg","font_size":null,"font_family":null,"hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving.","font_color":null,"hitokoto":false},"scroll":{"progress_bar":false,"percent":false}},"local_search":{"enable":false,"preload":false},"code_copy":{},"code_block":{"tools":{"enable":false,"style":"default"},"highlight_theme":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":true,"custom_label_list":["Trainee","Engineer","Architect"]},"word_count":{"enable":false,"wordcount":false,"min2read":false},"img_align":"left","copyright_info":false},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/logo.svg">
                </a>
            
            <a class="logo-title" href="/">
               学习笔记
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                    
                </ul>
            </div>
            <div class="mobile">
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">计算机操作系统问题</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/avatar.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">caijiQAQ</span>
                            
                                <span class="author-label">Lv3</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2024-05-05 00:00:00</span>
        <span class="mobile">2024-05-05 00:00</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2024-10-17 21:55:42</span>
    </span>
    
    
    

    
    
    
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <h1 id="C-x2F-C-问题"><a href="#C-x2F-C-问题" class="headerlink" title="C&#x2F;C++问题"></a>C&#x2F;C++问题</h1><p>1.程序从编译到运行全过程：</p>
<ul>
<li>预处理(.i)：预处理后文件，预处理器执行宏替换、条件编译以及包含指定的文件。<ul>
<li>宏替换：预处理器会将代码中的宏名替换为其定义的内容</li>
<li>头文件包含：预处理器会将头文件的内容插入到包含它们的源文件</li>
<li>条件编译：如 #if、#ifdef、#ifndef、#else、#elif 和 #endif</li>
<li>处理预定义的宏：如__FILE__、__LINE__、__DATE__</li>
</ul>
</li>
<li>编译(.s)。编译器会将程序源代码编译成汇编代码。</li>
<li>汇编(.o)。汇编器会将汇编代码文件翻译成为二进制的机器码。</li>
<li>链接(.out)。链接器会将一个个目标文件和库文件链接在一起，成为一个完整的可执行程序。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240622161115.png"></p>
<h1 id="操作系统"><a href="#操作系统" class="headerlink" title="操作系统"></a>操作系统</h1><p>好文：<a class="link"   target="_blank" rel="noopener" href="https://hansimov.gitbook.io/csapp/part2/ch08-exceptional-control-flow/8.1-exceptions" >https://hansimov.gitbook.io/csapp/part2/ch08-exceptional-control-flow/8.1-exceptions<i class="fas fa-external-link-alt"></i></a></p>
<h2 id="进程与线程"><a href="#进程与线程" class="headerlink" title="进程与线程"></a>进程与线程</h2><h3 id="1-进程与线程的区别"><a href="#1-进程与线程的区别" class="headerlink" title="1. 进程与线程的区别"></a>1. 进程与线程的区别</h3><p><strong>进程</strong>：</p>
<ul>
<li>系统进行<strong>资源分配的</strong>基本单位。具体分配哪些资源：地址空间、处理器时间（CPU时间）、文件描述符、输入&#x2F;输出设备、进程控制块等。</li>
<li>进程是线程的容器。程序是指令、数据及其组织形式的描述，进程是程序的实体。</li>
</ul>
<p><strong>线程</strong>：</p>
<ul>
<li>操作系统<strong>最小的运算调度单位</strong></li>
<li>线程包含在进程中，是进程实际执行任务的单位</li>
<li>在一些操作系统中，线程也被称为轻量化进程</li>
<li><strong>每一个线程只能占用多核处理器中的一个核</strong></li>
</ul>
<p><strong>线程和进程的区别</strong></p>
<ul>
<li>线程是进程的一份，使进程内实际执行单位，而进程则是操作系统分配资源的基本单位。</li>
<li>每个进程都有独立的<strong>地址空间和系统资源</strong>，而线程共享<strong>同一进程的地址空间和系统资源</strong>。虽然线程共享进程的地址空间，但每个线程都有<strong>自己独立的栈空间</strong>。线程的栈用于存储函数调用的局部变量、返回地址等。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240814105658.png"></li>
<li>线程之间的切换比进程之间的切换更快，因为线程共享相同的上下文和资源。</li>
<li>线程间通信更加方便，可以直接读写共享内存，而进程间通信需要通过特定的机制（<strong>如管道、消息队列等</strong>）。</li>
<li>进程的创建和销毁比线程的开销更大。</li>
<li>进程是相对独立的，一个进程的崩溃不会影响其他进程，而线程是相互依赖的，一个线程的崩溃会导致整个进程的崩溃。</li>
</ul>
<h3 id="2-什么时候用进程，什么时候用线程？"><a href="#2-什么时候用进程，什么时候用线程？" class="headerlink" title="2.什么时候用进程，什么时候用线程？"></a>2.什么时候用进程，什么时候用线程？</h3><h4 id="使用进程的情况："><a href="#使用进程的情况：" class="headerlink" title="使用进程的情况："></a>使用进程的情况：</h4><ul>
<li>1.需要独立的地址空间和系统资源。不同任务之间的数据隔离较为重要</li>
<li>2.需要更高的安全性和稳定性。一个任务的崩溃不会影响到其他任务的正常运行</li>
<li>3.&#x3D;&#x3D;并行计算要求&#x3D;&#x3D;：如果任务需要<strong>充分利用多核处理器的计算能力</strong>，可以通过多个独立的进程并行执行来提高计算效率。（一个线程的错误也许会影响到整个线程，比如内存泄漏，进程的资源分配：由于进程的资源是独立分配的，因此可以为不同的计算任务设置不同的资源配额或权限。同时这种可以保证进程的资源可以并行，如果一个进程下的进程同时在不同的核上进行计算可能会需要通信以及资源的抢占，这样就会影响计算的速度）</li>
</ul>
<h4 id="使用线程的情况："><a href="#使用线程的情况：" class="headerlink" title="使用线程的情况："></a>使用线程的情况：</h4><ul>
<li>1.共享数据和资源：数据同步通信较为频繁就可以使用线程</li>
<li>2.轻量化：如果任务比较轻量级，且并行执行可以提高效率，使用线程可以进行更快速的切换和调度，减少开销。</li>
<li>3.实时性：线程可以更快地响应事件和处理任务。</li>
</ul>
<p><em><strong>什么时候用多进程什么时候用多线程？</strong></em><br>多线程的三个名词：<strong>串行、并行、并发</strong>。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240905150222.png"><br>用多线程还是多进程，和很多方面有关系：</p>
<p>1：是否需要频繁创建销毁<br>需要频繁创建销毁的优先用<strong>线程</strong>。这种原则最常见的应用就是Web服务器了，来一个连接建立一个线程，断了就销毁线程，要是用进程，创建和销毁的代价是很难承受的</p>
<p>2：程序执行任务是强相关还是弱相关<br>强相关的处理用线程，弱相关的处理用进程。<br>其实也就是任务之间的耦合性，举个例子：要计算一天5只股票的成交单总计数，假设代码设计为一个int tradesum，每只票使用tradesum+&#x3D; num这种方式，那么就是强相关，使用线程合理；如果是每只票都维护一个临时的TempSum，最后另外一个地方把这5个tempsum相加，那么就是弱相关，使用进程合理。</p>
<p>3：程序是否需要数据共享<br>需要数据共享优先使用线程。<br>多线程共享同一进程的内存空间，这意味着线程之间可以<strong>直接访问</strong>相同的变量和数据结构，无需特别的通信机制即可实现数据共享，这对于需要频繁数据交换的场景非常有利。</p>
<p>4：<strong>程序是IO密集型还是CPU密集型</strong><br>多进程能够更好地利用多核CPU的<strong>并行计算</strong>能力。由于每个进程有自己的独立内存空间，操作系统可以将不同的进程分配到不同的CPU核心上同时执行，实现真正的并行处理，这对于计算密集型任务尤其重要。<br>I&#x2F;O密集型任务的特点是程序在执行过程中需要花费大量时间等待输入输出操作完成，如文件读写、网络通信等。在这段时间里，CPU实际上是空闲的。<strong>多线程允许在某个线程等待I&#x2F;O操作的同时，其他线程可以继续执行</strong>，提高了CPU的利用率。</p>
<p>5：是否多分布<br>多机器分布优先进程，多核分布优先线程</p>
<h4 id="线程与协程的区别"><a href="#线程与协程的区别" class="headerlink" title="线程与协程的区别"></a>线程与协程的区别</h4><p>协程可以通过在<strong>一个栈帧</strong>中执行多次暂停和恢复操作，而不需要像线程那样频繁创建新的栈帧，从而实现更轻量的调度。与线程相比，协程的上下文切换<strong>不需要操作系统的参与</strong>，通常是由程序自行管理的。这意味着协程的切换不涉及操作系统级别的栈切换、寄存器保存等操作，仅仅是恢复和保存一些局部状态。</p>
<p>线程与协程对比：<br><strong>线程：</strong></p>
<ul>
<li>每个线程拥有独立的栈空间，每次线程上下文切换时都需要操作系统保存和恢复线程的栈指针、寄存器等。</li>
<li>线程上下文切换是较为昂贵的操作，因为它需要进入内核态、调度线程、切换栈指针、恢复线程上下文。</li>
</ul>
<p><strong>协程：</strong></p>
<ul>
<li>协程的执行通常依赖于<strong>同一个线程的栈空间</strong>。多个协程共享同一个线程的栈，并在单个栈帧中通过暂停和恢复来模拟多任务。</li>
<li>协程的上下文切换在用户态完成，不需要进入内核态，切换开销仅为保存当前执行位置（如程序计数器）和局部状态。</li>
</ul>
<h3 id="3-一个线程占用多大内存"><a href="#3-一个线程占用多大内存" class="headerlink" title="3.一个线程占用多大内存"></a>3.一个线程占用多大内存</h3><p>一个线程在Linux系统中大约占用8MB的内存。这是因为Linux系统中的线程栈是通过<strong>缺页异常</strong>来进行内存分配的，不是所有的栈空间都会被实际分配内存。因此，<strong>8MB只是一个上限</strong>，实际的内存消耗会略微超过实际需要的内存。这个差额主要是由于内部损耗（每个线程内部的一些开销）所引起的，通常在4KB范围内.<br><strong>注：线程共享进程的地址空间，但每个线程有自己的栈空间。内核为每个线程分配独立的内核栈。</strong></p>
<h4 id="缺页异常是什么？"><a href="#缺页异常是什么？" class="headerlink" title="缺页异常是什么？"></a>缺页异常是什么？</h4><p>缺页异常是计算机操作系统中一种常见的异常，当程序访问一个在其虚拟地址空间中有效但没有被映射到物理内存的页面时，操作系统会触发这一异常。<br><strong>缺页异常的工作过程</strong>：</p>
<ul>
<li><p><strong>内存访问请求</strong>：当一个程序运行时，它试图访问某个地址上的数据。这个地址属于程序的虚拟地址空间。</p>
</li>
<li><p><strong>页面查找</strong>：操作系统通过页表（Page Table）检查该虚拟地址是否已经被映射到物理内存中的一个页面。</p>
</li>
<li><p><strong>缺页异常触发</strong>：如果发现对应的页面没有加载到物理内存中（即该页面不在内存中），操作系统会触发一个缺页异常。</p>
</li>
<li><p><strong>页面加载</strong>：</p>
<ul>
<li>操作系统会通过查找磁盘上的页面文件（如交换分区或文件）将所需的页面从磁盘加载到物理内存中。</li>
<li>如果物理内存已满，操作系统可能需要将一个不常用的页面从内存中写回到磁盘上（这称为页面置换），以腾出空间给新的页面。</li>
</ul>
</li>
<li><p><strong>页表更新</strong>：一旦页面被成功加载到物理内存中，操作系统会更新页表，将虚拟地址映射到新加载的物理地址。</p>
</li>
<li><p><strong>恢复程序执行</strong>：操作系统恢复程序的执行，重新尝试访问引发缺页异常的内存地址。因为现在该页面已经在物理内存中，所以访问可以正常进行。</p>
</li>
</ul>
<h3 id="4-信号量是什么？有什么作用？"><a href="#4-信号量是什么？有什么作用？" class="headerlink" title="4.信号量是什么？有什么作用？"></a>4.信号量是什么？有什么作用？</h3><p>信号量是一种同步机制，<strong>它本质上是一个计数器，用于多进程或多线程对共享资源的访问</strong>。信号量的主要作用是保护共享资源，使得在一个时刻只有一定数量的进程或线程可以访问。<br>信号量的原理是基于 P(sv) 和 V(sv) 两种操作：</p>
<ul>
<li>P(sv) 操作会将信号量的值减1，如果信号量的值大于零，进程或线程可以继续访问共享资源；如果信号量的值为零，进程或线程会被挂起，直到其他进程或线程通过 V(sv) 操作释放信号量。</li>
<li>V(sv) 操作会将信号量的值加1，如果有进程或线程因等待信号量而被挂起，它们中的一个会被唤醒继续执行；如果没有进程或线程等待信号量，信号量的值会增加。</li>
</ul>
<h3 id="5-多进程内存共享存在什么问题，如何处理？"><a href="#5-多进程内存共享存在什么问题，如何处理？" class="headerlink" title="5.多进程内存共享存在什么问题，如何处理？"></a>5.多进程内存共享存在什么问题，如何处理？</h3><h4 id="多进程内存共享问题："><a href="#多进程内存共享问题：" class="headerlink" title="多进程内存共享问题："></a>多进程内存共享问题：</h4><ul>
<li><strong>竞争条件</strong>（Race Condition）：当多个进程同时访问和修改共享内存时，由于执行顺序的不确定性，可能导致数据不一致或不正确的结果。</li>
<li><strong>数据同步问题</strong>：不同的进程可能以不同的速度访问共享内存，导致数据在读取和更新之间的时间差异，进而引发数据不一致的问题。</li>
<li><strong>死锁（Deadlock）</strong>：如果多个进程在访问共享内存时发生<strong>互相等待</strong>的情况，可能导致死锁，使得进程无法继续执行。</li>
</ul>
<h4 id="如何处理："><a href="#如何处理：" class="headerlink" title="如何处理："></a>如何处理：</h4><ul>
<li>使用互斥锁（Mutex）：通过在访问共享内存之前获取互斥锁，并在访问完成后释放锁，可以<strong>确保同一时间只有一个进程访问共享内存</strong>，从而避免竞争条件。</li>
<li>信号量：通过使用信号量来同步进程的访问，可以控制同时访问共享内存的进程数量，从而避免数据同步问题和死锁。</li>
<li>条件变量：条件变量可以用于进程间的通信和同步，它可以在特定条件满足时唤醒等待的进程，从而避免忙等待和减少资源消耗。</li>
<li>使用进程间通信机制(IPC)：使用操作系统提供的进程间通信机制，如管道、消息队列、共享内存、套接字等，可以实现进程间的数据传输和同步，确保共享数据的正确性和一致性。</li>
</ul>
<h4 id="条件变量的使用："><a href="#条件变量的使用：" class="headerlink" title="条件变量的使用："></a>条件变量的使用：</h4><p>使用条件变量时，必须确保与互斥锁一起使用，以避免<strong>竞态条件</strong>的发生。条件变量主要是为了避免竞态条件的发生。<br><strong>竞态条件</strong>（Race Condition）是指在设备或系统尝试同时执行两个或多个操作时，由于操作顺序不当而导致的不期望的结果。简单来说就是因为<strong>时序问题</strong>，而导致程序异常。</p>
<ul>
<li><p>条件变量的接口<br>1.condition_variable<br>2.初始化</p>
<pre><code>mutex mtx; 
condition_variable repo_not_full;
condition_variable repo_not_empty;
void producer()&#123;
    unique_lock&lt;mutex&gt; lock(mtx);
    //等待满足有空出来的地方的条件
    while(true)&#123;
        repo_not_full.wait(lock,[&amp;]()-&gt;bool&#123;return now_total&lt;MAX_size;&#125;);
        Sleep(40);
        que.push(++i);
        now_total++;
        cout&lt;&lt;&quot;producer:&quot;&lt;&lt;i&lt;&lt;endl;
        repo_not_empty.notify_all();
        if(i==target)&#123;
            done = true;
            repo_not_empty.notify_all();
            break;
        &#125;
    &#125;
&#125;
</code></pre>
<p>3.销毁：pthread_cond_destroy<br>4.等待：pthread_cond_wait</p>
<ul>
<li>解锁互斥锁：调用 pthread_cond_wait 的线程首先会释放（解锁）它当前持有的互斥锁。</li>
<li>加入等待队列：调用 pthread_cond_wait 的线程会将自己添加到与该条件变量相关联的<strong>等待队列</strong>中</li>
<li>阻塞并等待信号：线程在等待队列中保持阻塞状态，直到它收到一个针对该条件变量的信号。</li>
<li>重新获取互斥锁：当线程收到信号并准备从 pthread_cond_wait 返回时，它首先会尝试重新获取之前释放的互斥锁。</li>
<li>检查条件：一旦线程成功获取到互斥锁，它会再次检查导致它调用 pthread_cond_wait 的条件是否现在满足。</li>
<li>返回并继续执行：如果条件满足，线程会从 pthread_cond_wait 返回，并继续执行后续的代码。</li>
</ul>
<p>5.唤醒 ：pthread_cond_signal，唤醒正在等待特定条件变量的一个线程</p>
</li>
</ul>
<h3 id="6-多线程、多进程通信的方法："><a href="#6-多线程、多进程通信的方法：" class="headerlink" title="6.多线程、多进程通信的方法："></a>6.多线程、多进程通信的方法：</h3><ul>
<li>1.多线程：互斥锁、信号量、共享内存</li>
<li>2.多进程：信号量、管道、共享内存、socket、消息队列</li>
</ul>
<h3 id="7-父进程与子进程的区别："><a href="#7-父进程与子进程的区别：" class="headerlink" title="7.父进程与子进程的区别："></a>7.父进程与子进程的区别：</h3><h4 id="父进程与子进程的关系"><a href="#父进程与子进程的关系" class="headerlink" title="父进程与子进程的关系"></a>父进程与子进程的关系</h4><p>父进程是创建子进程的进程。当父进程创建一个新的进程时，该新进程就成为子进程。父进程在创建子进程时，会为子进程<strong>分配独立的资源和运行环境</strong>。<br>子进程是由父进程创建的新进程。子进程会继承父进程的大部分属性和资源。它可以独立运行，并且可以执行不同的代码路径。子进程可以创建自己的子进程，形成进程的层次结构。</p>
<h4 id="父进程与子进程的区别"><a href="#父进程与子进程的区别" class="headerlink" title="父进程与子进程的区别"></a>父进程与子进程的区别</h4><ul>
<li><strong>进程ID</strong>：每个进程在系统中都有一个唯一的进程ID。父进程在创建子进程时，会将子进程的进程ID分配给子进程。</li>
<li><strong>进程关系</strong>：父进程与子进程之间建立了一种层次关系，父进程是子进程的创造者和管理者。</li>
<li>资源继承：子进程会继承父进程的大部分属性和资源，<strong>包括打开的文件、环境变量和当前工作目录等。</strong></li>
<li><strong>进程通信</strong>：父进程和子进程可以通过进程间通信机制来进行交互和数据共享，如管道、共享内存、消息队列等。</li>
<li><strong>生命周期</strong>：父进程和子进程的生命周期是相互独立的。<font style="color:red">子进程可以在父进程退出后继续存在，成为孤儿进程，由系统的init进程接管管理</font>。</li>
</ul>
<p>注：fork() 函数用于创建一个新的进程。fork() 调用一次，但返回两次：一次在父进程中返回，一次在子进程中返回。父进程中返回新创建子进程的PID，而在<strong>子进程中，fork返回0</strong>，子进程也通过这个返回值知道自己是否是新创建的子进程。</p>
<h3 id="8-僵尸进程的处理方法"><a href="#8-僵尸进程的处理方法" class="headerlink" title="8.僵尸进程的处理方法"></a>8.僵尸进程的处理方法</h3><h4 id="僵尸进程出现的原因："><a href="#僵尸进程出现的原因：" class="headerlink" title="僵尸进程出现的原因："></a>僵尸进程出现的原因：</h4><p>僵尸进程（Zombie Process）是指一个子进程已经执行完毕并退出，但其父进程没有调用wait()或waitpid()等系统调用来获取子进程的退出状态，从而导致子进程的进程控制块（Process Control Block, PCB）仍然保留在系统中。</p>
<h4 id="处理方法："><a href="#处理方法：" class="headerlink" title="处理方法："></a>处理方法：</h4><ul>
<li>1.在使用fork()创建子进程后，确实应该及时使用**wait()或waitpid()**系统调用来回收子进程的资源。</li>
<li>2.<strong>kill命令来处理僵尸进程</strong>，kill命令主要是用来向进程发送信号。如果父进程在子进程退出后没有处理SIGCHLD信号导致出现僵尸进程，可以使用kill命令发送SIGCHLD信号给父进程来触发父进程处理僵尸进程。可以使用以下命令来找到僵尸进程的PID：ps aux | grep Z（ps aux列出进程，Z代表zombie）<br>接着使用kill -s SIGCHLD <parent_pid></li>
</ul>
<h4 id="为什么需要僵尸进程"><a href="#为什么需要僵尸进程" class="headerlink" title="为什么需要僵尸进程"></a>为什么需要僵尸进程</h4><p>当一个进程（父进程）创建了另一个进程（子进程）后，父进程可能需要了解子进程是<strong>如何结束的</strong>，是否正常退出，还是由于某种错误终止的。这些信息对于父进程的后续操作可能非常重要。操作系统通过僵尸进程来传递和保存这些信息，直到父进程读取它们。</p>
<h3 id="9-什么是进程上下文、中断上下文？"><a href="#9-什么是进程上下文、中断上下文？" class="headerlink" title="9.什么是进程上下文、中断上下文？"></a>9.什么是进程上下文、中断上下文？</h3><p>其实也就是这两个出现的条件不一样，进程上下文是因为操作系统调度器想要切换到另一个进程，而中断上下文则是因为出现了中断和异常，需要保存当前环境。</p>
<h4 id="进程上下文"><a href="#进程上下文" class="headerlink" title="进程上下文"></a>进程上下文</h4><ul>
<li><strong>进程状态信息</strong>：进程上下文是指操作系统在执行进程时所需的所有状态信息的集合。</li>
<li><strong>程序数据</strong>：包括程序的代码、数据、进程的标识符、堆栈、寄存器的值等。</li>
<li>进程上下文的切换通常发生在操作系统的调度器决定切换到另一个进程运行时。</li>
</ul>
<h4 id="中断上下文"><a href="#中断上下文" class="headerlink" title="中断上下文"></a>中断上下文</h4><ul>
<li>中断上下文是指当发生中断或异常事件时，硬件或操作系统内核自动保存当前被中断程序的执行现场，并切换到中断处理程序执行的上下文环境。</li>
<li>中断上下文包含了被中断程序的寄存器状态、堆栈指针、中断原因等信息。</li>
</ul>
<p>中断发生时并不是一个内核的线程出现来打断了现有的线程。中断是一种硬件机制，由硬件设备或CPU产生，不是由内核线程直接引发。它主要用于处理外部设备的请求、定时器或异常等事件。发生中断时，CPU 会暂停当前正在执行的线程或进程，切换到<strong>中断处理程序</strong>，并在中断处理完成后恢复原先的执行。<br>  <strong>使用场景</strong>：</p>
<ul>
<li><strong>当硬件设备发生某种事件</strong>，如I&#x2F;O完成、定时器中断等，会触发中断，并切换到中断上下文执行中断处理程序。</li>
<li>在中断处理程序执行过程中，保存和恢复被中断程序的上下文是必要的，以确保被中断程序的执行能够正确继续。</li>
</ul>
<h3 id="10-守护进程："><a href="#10-守护进程：" class="headerlink" title="10.守护进程："></a>10.守护进程：</h3><h4 id="什么是守护进程："><a href="#什么是守护进程：" class="headerlink" title="什么是守护进程："></a>什么是守护进程：</h4><p>在后台运行的特殊进程，通常以init进程为父进程，独立于终端或控制终端，用于执行常驻任务。一般可以用于网络服务、系统监控（例如top）、定时任务、设备管理：例如打印服务（如 CUPS）、硬件管理等。感觉就是后台的常驻程序。</p>
<h4 id="创建守护进程。"><a href="#创建守护进程。" class="headerlink" title="创建守护进程。"></a>创建守护进程。</h4><ul>
<li>1.<strong>创建子进程</strong>：通过在父进程中调用fork()函数来创建子进程。</li>
<li>2.<strong>终止父进程</strong>：子进程创建后，父进程会调用exit()函数或其他方式终止自身执行，从而使子进程成<strong>孤儿进程</strong>。</li>
<li>3.调用setsid()创建新会话：子进程调用setsid()函数创建一个新的会话。这将使子进程成为会话领导者，并且与其父进程和控制终端解除关系。</li>
<li>4.更改当前目录为根目录：守护进程通常将当前工作目录更改为根目录（chdir(“&#x2F;“)），这样可以避免后续操作与其他进程的目录关联。<br>（注：每个进程都有一个当前工作目录，即默认读取或保存文件的目录。）</li>
<li>5.重设文件权限掩码：守护进程会调用umask()函数来重设文件权限掩码，这样可以确保守护进程创建的文件具有适当的权限。<br>（注：文件权限掩码：文件权限掩码（umask）用于限制新创建文件的默认权限。而确保守护进程有适当的权限，通常将umask设置为0。）</li>
<li>6.关闭文件描述符：守护进程会关闭不再需要的文件描述符，比如标准输入、标准输出和标准错误。这可以防止守护进程意外地与控制终端进行交互。<br>（注：文件描述符是操作系统用于跟踪打开文件的整数标识符。常见的文件描述符包括：0：标准输入，1：标准输出，2：标准错误输出。<br><font style="color:red">感觉有必要去实操一下fork相关的东西</font></li>
</ul>
<h3 id="11-进程五种状态，如何转换。"><a href="#11-进程五种状态，如何转换。" class="headerlink" title="11.进程五种状态，如何转换。"></a>11.进程五种状态，如何转换。</h3><ul>
<li>1.<strong>创建状态</strong>：进程刚被创建，系统为其分配所需的资源，创建进程控制块（PCB）来管理进程的信息和状态。</li>
<li>2.<strong>就绪状态</strong>：进程已经准备好开始执行，但还没有获取到处理器资源，处于等待调度的状态。</li>
<li>3.<strong>执行状态</strong>：进程已经获取到处理器资源，正在执行指令和运行程序。</li>
<li>4.<strong>阻塞状态</strong>：在执行状态下，如果进程遇到阻塞操作，例如等待I&#x2F;O完成，它会进入阻塞状态。在此状态下，进程暂时无法继续执行，直到阻塞的操作完成或者条件满足后才能再次进入就绪状态。</li>
<li>5.<strong>终止状态</strong>：进程执行结束或者被系统终止，进入终止状态。在终止状态下，进程的资源会被释放，PCB会被删除。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240506224328.png"><br>（注：时间片（Time Slice 或 Time Quantum）是操作系统中分配给每个运行中的进程或线程的一段时间。在现代多任务操作系统中，为了让每个任务（进程或线程）都能<strong>公平地使用 CPU</strong>，操作系统会采用一种称为 <strong>时间片轮转调度</strong>（Round Robin Scheduling） 的调度算法。）</li>
</ul>
<h3 id="12-进程通信中的管道实现原理是什么？"><a href="#12-进程通信中的管道实现原理是什么？" class="headerlink" title="12.进程通信中的管道实现原理是什么？"></a>12.进程通信中的管道实现原理是什么？</h3><h4 id="管道是什么？"><a href="#管道是什么？" class="headerlink" title="管道是什么？"></a>管道是什么？</h4><p>管道是一种用于两个进程间同一时刻进行<font style="color:red">单向通信的机制</font>，也被称为半双工管道。操作系统在内核中开辟一块缓冲区（管道），用于进程之间的通信。由于其特性，<strong>同一时刻只能有一个进程进行读或写操作</strong>，所以称为半双工。</p>
<h4 id="管道分类"><a href="#管道分类" class="headerlink" title="管道分类"></a>管道分类</h4><p>管道分为无名管道和命名管道。<br>无名管道只能用于具有父子关系或兄弟关系的进程之间通信，它类似于特殊的文件，管道本质上也是一种文件。无名管道的读端由描述符fd[0]表示，写端由描述符fd[1]表示。<br>命名管道允许无亲缘关系的进程间通信，通过文件系统中的特殊文件进行。命名管道的特点是可以通过路径和文件名访问，不仅限于亲缘关系的进程。</p>
<h4 id="创建管道方法"><a href="#创建管道方法" class="headerlink" title="创建管道方法"></a>创建管道方法</h4><p>可以使用pipe()函数来创建管道。管道创建后可以使用文件IO函数来进行数据读写操作。通常情况下，一个进程在使用pipe()创建管道后，会再通过fork()创建子进程，然后通过管道实现父子进程之间的通信。父子进程都有管道的读端和写端，子进程的描述符是从父进程复制而来的。通过这种方式，<strong>父子进程可以进行数据交换和通信</strong>。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240506225300.png"></p>
<ul>
<li><p>1.创建两个文件描述符：pipefd[0]读,pipefd[1]写</p>
</li>
<li><p>2.创建管道：pipe(pipefd)</p>
<pre><code>#include &lt;iostream&gt;
#include &lt;unistd.h&gt;  // For pipe(), fork()
#include &lt;cstring&gt;   // For strlen()

int main() &#123;
    int pipefd[2];    // 创建两个文件描述符：pipefd[0] for read, pipefd[1] for write
    pid_t pid;
    char buffer[128];

    // 创建管道
    if (pipe(pipefd) == -1) &#123;
        std::cerr &lt;&lt; &quot;Pipe failed!&quot; &lt;&lt; std::endl;
        return 1;
    &#125;

    pid = fork();  // 创建子进程

    if (pid == -1) &#123;
        std::cerr &lt;&lt; &quot;Fork failed!&quot; &lt;&lt; std::endl;
        return 1;
    &#125;

    if (pid == 0) &#123;  // 子进程
        close(pipefd[1]);  // 关闭写端，子进程只读
        read(pipefd[0], buffer, sizeof(buffer));  // 从管道读取数据
        std::cout &lt;&lt; &quot;Child process received: &quot; &lt;&lt; buffer &lt;&lt; std::endl;
        close(pipefd[0]);
    &#125; else &#123;  // 父进程
        close(pipefd[0]);  // 关闭读端，父进程只写
        const char* message = &quot;Hello from parent process!&quot;;
        write(pipefd[1], message, strlen(message) + 1);  // 写入管道
        close(pipefd[1]);
    &#125;

    return 0;
&#125;
</code></pre>
</li>
</ul>
<h4 id="管道使用"><a href="#管道使用" class="headerlink" title="管道使用"></a>管道使用</h4><ul>
<li>1.<strong>创建管道</strong>：调用pipe()函数创建管道，获取管道的读端和写端的文件描述符。</li>
<li>2.<strong>创建子进程</strong>：调用fork()创建子进程，此时子进程会继承父进程的管道描述符。</li>
<li>3.<strong>保证父子进程的读写端</strong>：在父进程中关闭管道的不需要的端口，例如关闭管道的读端，保留管道的写端；在子进程中关闭管道的另一个端口，即关闭管道的写端，保留管道的读端。</li>
<li>4.<strong>写入数据</strong>：父进程通过保留的管道写端，使用write()函数向管道写入数据。</li>
<li>5.<strong>读取数据</strong>：子进程通过保留的管道读端，使用read()函数从管道中读取数据。</li>
<li>6.父进程和子进程根据需求进行数据的交换和通信。</li>
<li>7.<strong>关闭端口</strong>：当通信结束后，父进程和子进程分别关闭其管道端口，即父进程关闭管道的写端，子进程关闭管道的读端。</li>
<li>8.<strong>等待子进程结束</strong>：父进程通过调用wait()等待子进程的结束，确保子进程正确退出。</li>
</ul>
<h3 id="13-死锁的原因和条件以及如何预防？"><a href="#13-死锁的原因和条件以及如何预防？" class="headerlink" title="13. 死锁的原因和条件以及如何预防？"></a>13. 死锁的原因和条件以及如何预防？</h3><p>多个进程在执行过程中，因争夺资源而造成了互相等待。此时系统产生了死锁。</p>
<h4 id="死锁产生的条件"><a href="#死锁产生的条件" class="headerlink" title="死锁产生的条件"></a>死锁产生的条件</h4><p>主要其实就是自己手里有资源，但是还想要其他的资源，无法满足请求，然后就无限等待。</p>
<ul>
<li>1.互斥条件：进程对分配资源独享，其他进程需要等待</li>
<li>2.请求保持条件：进程需要<strong>持有已分配的资源</strong>，并继续请求其他资源，但他们无法满足请求，导致<strong>进程阻塞并保持对已有资源的持有</strong>。拿着手里的，还想要别人的。</li>
<li>3.不可剥夺：进程获得的资源不能被其他进程强制获取。</li>
<li>4.<strong>环路等待条件</strong>：存在多个进程之间形成循环等待资源的关系。我要你的，你要我的，转起来了。</li>
</ul>
<h4 id="预防死锁（对应上面的4个条件说给出解法）"><a href="#预防死锁（对应上面的4个条件说给出解法）" class="headerlink" title="预防死锁（对应上面的4个条件说给出解法）"></a>预防死锁（对应上面的4个条件说给出解法）</h4><ul>
<li>1.破坏互斥条件：尽可能地<strong>共享资源</strong>，而不是互斥地独占资源。</li>
<li>2.破坏请求保持条件：请求资源时<strong>先释放已占有的资源</strong>，再请求所需的资源，以避免持有资源的阻塞情况。</li>
<li>3.破坏不可剥夺条件：引入资源抢占机制，使得系统可以对进程已获取的资源进行剥夺。</li>
<li>4.破坏环路等待条件：通过合理的资源分配策略，避免形成循环等待的资源关系。</li>
</ul>
<h3 id="14-死锁和活锁的区别"><a href="#14-死锁和活锁的区别" class="headerlink" title="14.死锁和活锁的区别"></a>14.死锁和活锁的区别</h3><h4 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h4><ul>
<li>1.死锁指的是两个或多个线程彼此等待对方释放所持有的资源，从而导致所有线程都无法继续执行，程序无法继续运行的情况。</li>
<li>2.死锁是一种静止状态，线程被无限阻塞，直到外部干预，如强制终止某些线程。</li>
<li>3.死锁发生时，线程无法自行解锁，需要外部的干预来打破循环依赖，释放资源以解决死锁。</li>
</ul>
<h4 id="活锁"><a href="#活锁" class="headerlink" title="活锁"></a>活锁</h4><ul>
<li>1.活锁指的是&#x3D;&#x3D;多个线程不断重试&#x3D;&#x3D;，但最终无法取得进展的情况。线程们在不断改变自己的状态，但总是无法成功完成所需的操作。</li>
<li>2.活锁是一种<strong>动态状态</strong>，线程不断重试，但无法使程序向前推进。</li>
<li>3.活锁通常是由于竞争条件、过度的自旋等问题引起的。<br><strong>活锁举个例子</strong>：两个线程 threadFunction1 和 threadFunction2 分别尝试获取 mutex1 和 mutex2 这两个互斥量。但是它们在获取其中一个互斥量之后会尝试获取另一个互斥量，如果获取失败则释放已经获取的互斥量。这样，两个线程会不断地尝试交换互斥量的所有权，但最终都无法成功获取到所有的互斥量</li>
</ul>
<p><strong>解决活锁问题的方式：</strong></p>
<ul>
<li>1.引入随机性：通过引入随机因素，使线程的行为具有一定的不确定性，避免线程们不断重复相同的操作。</li>
<li>2.使用策略：在活锁发生时，采用某种策略，例如放弃一部分工作、转让任务或<strong>等待一段随机时间</strong>等。</li>
<li>3.调整线程优先级：适当调整线程的优先级，以改变线程的竞争行为。</li>
<li>4.重新设计算法和协调：如果活锁是由于设计问题引起的，需要重新设计算法或协调机制，以避免竞争条件。</li>
</ul>
<h3 id="15-sleep和wait的区别"><a href="#15-sleep和wait的区别" class="headerlink" title="15.sleep和wait的区别"></a>15.sleep和wait的区别</h3><ul>
<li>1.所属类别：sleep是Thread类的方法，而wait是Object类的方法。</li>
<li>2.锁的释放：在调用wait时，<strong>线程会释放它持有的锁，进入等待状态</strong>，并等待其他线程通过notify或notifyAll来唤醒它。而sleep方法不会释放锁，<strong>线程会保持对锁的持有</strong>。</li>
<li>3.唤醒方式：调用wait的线程<font style="color:red">必须依赖其他线程的notify或notifyAll来唤醒它</font>，而sleep方法可以<font style="color:red">设定一个固定的时间</font>，时间到后线程会自动唤醒。wait 函数来等待条件满足，如果条件不满足，它会释放互斥量并进入阻塞状态，等待其他线程发出信号。</li>
<li>4.使用场景：wait通常用于线程间的<strong>同步和协作</strong>，例如等待其他线程的信号或共享资源的通知。sleep适用于线程的<strong>暂时休眠</strong>，例如实现定时任务或控制线程执行间隔。</li>
</ul>
<h3 id="16-epoll和select的区别，epoll为什么高效？"><a href="#16-epoll和select的区别，epoll为什么高效？" class="headerlink" title="16.epoll和select的区别，epoll为什么高效？"></a>16.epoll和select的区别，epoll为什么高效？</h3><p>select 和 epoll 都是在 Linux 系统上用于多路复用 I&#x2F;O 的机制，可以使一个进程能够监视多个文件描述符的状态，从而在有 I&#x2F;O 事件发生时进行响应。<br>IO多路复用:一种同步IO模型，单个进程&#x2F;线程就可以同时处理多个IO请求。一个进程&#x2F;线程可以监视多个文件句柄；一旦某个文件句柄就绪，就能够通知应用程序进行相应的读写操作。<br><strong>例子：你是一个老师，让学生做作业，学生做完作业后收作业。</strong><br><strong>同步阻塞</strong>：逐个收作业，先收A，再收B，接着是C、D，如果有一个学生还未做完，则你会等到他写完，然后才继续收下一个。<br>解析：这就是同步阻塞的特点，只要中间有一个未就绪，则你会<strong>被阻塞住</strong>，从而影响到后面的其他学生。<br><strong>同步非阻塞</strong>：逐个收作业，先收A，再收B，接着是C、D，如果有一个学生还未做完，则你会跳过该学生，继续去收下一个。</p>
<p><strong>多路复用IO口的应用场景</strong>：<br>在需要处理多个输入&#x2F;输出通道的应用场景中非常有用：</p>
<ul>
<li>1.高并发网络服务器</li>
<li>2.试试数据处理</li>
</ul>
<p><strong>为什么更高效？</strong></p>
<p><strong>select</strong><br>select 通过让用户空间的应用程序向内核<strong>传递一个文件描述符集合</strong>，然后等待内核检查这些描述符的状态。每次调用select时，用户都必须将所有文件描述符列表传递给内核，内核需要遍历所有的文件描述符去检查其状态。</p>
<p><strong>epoll</strong><br>epoll 通过系统调用创建一个事件表（epoll_create），用户可以将文件描述符注册到事件表中（epoll_ctl），并且只需在事件发生时（如可读、可写）通知用户（epoll_wait）。比select，poll 不需要每次都重新传递整个文件描述符集合，而是通过<strong>事件表</strong>的机制只传递变化的文件描述符，这大大减少了用户空间与内核空间之间的交互次数。</p>
<p><strong>poll</strong><br>poll 使用一个结构体数组来表示文件描述符及其感兴趣的事件，可以监控的文件描述符数量仅受<strong>系统最大打开文件数的限制</strong>。调用方式：poll 每次调用时，将文件描述符数组传递给内核，内核扫描这些文件描述符，并<strong>标记就绪的文件描述符</strong>。返回处理：返回后，程序需要遍历数组来找到就绪的文件描述符。</p>
<h3 id="17-互斥锁机制，互斥锁与读写锁的区别？"><a href="#17-互斥锁机制，互斥锁与读写锁的区别？" class="headerlink" title="17.互斥锁机制，互斥锁与读写锁的区别？"></a>17.互斥锁机制，互斥锁与读写锁的区别？</h3><p>互斥锁（Mutex）是一种用于线程同步的机制，用于保护共享资源在多个线程间的互斥访问。互斥锁的特点如下：<br><strong>互斥原理</strong>：当一个线程获得互斥锁时，其他线程需要等待该线程释放锁才能继续执行。通过互斥锁的加锁和解锁操作，可以确保同一时间只有一个线程能够访问共享资源，从而保证数据的一致性和正确性。<br><strong>加锁操作</strong>：当线程想要访问共享资源时，首先需要尝试获得互斥锁。如果互斥锁已被其他线程占用，则当前线程会被阻塞，直到互斥锁被释放。一旦线程成功获得互斥锁，它就可以安全地访问共享资源。<br><strong>解锁操作</strong>：线程使用完共享资源后，应该释放互斥锁，以便其他线程可以继续访问。释放互斥锁将导致等待该锁的线程中的一个或多个线程恢复执行。</p>
<h4 id="互斥锁与读写互斥锁的区别："><a href="#互斥锁与读写互斥锁的区别：" class="headerlink" title="互斥锁与读写互斥锁的区别："></a>互斥锁与读写互斥锁的区别：</h4><ul>
<li>互斥锁（Mutex）：互斥锁保证了在任意时刻只有一个线程能够获得锁。当一个线程获得互斥锁后，其他线程必须等待该线程释放锁才能继续执行。互斥锁适用于对共享资源的互斥访问，既包括读操作也包括写操作。</li>
<li>读写锁（ReadWrite Lock）：读写锁允许多个线程同时读共享资源，但在写共享资源时需要互斥访问。多个线程可以同时获取读写锁的读锁，&#x3D;&#x3D;只有当没有线程持有读锁时，写锁才能被获取&#x3D;&#x3D;。读写锁适用于读多写少的场景，可以提高并发性能。</li>
</ul>
<h3 id="18-IO讲解："><a href="#18-IO讲解：" class="headerlink" title="18 IO讲解："></a>18 IO讲解：</h3><p><a class="link"   target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/607461843" >IO讲解<i class="fas fa-external-link-alt"></i></a></p>
<h4 id="文件描述符"><a href="#文件描述符" class="headerlink" title="文件描述符"></a>文件描述符</h4><p>我们知道在Linux系统中一切皆可以看成是文件，文件又可分为：普通文件、目录文件、链接文件和设备文件。在操作这些所谓的文件的时候，我们每操作一次就找一次名字，这会耗费大量的时间和效率。所以Linux中规定每一个文件<strong>对应一个索引</strong>，这样要操作文件的时候，我们直接找到索引就可以对其进行操作了。<br>文件描述符（file descriptor）就是内核为了高效管理这些已经被打开的文件所创建的索引，其是一个非负整数（通常是小整数），用于指代被打开的文件，所有执行I&#x2F;O操作的系统调用都通过文件描述符来实现</p>
<p>程序开始运行时，有三个文件被自动打开了，占用0 1 2 三个描述符：依次打开的三个文件分别是&#x2F;dev&#x2F;stdin，&#x2F;dev&#x2F;stdout，&#x2F;dev&#x2F;stderr<br>文件偏移量：写会改变文件大小。</p>
<h4 id="文件描述符表、打开文件表、i-node表。"><a href="#文件描述符表、打开文件表、i-node表。" class="headerlink" title="文件描述符表、打开文件表、i-node表。"></a>文件描述符表、打开文件表、i-node表。</h4><p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240513224439.png"></p>
<h4 id="inode：用于描述文件的信息："><a href="#inode：用于描述文件的信息：" class="headerlink" title="inode：用于描述文件的信息："></a>inode：用于描述文件的信息：</h4><ul>
<li><p>文件的字节数</p>
</li>
<li><p>文件拥有者的User ID</p>
</li>
<li><p>文件的Group ID</p>
</li>
<li><p>文件的读、写、执行权限</p>
</li>
<li><p>文件的时间戳，共有三个：ctime指inode上一次变动的时间，mtime指文件内容上一次变动的时间，atime指文件上一次打开的时间。</p>
</li>
<li><p>链接数，即有多少文件名指向这个inode</p>
</li>
<li><p>文件数据block的位置（磁盘上的）</p>
</li>
</ul>
<p>每个inode节点的大小，一般是128字节或256字节</p>
<h3 id="18-中断向量表"><a href="#18-中断向量表" class="headerlink" title="18.中断向量表"></a>18.中断向量表</h3><p>中断向量表（Interrupt Vector Table, IVT）是处理器用来管理<strong>中断处理程序地址</strong>的一个表。每当发生中断时，处理器会从中断向量表中获取相应中断处理程序的地址，并跳转到该地址执行相应的中断处理程序。<br>中断向量表通常位于内存的固定位置，不同处理器的具体实现会有所不同。例如，在 x86 处理器上，中断向量表通常位于内存的 0x0000 处，而在 ARM 处理器上，中断向量表的位置可以通过控制寄存器配置。</p>
<h3 id="19-内存泄漏"><a href="#19-内存泄漏" class="headerlink" title="19.内存泄漏"></a>19.内存泄漏</h3><p>内存泄漏(memory leak)是指由于疏忽或错误造成了程序未能释放掉不再使⽤的内存的情况。内存泄漏并⾮指内存在物理上的消失，⽽是应⽤程序分配某段内存后，由于设计错误，失去了对该段内存的控制，因⽽造成了内存的浪费。<br>内存泄漏的分类：</p>
<ul>
<li><p>1.堆内存泄漏：<br>使用malloc、new等方法从堆中分配一块地址，最终导致没有释放，这块地址就会产生堆内存泄漏</p>
</li>
<li><p>2.系统资源泄露<br>主要指程序使⽤系统分配的资源⽐如 Bitmap,handle ,SOCKET 等没有使⽤相应的函数释放掉，导致系统资源的浪费，严重的可导致系统效能降低，系统运⾏不稳定。 </p>
</li>
<li><p>3.没有将基类的析构函数定义为虚函数<br>当基类指针指向⼦类对象时，如果<strong>基类的析构函数不是 virtual，那么⼦类的析构函数将不会被调⽤</strong>，⼦类的资源没有正确是释放，因此造成内存泄露。这里指的是在构造函数中new定义了堆内存，而在析构函数中定义了释放。而子类析构函数的失效会导致new没有对应的delete。</p>
<p><em><strong>深度解读为什么基类的析构函数不是 virtual，那么⼦类的析构函数将不会被调⽤</strong></em></p>
<ul>
<li>静态绑定：当基类的析构函数不是virtual时，C++编译器在<strong>编译时就决定了在删除一个对象时应该调用哪个析构函数</strong>。如果你通过基类指针或引用删除一个派生类对象，由于基类的析构函数不是虚函数，编译器会静态绑定到基类的析构函数上。这意味着无论指针实际指向的是基类对象还是派生类对象，都会调用基类的析构函数。由于编译器不知道你实际上是在通过基类指针删除一个派生类对象，所以它不会调用派生类的析构函数。</li>
<li>动态绑定：如果基类的析构函数是virtual的，C++会使用动态绑定。这意味着在运行时，程序会根据实际对象的类型来决定调用哪个析构函数。当你通过基类指针删除一个派生类对象时，编译器会确保首先调用派生类的析构函数，然后调用基类的析构函数。这是通过虚函数表（vtable）实现的。</li>
</ul>
</li>
<li><p>4.栈可能引发的内存泄漏<br>栈本身不会引发内存泄漏，但是栈上new的空间不delete直接pop就可能会引发内存泄漏。<br>栈中存储指针（堆内存）： 如果栈中存储的是指向堆内存的指针（比如通过new分配的对象指针），在栈销毁或出栈时，没有正确释放这些指针所指向的内存，就可能引发内存泄漏。</p>
<pre><code>std::stack&lt;int*&gt; ptrStack;
ptrStack.push(new int(10)); // 分配的堆内存没有释放

// 在销毁栈或出栈时，没有释放内存
ptrStack.pop(); // 此时，指向`new int(10)`的指针丢失，导致内存泄漏
</code></pre>
</li>
</ul>
<h3 id="20-bootloader引导流程"><a href="#20-bootloader引导流程" class="headerlink" title="20.bootloader引导流程"></a>20.bootloader引导流程</h3><p>bootloader是开机引导程序，也就是一个裸机程序</p>
<ul>
<li>1.上电和复位：CPU开始从预定义的地址开始执行指令，通常是bootloader的入口地址</li>
<li>2.硬件初始化：<ul>
<li>CPU初始化</li>
<li>内存初始化</li>
<li>外设初始化：例如LCD等基础参数</li>
</ul>
</li>
<li>3.启动模式检测<ul>
<li>启动源选择</li>
<li>引导模式检测</li>
</ul>
</li>
<li>4.一级引导加载程序：将存储器中加载二级引导加载程序到RAM中</li>
<li>5.二级引导加载程序：<ul>
<li>初始化扩展硬件</li>
<li>加载操作系统内核</li>
<li>操作系统启动参数</li>
</ul>
</li>
<li>6.操作系统启动<ul>
<li>跳转内核</li>
<li>内核初始化：内核开始执行，初始化内核子系统和驱动程序，挂载根文件系统。</li>
<li>用户空间启动</li>
</ul>
</li>
</ul>
<h3 id="21-一个进程中多线程的内存排布方式"><a href="#21-一个进程中多线程的内存排布方式" class="headerlink" title="21.一个进程中多线程的内存排布方式"></a>21.一个进程中多线程的内存排布方式</h3><p>线程主要是每个栈不共享，每一个线程分配一个栈帧，在进程的虚拟内存空间中相互隔离。</p>
<p><strong>共享部分</strong>:</p>
<ul>
<li>代码段: 线程共享相同的可执行代码。</li>
<li>数据段: 线程共享初始化的全局变量和静态变量。</li>
<li>未初始化数据段: 线程共享未初始化的全局变量和静态变量。</li>
<li>堆内存: 线程可以相互访问动态分配的内存。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240723221338.png"><br><strong>独立部分</strong>:</p>
<ul>
<li>栈: 每个线程都有自己的栈空间，用于存储局部变量和函数调用信息。线程的栈是独立的，不会相互干扰</li>
</ul>
<h3 id="22-并发，同步，异步，互斥，阻塞，非阻塞的理解"><a href="#22-并发，同步，异步，互斥，阻塞，非阻塞的理解" class="headerlink" title="22.并发，同步，异步，互斥，阻塞，非阻塞的理解"></a>22.并发，同步，异步，互斥，阻塞，非阻塞的理解</h3><ul>
<li><strong>并发</strong><br>并发是指多个任务或操作在<strong>同一时间段</strong>内执行，它们相互独立，不一定按照严格的顺序执行。</li>
<li><strong>同步</strong><br>同步是为了协调多个任务或操作之间的顺序和行为，以确保数据的一致性。在同步中，任务或操作可能会按照&#x3D;&#x3D;特定的顺序&#x3D;&#x3D;执行或等待其他任务的完成，以满足特定的条件。</li>
<li><strong>异步</strong><br>异步是指任务或操作可以独立于当前线程继续执行，而不需要等待其他任务完成。在异步操作中，任务可以在后台或另一个线程中执行，并且可以提供结果或通知以后再处理。</li>
<li><strong>互斥</strong><br>互斥是指通过一种机制来确保同一时间只有一个任务或线程可以访问共享资源。它通过锁或信号量等机制实现，以避免数据竞争和冲突。</li>
<li><strong>阻塞</strong><br>阻塞是指当一个线程或任务在执行过程中遇到某种条件而无法继续进行时，暂停执行，等待条件满足或被唤醒。在阻塞状态下，资源通常不可用，直到条件满足。</li>
<li><strong>非阻塞</strong><br>非阻塞是指任务或操作在执行过程中不会暂停等待条件满足，而是立即返回并继续执行其他任务。非阻塞操作可以持续进行，而不会受到其他任务的影响。</li>
</ul>
<h3 id="23-线程同步和阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？"><a href="#23-线程同步和阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？" class="headerlink" title="23.线程同步和阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？"></a>23.线程同步和阻塞的关系？同步一定阻塞吗？阻塞一定同步吗？</h3><p>并不是所有的同步操作都会导致线程阻塞。例如，在&#x3D;&#x3D;使用无锁数据结构或者一些并发原语&#x3D;&#x3D;（如<strong>原子操作</strong>的情况下），线程可以在不阻塞的情况下实现同步。<br>阻塞也不一定意味着同步。线程阻塞是由于等待特定条件的满足或是在某些操作完成之前无法继续执行。而同步是为了协调线程之间的顺序和行为，以保证数据的一致性。阻塞有时可能会与同步相关，但阻塞本身并不代表同步。<br><strong>结论</strong>：同步不一定需要线程阻塞，而阻塞的目的也不一定是要与线程同步。</p>
<h3 id="24-epoll和select"><a href="#24-epoll和select" class="headerlink" title="24.epoll和select"></a>24.epoll和select</h3><p>epoll 和 select 是两种用于多路复用 I&#x2F;O 操作的系统调用，用于<strong>监视</strong>多个文件描述符，以查看哪些文件描述符准备好了进行 I&#x2F;O 操作（如读、写等）。它们通常用于开发高性能的服务器程序。</p>
<ul>
<li><strong>select</strong><br>select 能够监听一组文件描述符，并在其中任意一个文件描述符就绪时返回。在使用select时，需要将文件描述符集合加入到fd_set中，并通过&#x3D;&#x3D;轮询操作&#x3D;&#x3D;检查是否有文件描述符就绪，然后进行相应的操作。</li>
<li><strong>epoll</strong><br>它能够监视大量的文件描述符，并且在文件描述符就绪时触发相应的事件。只有当文件描述符状态发生变化时才触发事件通知，避免了频繁的轮询操作，提高了I&#x2F;O效率。</li>
</ul>
<p><strong>epoll为什么更高效？</strong></p>
<ul>
<li>拷贝开销：<ul>
<li>每次调用select，都需要将文件描述符集合从用户态拷贝到内核态，这个开销在文件描述符很多时会很大。</li>
<li>epoll保证了每个文件描述符在整个过程中只会拷贝一次，因此不会有拷贝开销的增加。</li>
</ul>
</li>
<li>遍历开销：<ul>
<li>每次调用select，需要在内核遍历传递进来的所有文件描述符，即使只有很少的文件描述符就绪。</li>
<li>epoll只需要轮询一次文件描述符集合，然后查看就绪链表中有没有就绪的文件描述符即可，避免了遍历所有文件描述符的开销。</li>
</ul>
</li>
</ul>
<p><strong>文件描述符数量的限制</strong>：<br>select有一个固定的限制，它支持的文件描述符数量较小，默认情况下是1024。<br>epoll没有这个限制，它所支持的文件描述符上限取决于系统最大可以打开的文件数目，一般远大于1024。</p>
<h3 id="25-epoll水平触发和边缘触发的区别"><a href="#25-epoll水平触发和边缘触发的区别" class="headerlink" title="25.epoll水平触发和边缘触发的区别"></a>25.epoll水平触发和边缘触发的区别</h3><p>在 epoll 中，有两种触发模式：<strong>水平触发</strong>（Level-Triggered，LT）和<strong>边缘触发</strong>（Edge-Triggered，ET）。</p>
<ul>
<li><strong>水平触发（LT）</strong>：在水平触发模式下，当一个文件描述符上有数据可读或可写时，<strong>epoll_wait 函数会立即返回</strong>，并通知用户程序进行 I&#x2F;O 操作。如果文件描述符上的数据没有被完全读取或写入，下次调用 epoll_wait 时仍然<strong>会通知用户程序</strong>。水平触发是默认的触发模式，在 epoll_ctl 函数中不指定 EPOLLET 标志即可使用水平触发。</li>
<li><strong>边缘触发（ET）</strong>：在边缘触发模式下，当一个文件描述符上的状态发生变化时（如从无数据变为有数据可读），epoll_wait 函数会通知一次，并且<strong>只通知一次</strong>。边缘触发模式要求用户程序持续地读取或写入数据，直到发生 EAGAIN 错误，才能确保不会错过任何事件。边缘触发需要在 epoll_ctl 函数中指定 EPOLLET 标志来开启。</li>
</ul>
<h3 id="26-5种IO模型"><a href="#26-5种IO模型" class="headerlink" title="26.5种IO模型"></a>26.5种IO模型</h3><h4 id="阻塞式-IO-模型："><a href="#阻塞式-IO-模型：" class="headerlink" title="阻塞式 IO 模型："></a>阻塞式 IO 模型：</h4><ul>
<li>在阻塞式 IO 模型中，当应用程序发起一个 IO 操作时，它会<strong>一直等待</strong>，直到操作完成并返回结果。</li>
<li>在这个过程中，应用程序无法进行其他任务，会一直阻塞在该 IO 操作上。</li>
<li>阻塞式 IO 模型简单易用，但会导致应用程序的整体性能受限，因为在等待 IO 完成期间无法进行其他工作。</li>
</ul>
<h4 id="非阻塞式-IO-模型"><a href="#非阻塞式-IO-模型" class="headerlink" title="非阻塞式 IO 模型"></a>非阻塞式 IO 模型</h4><ul>
<li>在非阻塞式 IO 模型中，应用程序通过设置文件描述符为非阻塞模式进行 IO 操作。</li>
<li>当进行非阻塞 IO 操作时，如果操作不能立即完成，系统会立即返回，而不会阻塞应用程序。</li>
<li>应用程序可以继续进行其他任务，然后通过轮询或其他手段来查询IO操作的状态，直到操作完成。</li>
</ul>
<h4 id="IO-复用模型"><a href="#IO-复用模型" class="headerlink" title="IO 复用模型"></a>IO 复用模型</h4><ul>
<li>IO 复用模型使用 select、poll 或 epoll 等函数，可以同时&#x3D;&#x3D;监听多个文件描述符上的 IO 事件&#x3D;&#x3D;。</li>
<li>当任何一个文件描述符上有 I&#x2F;O 事件发生时，应用程序会被通知，然后可以执行相应的读写操作。</li>
<li>IO 复用模型避免了阻塞操作，可以同时处理多个文件描述符上的 I&#x2F;O 事件，提高了系统的并发性能。</li>
</ul>
<h4 id="信号驱动式-IO-模型"><a href="#信号驱动式-IO-模型" class="headerlink" title="信号驱动式 IO 模型"></a>信号驱动式 IO 模型</h4><ul>
<li>在信号驱动式 IO 模型中，应用程序发起一个 IO 操作后，可以继续进行其他任务而不会阻塞。</li>
<li>当 IO 操作完成时，系统会向<strong>应用程序发送一个信号</strong>，应用程序通过信号处理函数处理完成的 IO 事件。</li>
<li>允许一个线程同时监控多个文件描述符并等待其状态变化</li>
</ul>
<h4 id="异步-IO-模型"><a href="#异步-IO-模型" class="headerlink" title="异步 IO 模型"></a>异步 IO 模型</h4><ul>
<li>在异步 IO 模型中，应用程序发起一个 IO 操作后，可以继续进行其他任务而不会阻塞。</li>
<li>当 IO 操作完成时，系统会通知应用程序，<strong>应用程序可以直接处理完成的 IO 事件</strong></li>
<li>完全非阻塞，应用程序发起 I&#x2F;O 操作后立即返回，操作系统在操作完成后通知应用程序。</li>
</ul>
<h3 id="27-自旋锁和互斥锁的使用场景？"><a href="#27-自旋锁和互斥锁的使用场景？" class="headerlink" title="27.自旋锁和互斥锁的使用场景？"></a>27.自旋锁和互斥锁的使用场景？</h3><p>自旋锁（Spin Lock）和互斥锁（Mutex Lock）是常见的线程同步机制，它们适用于不同的使用场景：</p>
<h4 id="自旋锁："><a href="#自旋锁：" class="headerlink" title="自旋锁："></a>自旋锁：</h4><ul>
<li>自旋锁采用了一种<strong>忙等待</strong>的方式，线程在无法获得锁时不会被阻塞，而是&#x3D;&#x3D;一直循环检查锁&#x3D;&#x3D;的状态，直到获得锁为止。</li>
<li>自旋锁适用于锁被占用的时间<strong>非常短暂而且线程竞争不激烈</strong>的情况。如果进入休眠和唤醒的开销比自旋等待的开销更大，自旋锁是更好的选择。</li>
<li>自旋锁不涉及上下文切换，因为线程在等待锁时会忙等待。因此，在多核处理器上，自旋锁可以表现得更好，因为它充分利用了处理器的并行性和线程的空闲时间。</li>
</ul>
<p><strong>自旋锁的使用场景包括</strong>：临界区较短且竞争不激烈的情况，常见于多核处理器、高性能计算和实时系统等。<br><strong>优点</strong>：低延迟：避免了线程休眠和唤醒的开销<br><strong>缺点</strong>：高CPU占用：如果锁保持时间较长，会导致CPU资源的浪费。不适用于长时间锁定：在长时间锁定的情况下效率低下。</p>
<h4 id="互斥锁"><a href="#互斥锁" class="headerlink" title="互斥锁"></a>互斥锁</h4><ul>
<li>互斥锁提供了线程的互斥访问，即只有一个线程能够获得锁并执行临界区代码，其他线程需要等待。</li>
<li>互斥锁适用于临界区较长或者有激烈线程竞争的情况。</li>
<li>互斥锁涉及到线程的阻塞和唤醒操作，当锁被占用时，等待线程会被阻塞，直到锁被释放。<br><strong>互斥锁的使用场景包括</strong>：临界区较长或者需要保证临界区的独占性的情况，常见于共享资源的读写、数据库访问、线程间通信等<br><strong>优点</strong>：低CPU占用：线程在等待锁时进入休眠，释放CPU资源。适用于长时间锁定：在锁保持时间较长的情况下效率较高。<br><strong>缺点</strong>：较高的上下文切换开销：线程休眠和唤醒需要操作系统的调度，开销较大。较高的延迟：由于线程可能被调度到不同的CPU上，可能会引入额外的延迟。</li>
</ul>
<h3 id="28-线程池工作原理？线程池中线程的数量由什么确定？"><a href="#28-线程池工作原理？线程池中线程的数量由什么确定？" class="headerlink" title="28.线程池工作原理？线程池中线程的数量由什么确定？"></a>28.线程池工作原理？线程池中线程的数量由什么确定？</h3><h4 id="线程池工作原理"><a href="#线程池工作原理" class="headerlink" title="线程池工作原理"></a>线程池工作原理</h4><ul>
<li>1.<strong>线程初始化</strong>：<ul>
<li>创建并启动一定数量的线程（称为工作线程）。</li>
<li>这些工作线程会在后台运行，并等待来自任务队列的任务。</li>
</ul>
</li>
<li>2.<strong>提交任务</strong>：<ul>
<li>当需要执行一个任务时，程序将任务提交到线程池的任务队列中。</li>
<li>任务可以是任何可以被线程执行的工作单元，例如函数、方法或操作。</li>
</ul>
</li>
<li>3.<strong>任务分配</strong>：<ul>
<li>工作线程<strong>会从任务队列中取出任务并执行</strong>。</li>
<li>如果所有工作线程都在忙，任务将被放入队列中等待。</li>
</ul>
</li>
<li>4.<strong>任务执行</strong>：<ul>
<li>工作线程从任务队列中取出任务并执行任务。</li>
<li>执行完成后，工作线程将继续从任务队列中取出下一个任务。</li>
</ul>
</li>
<li>5.<strong>线程复用</strong>：</li>
<li>线程池通过&#x3D;&#x3D;复用现有线程避免了频繁的线程创建和销毁&#x3D;&#x3D;，降低了系统的开销。</li>
<li>当没有任务时，工作线程会进入等待状态，直到有新任务提交。</li>
</ul>
<h4 id="决定数量"><a href="#决定数量" class="headerlink" title="决定数量"></a>决定数量</h4><p>线程池中线程数量的选择与CPU、IO、并行和并发等因素有关。</p>
<ol>
<li><strong>CPU密集型应用</strong>：如果任务主要是计算密集型，即需要大量的CPU时间，通常将线程池大小设置为<strong>CPU核心数量+1</strong>，这样可以保持CPU的高利用率。 </li>
<li><strong>IO密集型应用</strong>：如果任务主要是IO密集型，即任务在等待IO操作的时间较长，可以增加线程池的大小，一般建议将线程池大小设置为<strong>2倍的CPU核心数量加1</strong>。这样可以充分利用CPU的计算能力，同时<strong>允许一些线程在等待IO操作时进行并发执行</strong>。</li>
<li><strong>并行度和响应性需求</strong>：线程池的大小还受到任务的并行度和对响应性的需求影响。根据公式最佳线程数目 &#x3D; （线程等待时间与线程CPU时间之比 + 1）* CPU数目，线程等待时间所占比例越高，就需要更多的线程来充分利用等待时间；线程CPU时间所占比例越高，就可以减少线程的数量。考虑到任务等待时间和CPU时间的比例，可以调整线程池的大小以提供最佳的性能。</li>
</ol>
<h4 id="线程池的优点"><a href="#线程池的优点" class="headerlink" title="线程池的优点"></a>线程池的优点</h4><p>1 2对于消耗的系统时间；3 4 对于线程管理</p>
<ul>
<li>1.减少线程创建和销毁的开销：<br>创建和销毁线程需要消耗系统资源，特别是在高并发环境下。如果每次执行任务都创建和销毁线程，会浪费大量资源。线程池通过复用线程，减少了这些开销。</li>
<li>2.提高响应速度：<br>任务到来时，线程已经进入等待，任务立刻可以被处理，不需要创建</li>
<li>3.控制并发量：<br>通过限制线程池中的线程数量，线程池可以控制系统中同时运行的线程数量，避免因过多线程导致的资源竞争和性能下降</li>
<li>4.任务调度和管理：<br>线程池可以对任务进行有效的调度和管理，确保任务按照预期的顺序和优先级执行</li>
</ul>
<h3 id="29-页表是什么以及页表的作用-x2F-内存管理是怎么实现的"><a href="#29-页表是什么以及页表的作用-x2F-内存管理是怎么实现的" class="headerlink" title="29.页表是什么以及页表的作用&#x2F;内存管理是怎么实现的"></a>29.页表是什么以及页表的作用&#x2F;内存管理是怎么实现的</h3><p>页表（Page Table）是操作系统中的一种数据结构，用于&#x3D;&#x3D;管理虚拟内存和物理内存之间的映射关系&#x3D;&#x3D;。它记录了进程的页（Page）与物理页框（Page Frame）之间的对应关系。</p>
<h4 id="作用："><a href="#作用：" class="headerlink" title="作用："></a>作用：</h4><ul>
<li>1.<strong>映射关系</strong>：系统可以将虚拟地址转为实际的物理地址，这样进程使用的连续的虚拟地址反映在物理地址上不一定是连续的。</li>
<li>2.<strong>内存管理</strong>：页表可以帮助操作系统有效地管理内存。它可以将进程的虚拟地址空间分割成小的固定大小的页，同时将物理内存分割成与页大小相同的块。这样，操作系统可以根据需要进行页面调度，将进程所需的虚拟页加载到物理内存中，并保持合理的内存利用率。</li>
<li>3.<strong>内存保护</strong>：页表中可以记录访问权限和保护位等信息，用于控制进程对内存的访问权限。通过页表，操作系统可以实现内存的保护，确保进程<strong>只能访问到其所拥有的内存空间</strong>，防止越界访问和非法操作。</li>
<li>4.<strong>虚拟化技术支持</strong>：在虚拟化环境下，页表可以实现虚拟机对物理内存的访问和管理。虚拟机监控程序（Hypervisor）会维护独立的页表，将<strong>虚拟机的虚拟地址转换为物理地址</strong>，隔离不同虚拟机之间的内存空间。</li>
</ul>
<h3 id="30-操作系统的缺页中断是什么？"><a href="#30-操作系统的缺页中断是什么？" class="headerlink" title="30.操作系统的缺页中断是什么？"></a>30.操作系统的缺页中断是什么？</h3><p><strong>缺页异常</strong>：malloc和mmap函数在分配内存时只是建立了进程虚拟地址空间，并没有分配虚拟内存对应的物理内存。当<strong>进程访问这些没有建立映射关系的虚拟内存</strong>时，处理器自动触发一个缺页异常，引发缺页中断。<br><strong>缺页中断</strong>（Page Fault）：当程序访问的页不在物理内存中时发生的一种中断机制。当程序需要访问一个虚拟页，但<strong>该页当前不在物理内存中</strong>时，CPU会触发一个缺页中断，将控制权交给操作系统。</p>
<h3 id="31-虚拟内存的好处？"><a href="#31-虚拟内存的好处？" class="headerlink" title="31.虚拟内存的好处？"></a>31.虚拟内存的好处？</h3><ul>
<li>1.<strong>扩展内存容量</strong>：虚拟内存允许进程访问超过物理内存容量的虚拟地址空间。当物理内存不足以容纳所有进程的数据时，操作系统可以将不常用的页面置换到磁盘上，从而释放物理内存空间给其他进程使用。</li>
<li>2.<strong>内存隔离</strong>：每个进程都有独立的虚拟地址空间，使得不同进程之间的内存彼此隔离，互不干扰。这提高了系统的安全性和稳定性，一个进程的错误不会影响其他进程。</li>
<li>3.<strong>简化程序设计</strong>：虚拟内存使得程序设计人员可以将内存视为连续的地址空间，而<strong>不需要关注物理内存的限制和分配</strong>。程序可以使用大量的虚拟内存，而不必担心物理内存的实际大小。可以举一下裸机的例子。</li>
<li>4.<strong>提高性能</strong>：虚拟内存通过提供更大的地址空间和内存管理机制，可以提高系统的性能。它允许操作系统将常用的页面保留在物理内存中，减少了磁盘访问次数，提高了访问速度。</li>
</ul>
<h3 id="32-虚拟地址到物理地址的映射方法？"><a href="#32-虚拟地址到物理地址的映射方法？" class="headerlink" title="32.虚拟地址到物理地址的映射方法？"></a>32.虚拟地址到物理地址的映射方法？</h3><p>虚拟地址到物理地址的映射是通过<strong>页表</strong>来实现的。页表是一种数据结构，记录了虚拟页和物理页之间的映射关系。</p>
<h4 id="整体过程"><a href="#整体过程" class="headerlink" title="整体过程"></a>整体过程</h4><ol>
<li>程序生成虚拟地址。</li>
<li>虚拟地址由两部分组成：页表索引和页内偏移。页表索引用于在页表中查找对应的页表项。</li>
<li>操作系统根据进程的页表找到对应的页表项。</li>
<li>页表项中包含了物理页的地址信息。</li>
<li>操作系统将虚拟页的高位替换为物理页的高位，形成物理地址的高位部分。</li>
<li>将物理地址的高位部分与虚拟地址的低位部分（页内偏移）组合，得到最终的物理地址。</li>
</ol>
<p>每一个32位的线性地址被划分为三部分：<strong>页目录索引（10位）、页表索引（10位）、页内偏移（12位）</strong></p>
<ul>
<li>页目录表：使用虚拟地址的高10位作为索引，从页目录表中找到页表的物理地址。</li>
<li>页表：使用虚拟地址的中间10位作为索引，从页表中找到实际页帧的物理地址。</li>
<li>物理地址：将页帧地址和虚拟地址的低12位（页内偏移量）组合，形成最终的物理地址。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240725223417.png"></p>
<h3 id="33-中断和异常的区别"><a href="#33-中断和异常的区别" class="headerlink" title="33.中断和异常的区别"></a>33.中断和异常的区别</h3><p>1.触发方式</p>
<ul>
<li>中断：由<strong>外部设备或其他特殊事件</strong>触发，如外部设备请求处理器的服务或时钟中断。</li>
<li>异常：由<strong>当前执行的指令</strong>引发，表示当前指令无法正常执行或发生了错误，如除零错误、越界访问、非法指令等。</li>
</ul>
<p>2.异步性：同步异常与异步异常（中断）</p>
<ul>
<li>中断：是异步事件，与当前程序的执行无关，可以在任何时刻发生。</li>
<li>异常：是同步事件，由当前执行的指令引发，与当前程序的执行步骤相关。</li>
</ul>
<p>3.类型</p>
<ul>
<li>中断：中断没有明确的类型，但可以根据中断源进行分类，如外部设备中断、时钟中断等。</li>
<li>异常：异常可以分为故障（Fault）、陷阱（Trap）和终止（Abort）三种类型。故障表示可以被修复的异常，陷阱用于实现系统调用和调试功能，终止表示无法恢复的异常。</li>
</ul>
<p>4.优先级</p>
<ul>
<li>中断：中断没有明确的类型，但可以根据中断源进行分类，如外部设备中断、时钟中断等。</li>
<li>异常：异常可以分为故障（Fault）、陷阱（Trap）和终止（Abort）三种类型。故障表示可以被修复的异常，陷阱用于实现系统调用和调试功能，终止表示无法恢复的异常。</li>
</ul>
<p><em><strong>异常详解</strong></em><br>异常（Exception）是指在程序执行过程中发生的预期外或意外的事件，需要由硬件或操作系统进行处理。</p>
<ul>
<li><p>陷阱（Trap）：<br>定义：陷阱是一种可恢复的异常，通常由系统调用引发。陷阱异常发生后，控制权会立即转移到操作系统的处理程序，并在处理完成后返回到程序的<strong>下一个指令</strong>。<br>用途：常用于<strong>系统调用和调试</strong>，read&#x2F;write。陷阱允许程序通过异常机制向操作系统发出服务请求。</p>
</li>
<li><p>故障（Fault）：<br>定义：故障是一种可恢复的异常，在异常处理完成后，程序可以重新执行导致异常的指令。通常，故障是由某些指令在执行时发生问题引起的，但这些问题可能在处理后解决。<br>用途：常用于<strong>内存保护和分页机制</strong>。故障通常用于纠正条件并允许指令重新执行。</p>
</li>
<li><p>终止（Abort）：<br>定义：<strong>终止是一种不可恢复的异常</strong>，通常由严重的硬件故障或致命的系统错误引发。在发生终止时，程序无法继续执行，通常操作系统会终止程序或系统重启。<br>用途：用于处理致命错误，通常无法通过软件修复。</p>
</li>
</ul>
<h3 id="34-操作系统的文件访问方式有哪些？"><a href="#34-操作系统的文件访问方式有哪些？" class="headerlink" title="34.操作系统的文件访问方式有哪些？"></a>34.操作系统的文件访问方式有哪些？</h3><p>顺序访问，随机访问，直接访问。<br>1.<strong>顺序访问</strong></p>
<ul>
<li>顺序访问是按照数据在文件中的顺序进行访问的方式。</li>
<li>读取数据时，必须从文件的开头开始，依次读取每个数据项，直到达到目标位置。</li>
<li>写入数据时，新的数据将追加到文件的末尾。</li>
<li>顺序访问适用于顺序处理数据的场景，如<strong>读取日志文件或批量处理数据</strong>。</li>
</ul>
<p>2.<strong>随机访问</strong></p>
<ul>
<li>随机访问允许根据数据在文件中的位置进行直接访问。</li>
<li>读取数据时，可以通过指定数据在文件中的位置或偏移量来读取特定位置的数据。</li>
<li>写入数据时，可以将数据直接写入文件的指定位置。</li>
<li>随机访问适用于需要&#x3D;&#x3D;快速访问文件中特定位置的数据的场景&#x3D;&#x3D;，如数据库系统或索引文件。</li>
</ul>
<p>3.<strong>直接访问</strong></p>
<ul>
<li>直接访问允许通过记录的&#x3D;&#x3D;标识符（如文件中的记录号）直接访问文件中的数据&#x3D;&#x3D;。</li>
<li>读取数据时，可以通过记录的标识符来定位和读取特定记录的数据。</li>
<li>写入数据时，可以将数据直接写入文件中指定记录的位置。</li>
<li>直接访问适用于需要根据记录标识符快速访问文件中数据的场景，如数据库系统或索引文件。</li>
</ul>
<p>顺序访问和直接访问的区别就像是链表和数组的区别，顺序访问是锁定只能顺序一步一步走下来，而直接访问可以通过索引一步到位。</p>
<h3 id="35-内核态与用户态的区别"><a href="#35-内核态与用户态的区别" class="headerlink" title="35.内核态与用户态的区别"></a>35.内核态与用户态的区别</h3><p>1.权限：内核态拥有最高的权限，可以访问和执行所有的系统指令和资源，而用户态的权限相对较低，只能访问受限的指令和资源。内核态能够执行特权指令，如修改内存映射、管理硬件设备等，而用户态不能直接执行这些特权指令。</p>
<p>2.安全性：由于内核态具有较高的权限，错误的操作或滥用权限可能会导致系统崩溃或不安全。为了保护系统的稳定性和安全性，将操作系统的核心部分放在内核态下运行，限制用户态的权限。</p>
<p>3.进入内核态的方式：进入内核态有三种方式，分别是&#x3D;&#x3D;系统调用、异常和设备中断&#x3D;&#x3D;。系统调用是应用程序主动向内核请求服务的方式；异常是由应用程序中的错误或异常情况触发的，如非法指令、内存访问越界等；设备中断是外部设备产生的中断信号，需要内核处理。</p>
<h3 id="36-Linux内核组成"><a href="#36-Linux内核组成" class="headerlink" title="36.Linux内核组成"></a>36.Linux内核组成</h3><p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240806222720.png"></p>
<ul>
<li><strong>进程管理</strong>：负责创建、管理和调度进程，包括进程的创建、销毁和调度等功能。</li>
<li><strong>内存管理</strong>：负责管理内存资源，包括物理内存的分配与释放、虚拟内存的映射与管理等。</li>
<li><strong>文件系统</strong>：提供对存储设备和文件的访问接口，支持各种文件系统格式。</li>
<li><strong>设备驱动</strong>：提供对硬件设备的抽象和控制接口，支持各种设备驱动程序。</li>
<li><strong>网络协议栈</strong>：实现了各种网络协议，提供网络通信的功能。</li>
<li><strong>系统调用</strong>：提供用户空间程序与内核之间的接口，允许应用程序调用内核提供的功能和服务。</li>
</ul>
<h3 id="37-系统调用read-x2F-write-，内核具体作了哪些事情"><a href="#37-系统调用read-x2F-write-，内核具体作了哪些事情" class="headerlink" title="37.系统调用read()&#x2F;write()，内核具体作了哪些事情"></a>37.系统调用read()&#x2F;write()，内核具体作了哪些事情</h3><ul>
<li>用户程序将相关参数（如文件描述符、缓冲区地址和大小等）<strong>传递给read()或write()函数</strong>。</li>
<li>内核通过系统调用接口获取用户程序的请求，并验证参数的有效性。内核根据文件描述符查找对应的<strong>文件控制块</strong>（File Control Block，FCB），确定读取或写入的文件对象。通过inode找到存放在磁盘上的文件位置，其中也要验证权限是否足够，并且将文件内容复制到内存上，当页缓存有时则直接进行下面的内存读取工作，当页缓存中不存在时则读取到内存页中。</li>
<li>如果是读操作（read()），就将数据从也缓存或内存页复制到用户的缓冲区上</li>
<li>读写完成后，内核返回结果给用户程序。如果成功，返回读取&#x2F;写入的字节数；如果失败，则返回错误码。</li>
</ul>
<h3 id="38-NAND-FLASH和SRAM、DRAM的区别"><a href="#38-NAND-FLASH和SRAM、DRAM的区别" class="headerlink" title="38.NAND FLASH和SRAM、DRAM的区别"></a>38.NAND FLASH和SRAM、DRAM的区别</h3><ul>
<li>易失性存储分成 DRAM 和 SRAM。<br>SRAM 更快但价格更贵，所以主存储器多用 DRAM、快取多用 SRAM。</li>
<li>非易失性存储分成 ROM 和 Flash。主要用来作为硬盘。<br>Flash 又分成 NOR Flash 与 NAND Flash，现在硬盘多以 NAND Flash 构成的 SSD 为主。</li>
</ul>
<p><em><strong>NANDFlash不支持本地执行？</strong></em><br>“本地执行”通常指的是存储器中存储的数据直接在存储设备上执行，而无需将<strong>数据先传输到处理器或系统的主存储器</strong>中。在实践中，这意味着如果要在嵌入式设备上执行存储在 NAND Flash 中的程序，首先需要将这些程序从 NAND Flash 读取到 <strong>RAM</strong> 中，然后再由处理器执行。这也是为什么 NAND Flash 更适合作为数据存储设备，而不是直接作为执行程序的存储器的原因。</p>
<p><em><strong>RAM和cache的关系</strong></em></p>
<ul>
<li>功能：RAM 是计算机的主存储器，负责存储当前正在运行的程序和正在处理的数据。Cache 用于存储处理器经常访问的数据或指令，以减少处理器从 RAM 中读取数据的时间。</li>
<li>速度：RAM速度较快，但是和cache相比还是差的很多，cache距离处理器非常近，因此是速度最快的存储器之一</li>
<li>大小：RAM: RAM 的容量相对较大，通常在几 GB 到几十 GB 之间。Cache: Cache 的容量相对较小，通常只有几 KB 到几 MB。</li>
<li>层级：RAM: RAM 是计算机内存层级结构中的主存，位于硬盘（或其他非易失性存储器）之上，Cache 之下。Cache: Cache 通常分为多个层级（如 L1, L2, L3），L1 Cache 离处理器最近，速度最快，但容量最小；L3 Cache 离处理器较远，速度稍慢，但容量较大。Cache 位于 RAM 和处理器之间，充当桥梁角色。</li>
</ul>
<h3 id="39-进程终止的状态变化"><a href="#39-进程终止的状态变化" class="headerlink" title="39.进程终止的状态变化"></a>39.进程终止的状态变化</h3><p><strong>1.资源释放</strong>：</p>
<ul>
<li>在进程终止后，操作系统会自动释放与该进程相关联的大部分资源，如打开的文件描述符、内存空间、内核对象等。</li>
<li>但进程的进程控制块（PCB）不会&#x3D;&#x3D;立即释放&#x3D;&#x3D;，它会保留在进程表中，直到&#x3D;&#x3D;其父进程读取了退出状态&#x3D;&#x3D;。</li>
</ul>
<p><strong>2.僵尸态</strong>：</p>
<ul>
<li>僵尸态是一种过渡状态，进程已经结束运行，但进程的条目仍然保留在进程表中。保留的主要目的是让父进程可以通过 wait() 或 waitpid() 系统调用获取子进程的退出状态。</li>
<li>僵尸态的进程占用的资源很少，但如果父进程不及时调用 wait() 系统调用，系统中的僵尸进程数量可能会增加，最终耗尽系统的进程表项。</li>
</ul>
<p><strong>3.清理僵尸进程</strong>：</p>
<ul>
<li>当父进程调用 wait() 或 waitpid() 并获取了子进程的退出状态后，僵尸态进程的进程表项将被移除，资源彻底释放。</li>
<li>如果父进程终止，且未获取子进程的退出状态，子进程将被 init 进程（PID 1）收养，<strong>init 会定期调用 wait() 来清理僵尸进程</strong>。</li>
</ul>
<h3 id="40-什么是页表与页表的作用"><a href="#40-什么是页表与页表的作用" class="headerlink" title="40. 什么是页表与页表的作用"></a>40. 什么是页表与页表的作用</h3><p>页表是用来转换物理地址与虚拟的地址的数据结构。作用：内存非连续分区分配的基础，实现逻辑地址转换成物理地址。<br>MMU（Memory Management Unit）内存管理单元，就是分页用于管理转换表的管理单元。</p>
<h3 id="41-交换空间"><a href="#41-交换空间" class="headerlink" title="41.交换空间"></a>41.交换空间</h3><p>操作系统把物理内存(physical RAM)分成一块一块的小内存，每一块内存被称为页(page)。当内存资源不足时，Linux把<strong>某些页的内容转移至硬盘上的一块空间上</strong>，以释放内存空间。硬盘上的那块空间叫做交换空间(swap space),而这一过程被称为交换(swapping)。物理内存和交换空间的总容量就是虚拟内存的可用容量。</p>
<h3 id="42-缓冲区和缓存是一个东西吗？"><a href="#42-缓冲区和缓存是一个东西吗？" class="headerlink" title="42.缓冲区和缓存是一个东西吗？"></a>42.缓冲区和缓存是一个东西吗？</h3><p>答：根本不是一个东西。</p>
<ul>
<li><p><strong>1.1 缓冲区（Buffer）：</strong> 它是内存空间的一部分。也就是说，在内存空间中预留了一定的存储空间，这些存储空间用来缓冲输入或输出的数据，这部分预留的空间就叫做缓冲区，显然缓冲区是具有一定大小的。<br>有时候，从键盘输入的内容，或者将要输出到显示器上的内容，会暂时进入缓冲区，待时机成熟，再一股脑将缓冲区中的所有内容“倒出”，我们才能看到变量的值被刷新，或者屏幕产生变化。<br><strong>总结：</strong> 缓冲区就是一块内存区，它用在输入输出设备和CPU之间，用来存储数据。它使得低速的输入输出设备和高速的CPU能够协调工作，避免低速的输入输出设备占用CPU，解放出CPU，使其能够高效率工作，同时减少操作硬件的次数。<br><strong>1.2 缓冲区的好处</strong> ：<br>读取与写入硬盘速度非常缓慢，使用缓冲区可以减少写入的次数，一起再写入，节省时间。<br><strong>1.3 缓冲的类型：</strong><br>全缓冲：在这种情况下，当填满标准I&#x2F;O缓存后才进行实际I&#x2F;O操作，即一定大小的缓冲区填满后。<strong>举例</strong> ：全缓冲的典型代表是对磁盘文件的读写。<br>行缓冲：在遇到换行符之后再进行输入输出。<strong>举例</strong> ：按下回车键换行时才进行实际的I&#x2F;O操作。行缓冲的典型代表就是标准输入设备（也即键盘）和标准输出设备（也即显示器）。<br>不带缓冲： 不进行缓冲操作，类似C语言的getch</p>
</li>
<li><p><strong>2. 缓存（cache）：</strong> CPU的Cache，它中文名称是高速缓冲存储器，读写速度很快，几乎与CPU一样。由于CPU的运算速度太快，内存的数据存取速度无法跟上CPU的速度，所以在CPU与内存间设置了Cache为CPU的数据快取区。当计算机执行程序时，数据与地址管理部件会预测可能要用到的数据和指令，并将这些数据和指令预先从内存中读出送到Cache。</p>
</li>
<li><p><strong>主要区别：</strong> Buffer的核心作用是用来缓冲，缓和冲击。比如你每秒要写100次硬盘，对系统冲击很大，浪费了大量时间在<strong>忙着处理开始写和结束写</strong>这两件事嘛。用个buffer暂存起来，变成每10秒写一次硬盘，对系统的冲击就很小，写入效率就高了，并极大缓和了冲击。<br>Cache的核心作用是加快取用的速度。比如你一个很复杂的计算做完了，下次还要用结果，就把结果放手边一个好拿的地方存着，<strong>下次不用再算了</strong>。加快了数据取用的速度。<br>一个是为了保证向系统写的效率，一个是为了保证数据提取效率，目的完全不同。</p>
</li>
</ul>
<h3 id="43-为什么Linux一定要用虚拟地址？"><a href="#43-为什么Linux一定要用虚拟地址？" class="headerlink" title="43.为什么Linux一定要用虚拟地址？"></a>43.为什么Linux一定要用虚拟地址？</h3><p>为了提供更高效的内存管理以及更好的系统性能。</p>
<ul>
<li>1.地址空间隔离： 虚拟地址提供了地址空间的隔离，使得<strong>每个进程</strong>都可以拥有自己独立的地址空间。这意味着每个进程可以访问自己的虚拟地址空间，而不会影响其他进程的地址空间。这种隔离性有助于增强系统的安全性和稳定性。</li>
<li>2.内存保护： 虚拟地址使得操作系统能够实现内存<strong>保护机制</strong>。通过使用页表和内存管理单元（MMU），<font style ="color:red">操作系统可以控制进程对内存的访问权限</font>，例如只读、读写或不可访问等，从而保护系统免受恶意或错误的访问。</li>
<li>3.内存管理： 虚拟地址使得操作系统可以更灵活地管理内存。操作系统可以通过虚拟内存管理技术，将物理内存映射到不同进程的虚拟地址空间中，从而实现进程间的共享内存、内存回收、内存分配等功能。</li>
<li>4.地址重定位： 虚拟地址允许操作系统对进程的内存访问进行重定向。例如，操作系统可以将进程的虚拟地址映射到不同的物理地址，以<strong>实现内存压缩、内存共享或者动态内存分配</strong>等功能。</li>
<li>5.便于移植性： 使用虚拟地址可以<strong>使得操作系统更容易地移植到不同的硬件平台上</strong>。<strong>虚拟地址屏蔽了底层硬件</strong>的差异，使得操作系统能够以统一的方式管理内存，从而提高了操作系统的可移植性。</li>
</ul>
<h3 id="44-子进程与父进程的结束问题"><a href="#44-子进程与父进程的结束问题" class="headerlink" title="44.子进程与父进程的结束问题"></a>44.子进程与父进程的结束问题</h3><ul>
<li>1.子进程如果提前与父进程结束，那么父进程会自己继续执行到结束。<strong>注意</strong>:最好父进程要在合适的地方放一些wait()或者waitpid()函数来等待子进程的结束，如果没有父进程就只能在结束的时候读取子进程状态了，也就存在了一个僵尸进程。</li>
<li>2.父进程提前结束，会给孤儿进程找一个继父</li>
</ul>
<h3 id="45-僵尸状态"><a href="#45-僵尸状态" class="headerlink" title="45.僵尸状态"></a>45.僵尸状态</h3><p>僵尸状态-Z（zombie）:当一个进程将要退出的时候，操作系统OS不会立即释放该进程的资源，会等一段时间，让父进程或者操作系统读取子进程的返回结果（即退出码），没有读取到子进程退出的返回代码就会产生僵尸进程。僵尸进程会以终止状态保持在进程表中，并且会一直在等待父进程读取退出状态代码。所以，只要子进程退出，父进程还在运行，但<strong>父进程没有读取子进程状态</strong>，子进程就进入僵尸状态-Z。</p>
<h3 id="46-僵尸进程的危害"><a href="#46-僵尸进程的危害" class="headerlink" title="46.僵尸进程的危害"></a>46.僵尸进程的危害</h3><ul>
<li>1.僵尸进程的退出状态必须要被维持下去，因为它要告诉关心它的进程（父进程），你交给我的任务，我办的怎么样了。可父进程如果一直不读取，那么子进程就会一直处于僵尸Z状态。</li>
<li>2.维护退出状态要用数据维护，这也属于进程基本信息，所以僵尸进程的退出信息保存在task_stuct（PCB）中，如果父进程一直不读取子进程退出结果，那么Z状态一直不退出，PCB就要一直被维护。</li>
<li>3.如果一个父进程创建了很多子进程，但是都没有进行回收，那么就会造成内存资源的浪费，因为数据结构对象（task_stuct）本省就要占用内存，如果不进行回收，那当然就会造成内存泄漏这样严重的问题。</li>
</ul>
<h3 id="47-工作队列是什么？"><a href="#47-工作队列是什么？" class="headerlink" title="47.工作队列是什么？"></a>47.工作队列是什么？</h3><p>工作队列（Workqueue）是 Linux 内核中一种用于延迟执行任务的机制。它允许将一些需要在内核上下文中执行的&#x3D;&#x3D;任务推迟到稍后在内核线程中执行&#x3D;&#x3D;，而不是在中断上下文或其他紧急上下文中立即执行。<strong>工作队列允许内核将一些工作推迟到稍后的时间，由内核线程来处理</strong>。这种处理方式是通过调度一个内核线程来执行具体任务的，从而避免在中断上下文中执行长时间的任务，减少了中断处理时间。（自己不处理丢给一个内核线程来处理）</p>
<p><em><strong>中断处理的两部分</strong></em></p>
<ul>
<li><p>上半部（Top Half）：<br>这是中断处理的第一部分，也称为快速中断处理。上半部通常只处理非常紧急和重要的任务，如读取<strong>硬件寄存器、清除中断标志位、基本数据采集</strong>等。</p>
</li>
<li><p>下半部：<br>特点：上半部完成后，将较为复杂、耗时的工作推迟到下半部进行处理。下半部可以在中断处理完成后，在合适的时间点以非中断上下文运行。</p>
</li>
</ul>
<p><strong>应用场景</strong>：<br>USB驱动：</p>
<ul>
<li>上半部：当 USB 设备插入或拔出时，硬件会产生中断，上半部会立即响应，快速检查设备状态并更新设备的基本信息。</li>
<li>下半部：完成复杂的设备初始化、驱动程序加载等任务。</li>
</ul>
<p>注意这里有一个误解：不能简单地认为触发中断是上半部的工作，而中断处理函数是下半部的工作。实际上，触发中断是中断机制的开始，而中断处理函数包括了上半部和下半部的实际处理逻辑。也就是说上半部和下半部的概念是针对中断处理函数而言的。</p>
<p><em><strong>linux中断类型</strong></em><br>中断可以分为两大类：硬件中断与软件中断。<br><strong>硬件中断</strong>：硬件中断是由<strong>外部硬件设备触发的中断</strong>，通常用于通知 CPU 某个硬件事件的发生，比如键盘输入、网络数据到达、定时器事件等。硬件中断又可以进一步细分为以下几种：</p>
<ul>
<li>边沿触发中断：这种中断在信号电平发生变化时触发</li>
<li>电平触发中断：这种中断在信号保持某种电平时会持续触发</li>
</ul>
<p><strong>软件中断</strong>：软件中断是由程序代码触发的中断。通常用于内核态和用户态之间的通信，比如系统调用或调度操作等。软件中断主要包括以下几种类型：</p>
<ul>
<li>系统调用：用户态程序通过系统调用来请求内核服务（例如文件读写、内存管理、进程控制等）。系统调用实际上是软中断的一种实现方式，将用户态的请求转到内核态处理。</li>
<li>异常：这是由 CPU 执行指令时遇到的异常情况而触发的中断，比如除零错误、缺页错误、非法指令等。异常有时被称为陷阱（Trap），它们可以是同步的（发生在某个指令执行时）或者异步的。异常通常用于处理程序运行时的错误或异常情况，并进行适当的处理（如生成段错误信号）。</li>
<li>内核调度中断：这是用于进程调度的软中断。在内核中，当某个进程的时间片用完时，调度器会触发一次软中断以便切换到另一个进程。<br>如果是软件中断整体流程如下：</li>
<li>用户态触发系统调用</li>
<li>切换到内核态：当系统调用指令被执行时，CPU 会从用户态切换到内核态，并查找中断向量表。对于系统调用触发的中断，内核会找到对应的中断处理程序入口点，这个入口点会引导系统进入<strong>系统调用处理</strong>流程。</li>
<li>调用系统调用处理程序：在进入内核态后，中断服务程序会根据系统调用号（system call number）来确定具体需要执行的内核功能。内核根据这个系统调用号查找一个<strong>系统调用表</strong>（sys_call_table），这个表中存储了每个系统调用对应的处理函数。找到对应的系统调用处理函数后，内核就会执行该函数。</li>
</ul>
<p><em><strong>使用场景：</strong></em></p>
<ul>
<li><strong>延迟执行</strong>：某些任务不需要在中断处理程序中立即完成，可以安全地推迟执行。例如，网络数据包的进一步处理、磁盘数据的读写等。</li>
<li><strong>上下文切换</strong>：某些操作需要在内核线程上下文中执行，而不能在中断上下文中执行，例如内存分配、阻塞操作等。</li>
<li><strong>减少中断延迟</strong>：通过将复杂任务推迟到工作队列中执行，可以减少中断处理程序的执行时间，提高系统的中断响应能力。</li>
</ul>
<h3 id="48-什么是操作系统的抽象层？它的作用是什么？"><a href="#48-什么是操作系统的抽象层？它的作用是什么？" class="headerlink" title="48. 什么是操作系统的抽象层？它的作用是什么？"></a>48. 什么是操作系统的抽象层？它的作用是什么？</h3><p>操作系统的抽象层是用于隔离硬件和软件的中间层，它提供了<strong>一组统一的接口，使得应用程序和系统服务可以在不直接与底层硬件交互的情况下完成工作</strong>。操作系统通过这些抽象层隐藏了硬件的复杂性，例如 CPU、内存、存储设备等，使得开发者可以专注于更高层次的功能开发。</p>
<p>抽象层的主要作用包括：</p>
<ul>
<li>1.<strong>简化开发</strong>：通过提供标准化的接口，开发者可以在不考虑硬件差异的情况下编写代码。例如，文件系统抽象层允许开发者以统一的方式读取和写入文件，而不必关心底层的存储介质是硬盘、固态硬盘还是网络存储。</li>
<li>2.<strong>增强可移植性</strong>：由于抽象层隐藏了硬件的细节，应用程序可以在不同的硬件平台上运行而无需修改。例如，使用 POSIX 标准的操作系统可以在多种硬件平台上移植和运行。</li>
<li>3.<strong>提供资源管理和安全性</strong>：抽象层不仅简化了硬件交互，还允许操作系统管理和保护硬件资源。例如，内存管理抽象层确保不同进程不会互相干扰，并且可以安全地访问系统内存。</li>
</ul>
<h3 id="49-同步和异步"><a href="#49-同步和异步" class="headerlink" title="49.同步和异步"></a>49.同步和异步</h3><p>同步和异步是两种用于管理多线程与多进程环境下的资源访问机制。</p>
<p><strong>同步</strong>：是指在多线程或多进程环境中，协调它们的执行顺序，以确保共享资源或数据按照正确的顺序被访问。同步的主要目的是避免竞争条件（race conditions），确保<strong>数据一致性</strong>。例如，在生产者-消费者模型中，生产者线程需要在消费者线程之前将数据放入缓冲区，这种顺序就是通过同步来保证的。</p>
<p><strong>异步</strong>：同步的一种具体实现方式，它确保在某一时刻只有一个线程或进程可以访问某个共享资源或临界区。互斥通常通过锁机制来实现，比如互斥锁（mutex）。当一个线程持有互斥锁时，其他线程无法进入该临界区，必须等待该线程释放锁。这样，互斥可以有效防止多个线程同时修改共享数据导致的冲突。</p>
<h3 id="50-什么是进程的优先级反转？如何解决？"><a href="#50-什么是进程的优先级反转？如何解决？" class="headerlink" title="50.什么是进程的优先级反转？如何解决？"></a>50.什么是进程的优先级反转？如何解决？</h3><p>这道题真的是完全没听说过了赶紧学习一下！<br><strong>进程的优先级反转</strong>是指在多任务操作系统中，低优先级的任务占有某一共享资源（例如互斥锁），而高优先级的任务需要等待这个资源释放才能继续执行，这导致了高优先级任务被阻塞。此时，如果一个中等优先级的任务开始执行，它可能会先于低优先级任务执行完毕，从而进一步推迟了高优先级任务的执行。这种情况就被称为优先级反转。<br>解决优先级翻转的方法：</p>
<ul>
<li><strong>优先级继承</strong>：提升任务等级<br>当低优先级任务持有某个高优先级任务所需的资源时，操作系统暂时将低优先级任务的优先级提升至与高优先级任务相同，以减少优先级反转的影响。当资源被释放后，低优先级任务的优先级恢复原状。</li>
<li><strong>优先级上线协议</strong>：提升共享资源优先级<br>优先级上限协议（Priority Ceiling Protocol）：为每个共享资源设置一个优先级上限，当某个任务锁住这个资源时，其优先级被自动提高到这个上限，从而防止其他中等优先级的任务抢占执行。</li>
</ul>
<p><em><strong>为什么这个不是掩耳盗铃：</strong></em><br>低优先级任务在优先级继承机制下会被临时提升，但这种设计的目的是服务于高优先级任务，保证它尽可能快地获取所需资源并执行完毕。如果没有优先级继承，可能会出现一种情况：中等优先级任务持续占用 CPU，导致高优先级任务一直被阻塞，最终影响整个系统的实时性能。因此，优先级继承是在一定程度上牺牲了低优先级任务的顺序性，换取了高优先级任务的实时性。</p>
<p><em><strong>总结</strong></em><br>这个机制其实是为了让低优先级的任务尽快结束，将资源释放出来。</p>
<h3 id="51-操作系统如何处理内存碎片？"><a href="#51-操作系统如何处理内存碎片？" class="headerlink" title="51.操作系统如何处理内存碎片？"></a>51.操作系统如何处理内存碎片？</h3><p>内存碎片是指由于内存分配和释放过程中的不连续性，导致内存空间无法被有效利用。内存碎片主要分为两类：</p>
<ul>
<li><strong>内部碎片</strong>：这是由于分配的内存块比实际使用的内存块大，从而在每个分配单元内产生了一些未使用的空间。例如，某个程序申请了一个64字节的内存块，但内存管理系统<strong>只能按128字节的单位分配</strong>，因此会有64字节的内部碎片。</li>
<li><strong>外部碎片</strong>：是指内存中虽然有足够的总空间来满足内存分配请求，但这些空间被分散在不同的内存块中，无法提供连续的内存块，导致无法满足请求。例如，<strong>当多个小程序释放内存后，留下零散的小块内存</strong>，但无法满足需要大块连续内存的程序的需求。</li>
</ul>
<p>如何处理内存碎片：</p>
<ul>
<li>1.<strong>紧凑化</strong>：操作系统通过将分散的内存块移动到一起，将空闲内存集中起来，形成一个大块的连续内存空间。这种方法主要用于处理外部碎片，但它需要较大的计算开销，因为涉及数据的移动和地址的更新。</li>
<li>2.<strong>内存池</strong>：操作系统或应用程序可以使用预先分配好的内存池来减少碎片。内存池通过管理固定大小的内存块，减少内部碎片的产生。</li>
<li>3.分页：通过将内存划分为固定大小的页和页框来消除外部碎片</li>
<li>4.分段：分段是一种内存管理方式，将程序的内存空间划分为逻辑段，每个段代表一个特定的用途（如代码段、数据段、堆栈段等）。</li>
</ul>
<h3 id="52-解释一下操作系统中的信号机制"><a href="#52-解释一下操作系统中的信号机制" class="headerlink" title="52.解释一下操作系统中的信号机制"></a>52.解释一下操作系统中的信号机制</h3><p>1.信号定义：信号是一种用于通知进程发生某种特定事件的简短消息。每个信号都有一个唯一的整数标识符（例如，SIGINT、SIGKILL），表示不同的事件类型。<br>2.信号类型：</p>
<ul>
<li>标准信号：<ul>
<li>SIGINT：由键盘产生的中断信号，通常由 Ctrl+C 触发。</li>
<li>SIGKILL：强制终止进程的信号，无法被捕获或忽略。</li>
<li>SIGTERM：请求终止进程的信号，可以被捕获或忽略，用于请求- 进程正常退出。</li>
<li>SIGSEGV：段错误信号，当进程非法访问内存时产生。<br>3.基本操作：</li>
</ul>
</li>
<li>1.发送信号：<ul>
<li>kill可以向一个或多个进程发送信号</li>
<li>某些硬件事件（如按键、中断）会由内核产生信号。</li>
</ul>
</li>
</ul>
<p>信号是 Unix&#x2F;Linux 操作系统中重要的进程控制工具，通过信号，系统和用户可以异步地控制进程的执行。</p>
<h3 id="53-什么是系统调用栈？它的作用是什么？"><a href="#53-什么是系统调用栈？它的作用是什么？" class="headerlink" title="53.什么是系统调用栈？它的作用是什么？"></a>53.什么是系统调用栈？它的作用是什么？</h3><p>系统调用栈（System Call Stack）是操作系统内核在处理系统调用时用于管理函数调用和局部变量的一种数据结构。它是进程的栈空间的一部分，主要用于管理在用户态和内核态之间切换时的函数调用、参数传递、返回地址和局部变量等信息。</p>
<p><strong>作用</strong>：</p>
<ul>
<li>1.管理系统调用的上下文：<br>当进程从用户态通过系统调用进入内核态时，系统调用栈用于保存调用过程中的上下文信息，包括函数的返回地址、传递的参数、局部变量等。内核通过<strong>系统调用栈来管理这些信息</strong>，确保在系统调用执行完成后能够正确返回用户态继续执行。</li>
<li>2.保护用户态和内核态的隔离：<br>系统调用栈帮助维护用户态和内核态之间的隔离。用户态代码无法直接访问内核态栈，内核态栈中的数据结构和变量仅在内核态下使用。</li>
</ul>
<p><strong>工作流程</strong>：</p>
<ul>
<li>1.从用户态到内核态的切换：<ul>
<li>当进程执行系统调用时，例如调用 open()、read() 等函数，系统会触发一个中断或陷阱（Trap），进程从用户态切换到内核态。</li>
<li>在切换过程中，系统会保存当前用户态的上下文（如寄存器值、程序计数器等），并将这些信息压入内核态栈。</li>
</ul>
</li>
<li>2.系统调用处理：<ul>
<li>进入内核态后，系统调用栈用于管理内核态下的函数调用，包括系统调用的参数、局部变量以及嵌套调用的返回地址。</li>
<li>内核完成系统调用后，栈中的信息用于恢复内核态的执行环境。</li>
</ul>
</li>
<li>3.从内核态返回用户态：<ul>
<li>系统调用执行完成后，内核会将用户态的上下文信息从系统调用栈中弹出，恢复进程在用户态的执行环境。</li>
<li>最终，控制权交还给用户态进程，进程继续从系统调用返回处执行。</li>
</ul>
</li>
</ul>
<h3 id="54-用户态如何进入到内核态的"><a href="#54-用户态如何进入到内核态的" class="headerlink" title="54.用户态如何进入到内核态的"></a>54.用户态如何进入到内核态的</h3><ul>
<li>1.<strong>系统发起</strong>：<br>用户态进程调用标准库函数，如 open()、read() 等。这些库函数最终会调用一个系统调用接口，例如 syscall 指令、软中断（如 int 0x80）、或者在 x86-64 系统中通过 sysenter 或 syscall 指令。</li>
<li>2.<strong>陷入内核态</strong>：<br>系统调用的触发会导致 CPU 进入内核态。这一过程称为“陷入”（Trap），CPU 切换到内核态执行预定义的内核代码。陷入内核态后，CPU 使用内核栈来保存当前的执行上下文（如寄存器、程序计数器等）。</li>
<li>3.<strong>内核处理系统调用</strong>：<ul>
<li>内核根据系统调用号识别出请求的服务，并调用相应的内核函数来处理该请求。例如，read() 系统调用会请求内核从文件中读取数据，内核会执行文件系统代码，完成读取操作。</li>
<li>内核态的代码运行在内核的地址空间，并且可以访问所有系统资源，包括硬件设备和所有内存。</li>
</ul>
</li>
<li>4.<strong>返回用户态</strong><br>当系统调用处理完成后，内核恢复保存的用户态上下文，并通过特定的指令（如 iret 或 sysret）返回到用户态，继续执行用户进程的代码。</li>
</ul>
<h3 id="55-解释一下Linux中的守护进程"><a href="#55-解释一下Linux中的守护进程" class="headerlink" title="55.解释一下Linux中的守护进程"></a>55.解释一下Linux中的守护进程</h3><p>守护进程（Daemon）是指在&#x3D;&#x3D;后台运行&#x3D;&#x3D;、&#x3D;&#x3D;不与任何用户直接交互&#x3D;&#x3D;的进程。它们<strong>通常在系统启动时启动，并一直运行，直到系统关闭</strong>。守护进程通常用于执行系统级任务或提供某些服务，确保操作系统和应用程序的正常运行。</p>
<p><strong>典型用途</strong>：<br>系统服务：如网络服务（sshd，httpd）、打印服务（cupsd）、邮件服务（sendmail）。<br>监控任务：如监控系统日志（syslogd）、调度任务（crond）。<br>后台任务：如数据库管理（mysqld）、缓存服务（memcached）。</p>
<p><strong>创建步骤</strong>：<br>1.创建子进程并终止父进程<br>2.创建新的会话<br>3.更改工作目录<br>4.重设文件权限掩码<br>5.关闭不要的文件描述符：关闭继承自父进程的所有打开的文件描述符，如标准输入、标准输出和标准错误（通常会将它们重定向到 &#x2F;dev&#x2F;null）。</p>
<h3 id="56-如何定位死锁位置"><a href="#56-如何定位死锁位置" class="headerlink" title="56.如何定位死锁位置"></a>56.如何定位死锁位置</h3><p>使用gdb可以定位：</p>
<ul>
<li>1.先生成一个带有死锁的可执行文件</li>
<li>2.gdb .&#x2F;try1</li>
<li>3.(gdb)run 这个时候会发现，程序会卡死在一个部分</li>
<li>4.开始查找 (gdb)thread1 info，这里显示的就是会有lock_wait这种的显示<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240827200210.png"></li>
</ul>
<h3 id="57-在多线程编程中如何来保证数据的安全的"><a href="#57-在多线程编程中如何来保证数据的安全的" class="headerlink" title="57.在多线程编程中如何来保证数据的安全的"></a>57.在多线程编程中如何来保证数据的安全的</h3><p>在多线程编程中，确保线程之间的数据安全是至关重要的。线程间的数据安全通常指的是防止竞争条件、数据不一致和数据损坏的情况。</p>
<ul>
<li>1.互斥锁</li>
<li>2.读写锁</li>
<li>3.条件变量</li>
<li>4.原子操作</li>
<li>5.信号量</li>
</ul>
<h3 id="58-内存管理中的分页和分段的区别"><a href="#58-内存管理中的分页和分段的区别" class="headerlink" title="58.内存管理中的分页和分段的区别"></a>58.内存管理中的分页和分段的区别</h3><h4 id="分页："><a href="#分页：" class="headerlink" title="分页："></a>分页：</h4><p><strong>1.概念</strong></p>
<ul>
<li>1.分页是将物理内存划分为固定大小的块，称为 <strong>页框</strong>（Page Frame），同时将进程的逻辑地址空间也划分为相同大小的块，称为 <strong>页</strong>（Page）。页和页框的大小通常是相同的。</li>
<li>页表（Page Table）用来映射进程的逻辑地址（虚拟地址）到物理地址。</li>
</ul>
<p><strong>2.机制</strong>:</p>
<ul>
<li>1.当进程访问一个内存地址时，地址被拆分为两部分：页号（Page Number）和页内偏移（Offset）。</li>
<li>2.页号通过页表找到对应的页框（Page Frame），页内偏移决定具体的物理地址。</li>
<li>这样以来程序的每一页都可以映射到内存的任意页框，而不必连续。<br>只有进程有页表吗，如果想通过虚拟地址来访问物理地址不应该也是要用吗？</li>
</ul>
<h4 id="分段："><a href="#分段：" class="headerlink" title="分段："></a>分段：</h4><p><strong>1.概念</strong></p>
<ul>
<li>分段是将进程的逻辑地址空间划分为多个段（Segment），每个段表示一个逻辑单位，如代码段、数据段、堆栈段等。每个段可以有不同的大小。</li>
<li>段表（Segment Table）用来记录每个段的起始地址和长度。</li>
</ul>
<p><strong>2.机制</strong></p>
<ul>
<li>每个逻辑地址被拆分为两部分：段号（Segment Number）和段内偏移（Offset）。</li>
<li>段号通过段表找到段的起始地址，段内偏移决定具体的物理地址。<br>段与段之间可以不连续，从而允许内存的更灵活分配。</li>
</ul>
<h4 id="分页和分段的优缺点"><a href="#分页和分段的优缺点" class="headerlink" title="分页和分段的优缺点"></a>分页和分段的优缺点</h4><p><strong>分页</strong><br>优点：</p>
<ul>
<li>消除了外部碎片：由于页框大小固定，不存在因不连续分配内存而产生的外部碎片。</li>
<li>简化内存管理：页和页框大小一致</li>
</ul>
<p>缺点：</p>
<ul>
<li>内部碎片：因为页的大小固定，进程可能无法完全使用最后一页，导致内存浪费。</li>
<li>页表管理带来的开销增大：每个进程都需要维护一个页表，随着地址空间的增大，页表的大小和管理开销也会增大。</li>
</ul>
<p><strong>分段</strong><br>优点：</p>
<ul>
<li>消除了内部碎片</li>
<li>符合程序逻辑结构：: 分段反映了程序的逻辑结构（如代码段、数据段、堆栈段等），使得内存管理更直观。</li>
<li>共享和保护: 不同进程可以共享某些段（如代码段），并且可以对每个段设置不同的访问权限（如只读、可写等）。</li>
</ul>
<p>缺点：</p>
<ul>
<li>外部碎片：随着段的分配和释放，有可能会出现不连续的空闲区，也就导致了外部碎片。</li>
</ul>
<h4 id="分页和分段的结合：段页式内存管理"><a href="#分页和分段的结合：段页式内存管理" class="headerlink" title="分页和分段的结合：段页式内存管理"></a>分页和分段的结合：段页式内存管理</h4><p>在实际操作系统中，分页和分段可以结合使用，称为 <strong>段页式内存管理</strong>。具体实现如下：</p>
<ul>
<li>分段：<ul>
<li>进程的虚拟地址空间首先被划分为多个段，每个段代表程序中的一个逻辑单元（例如代码段、数据段等）。</li>
<li>每个段都有一个段基址（Segment Base Address）和段长度（Segment Length），这两个信息存储在段表（Segment Table）中。</li>
</ul>
</li>
<li>分页：<ul>
<li>每个段中的地址空间进一步划分为固定大小的页，这些页通过页表映射到物理内存中的页框。</li>
<li>分段中的每个页在段表中有对应的页表入口，页表记录了该页的物理地址映射。<br>在这种机制中，逻辑地址首先通过段表找到<strong>对应的段</strong>，再通过页表找到段中的某一页，从而计算出物理地址。这种方式结合了分页和分段的优点，但也增加了实现的复杂性。</li>
</ul>
</li>
</ul>
<h3 id="59-软链接和硬链接的区别"><a href="#59-软链接和硬链接的区别" class="headerlink" title="59.软链接和硬链接的区别"></a>59.软链接和硬链接的区别</h3><ul>
<li><p>软链接：<br>软链接，也称为符号链接，是一个独立的文件，它包含了<strong>另一个文件或目录的路径名</strong>。软连接指向目标文件的路径，而不是文件本身。软连接类似于快捷方式，可以<strong>跨文件系统和分区创建</strong>。</p>
</li>
<li><p>硬链接：<br>硬链接是指向文件数据的直接引用。多个硬链接可以指向同一个文件的数据块，并且它们在文件系统中的表现如同原始文件，所有的硬链接<strong>共享相同的inode</strong>（文件标识符）。<br>硬链接不创建新的文件，它只是为现有文件创建了一个新的入口。</p>
</li>
<li><p>应用场景：<br>软链接：常用于创建跨文件系统的快捷方式或别名。方便在不同位置访问同一个文件或目录，尤其适用于需要在多个分区或文件系统间共享文件的情况。因为只记录文件路径，所以文件系统的差异或者多个分区并不影响<br>硬链接：<br>常用于创建文件的备份，多个硬链接指向同一个数据，节省了磁盘空间。</p>
</li>
</ul>
<h3 id="60-中断中可以用锁嘛-用的是什么锁"><a href="#60-中断中可以用锁嘛-用的是什么锁" class="headerlink" title="60.中断中可以用锁嘛?用的是什么锁?"></a>60.中断中可以用锁嘛?用的是什么锁?</h3><p>在中断处理中使用锁需要格外小心，因为中断处理程序的执行时间要求非常严格。一般来说，在中断处理程序中<strong>不建议</strong>使用常规的锁机制，如互斥锁（mutex）或自旋锁（spinlock），因为它们可能会引发死锁或导致系统性能下降。</p>
<ul>
<li>自旋锁（只讨论一种情况吧&#x3D;&#x3D;）<br>自旋锁是一种可以在中断上下文中使用的锁，常用于多处理器系统中。在中断处理中使用自旋锁时，关键在于<strong>禁用中断</strong>，以避免死锁和优先级反转问题。<br><strong>原理</strong>：自旋锁的核心思想是“忙等”，即不断检查锁的状态，直到锁被释放为止。自旋锁不会引发进程上下文切换，而是通过 CPU 指令实现锁的抢占与释放。在中断上下文中，使用 irqsave 和 irqrestore 的变种是为了确保锁定过程中中断不会被触发，以避免中断处理函数<strong>再次尝试获取同一把锁引发死锁</strong>。</li>
</ul>
<p><em><strong>为什么使用互斥锁或者自旋锁可能会引发死锁呢？</strong></em></p>
<p><strong>在中断中使用互斥锁的问题</strong>：<br>无法休眠：在中断处理程序中，<strong>中断的执行上下文是不可休眠的</strong>。但是<strong>互斥锁在锁不可用时会使调用的线程进入阻塞状态</strong>，等待其他线程释放锁。中断处理程序如果尝试获取一个已经被其他进程占用的互斥锁，会进入休眠状态，这会导致系统出现严重问题，因为中断处理程序是不能休眠的，必须尽快完成。如果中断处理程序进入阻塞状态等待锁释放，而持有该锁的线程被挂起等待中断处理完成，这就会形成<strong>死锁</strong>。</p>
<p>情景：</p>
<ul>
<li>线程 A 持有一个互斥锁 mutex，并在等待某个中断完成。</li>
<li>中断处理程序 触发，但在执行时试图获取同一个互斥锁 mutex。</li>
<li>由于互斥锁已被线程 A 持有，中断处理程序进入阻塞状态。</li>
<li>然而，线程 A 也在等待中断完成，导致两者相互等待，形成<strong>死锁</strong>。</li>
</ul>
<p><strong>自旋锁导致死锁的情况</strong></p>
<p><strong>在中断中使用自旋锁的问题</strong>：<br>中断重入问题：如果一个线程已经获取了自旋锁，随后中断触发，而中断处理程序再次试图获取同一个自旋锁，可能会导致死锁。这是因为自旋锁的持有者无法释放锁，而中断处理程序也在等待该锁，这两者会产生互相等待的情况。<br><strong>情景</strong>：</p>
<ul>
<li>线程 A 获取了一个自旋锁 spinlock 并正在执行某个任务。</li>
<li>中断处理程序 触发，在执行时再次试图获取同一个自旋锁 spinlock。</li>
<li>由于线程 A 尚未释放锁，中断处理程序会一直自旋等待锁的释放。</li>
<li>由于中断处理中自旋占用 CPU 时间，线程 A 无法继续执行释放锁，导致系统进入死锁状态。</li>
</ul>
<p><strong>如何解决</strong>：使用特定版本的自旋锁<br>避免中断处理程序打断当前线程并试图获取已经被当前线程持有的自旋锁。Linux 内核提供了禁用中断的自旋锁版本：spin_lock_irqsave() 和 spin_unlock_irqrestore()。</p>
<ul>
<li>**spin_lock_irqsave()**：当线程获取自旋锁时，它会首先禁用当前 CPU 的中断，确保当前的中断处理程序不会在此时打断线程并试图获取同一个自旋锁。</li>
<li>**spin_unlock_irqrestore()**：在线程释放自旋锁时，它会恢复之前的中断状态。</li>
</ul>
<h3 id="61-对于读写锁而言读的过程需要上锁吗？"><a href="#61-对于读写锁而言读的过程需要上锁吗？" class="headerlink" title="61.对于读写锁而言读的过程需要上锁吗？"></a>61.对于读写锁而言读的过程需要上锁吗？</h3><p>在读写锁中，读操作和写操作的处理方式是不同的。<strong>读写锁</strong>允许多个线程同时<strong>进行读操作</strong>（只读共享资源），但在写操作时必须保证独占访问，即在写操作期间，不允许其他线程进行读或写操作。</p>
<p><strong>读写锁的基本概念：</strong></p>
<ul>
<li>读锁： 多个线程可以同时获取读锁，多个线程可以并发读取共享资源，但不能有写线程在写入。</li>
<li>写锁： 写操作必须是独占的，获取写锁的线程必须等待所有的读锁释放，且在持有写锁时，不能有其他读线程或写线程访问资源。</li>
</ul>
<p><strong>读操作是否需要上锁？</strong><br>需要上锁。在多线程环境下，虽然读操作本身不会修改数据，但为了避免读写冲突，仍然需要使用读锁进行保护。通过上读锁，读操作可以确保当前没有写操作正在进行，这样可以避免数据的不一致性问题。</p>
<h3 id="62-安全获取锁的方法"><a href="#62-安全获取锁的方法" class="headerlink" title="62.安全获取锁的方法"></a>62.安全获取锁的方法</h3><p>1.lock_guard:<br>自动获取并持有锁，直到函数结束。当lock超出作用域的时候会调用mtx.unlock()来释放互斥锁。</p>
<p>2.unique_lock:</p>
<ul>
<li>可以延迟获取锁</li>
<li>可以与条件变量共同使用</li>
<li>可以与条件变量一起使用</li>
</ul>
<p>3.try_lock:<br>std::try_lock 是一种非阻塞的锁获取方式，它允许尝试获取锁而不导致线程阻塞。如果锁不可用，try_lock 会立即返回而不是等待锁被释放。</p>
<p>4.shared_mutex:<br>std::shared_mutex 是一种读写锁，允许多个线程同时获取读锁，但写锁是独占的。这在读多写少的场景中非常有效。</p>
<h3 id="63-什么是嵌套中断"><a href="#63-什么是嵌套中断" class="headerlink" title="63.什么是嵌套中断"></a>63.什么是嵌套中断</h3><p>嵌套中断（Nested Interrupt）是指在处理一个中断的过程中，<strong>系统允许更高优先级的中断打断当前的中断处理</strong>，优先处理新到来的中断。当<strong>新的中断处理完成后，系统会返回到之前中断的处理继续执行</strong>。这种机制可以提高系统对高优先级中断的响应能力。<br><em><strong>嵌套中断和自旋锁</strong></em><br>为了防止自旋锁出现死锁的情况，一般会在获取自旋锁的过程中启用中断禁止，但是中断禁止后嵌套中断又无法使用了。因此，在中断嵌套中，使用自旋锁时必须小心管理锁的持有时间，并根据系统优先级设计来避免竞争。</p>
<h3 id="64-CPU常见寄存器（ARM架构）"><a href="#64-CPU常见寄存器（ARM架构）" class="headerlink" title="64.CPU常见寄存器（ARM架构）"></a>64.CPU常见寄存器（ARM架构）</h3><p>1.通用寄存器<br>通用寄存器主要用于存储数据和地址，可以灵活用于多种运算操作</p>
<ul>
<li>R0 - R12：这 13 个寄存器是<strong>通用的</strong>，存储临时数据。它们通常用于函数的参数传递、计算结果存储等。</li>
<li>R13（SP，Stack Pointer，栈指针）：<strong>栈指针寄存器</strong>，用于管理栈的操作。R13 负责指向栈顶，支持函数调用和局部变量的存储。</li>
<li>R14（LR，Link Register，<strong>链接寄存器</strong>）：保存函数调用的返回地址。当调用子函数时，当前函数的返回地址会存储在 LR 中。</li>
<li>R15（PC，Program Counter，<strong>程序计数器</strong>）：保存当前正在执行指令的地址。R15 是程序计数器，指向即将执行的指令。</li>
</ul>
<p>2.程序状态寄存器</p>
<ul>
<li>CPSR（Current Program Status Register）：<strong>当前程序状态寄存器</strong>，保存处理器的状态信息，如条件标志（负号、零、进位、溢出标志等）、中断禁用标志、处理器模式等。</li>
<li>SPSR（Saved Program Status Register）：在 ARM 的不同异常模式下，处理器会使用 SPSR 来保存<strong>异常</strong>发生时的 CPSR，以便在恢复正常模式时能够恢复原来的处理器状态。</li>
</ul>
<p>3.浮点寄存器</p>
<ul>
<li>S0 - S31：这些寄存器用于单精度和双精度浮点运算。</li>
</ul>
<p>4.寄存器模式寄存器<br>ARM 有多个处理器模式（如用户模式、系统模式、中断模式、异常模式等），其中一些模式可能有额外的寄存器映射。不同模式下，部分寄存器会被重新定义或映射。</p>
<p><em><strong>线程切换时需要保存和恢复的寄存器</strong></em></p>
<ul>
<li>1.通用寄存器</li>
<li>2.<strong>栈寄存器R13（SP）</strong></li>
<li>3.<strong>链接寄存器</strong>R14：：保存函数调用的返回地址。在任务切换时，需要保存 LR，以便在任务切换回来后能够继续执行当前函数。</li>
<li>4.<strong>程序计数器 R15（PC）</strong>：保存当前正在执行的指令地址，以便任务切换回来时从正确的位置继续执行。</li>
<li>5.<strong>当前程序状态寄存器</strong>（CPSR）：保存处理器当前的状态信息，包括标志位、处理器模式等，保证任务切换回来后处理器能够在正确的状态下运行。</li>
<li>6.浮点寄存器（S0 - S31，如果使用）：如果当前任务涉及浮点运算或启用了 VFP，则需要保存浮点寄存器的内容。</li>
</ul>
<p><em><strong>链接寄存器有什么用？</strong></em><br>链接寄存器（Link Register，简称 LR）是 ARM 架构中的一个特殊寄存器，用于存储函数调用的返回地址。在 ARM 处理器中，调用一个子函数时，调用者的返回地址会被自动保存到 LR 寄存器中，当子函数执行完毕时，可以从 LR 中<strong>获取返回地址</strong>，并跳回到调用函数继续执行。<br>当 ARM 处理器执行 BL（Branch with Link）指令时，当前指令的<strong>下一条指令地址</strong>（即调用者的返回地址）会被存储到链接寄存器 LR 中。然后跳转到子函数。当子函数执行完毕时，可以通过将 LR 中的值加载到程序计数器 PC 中，从而返回到调用者的位置继续执行。<br>一般是调用子函数，ARM调用BL指令，同时将下一条指令的地址存放到LR（链接寄存器中），跳转到函数。</p>
<h3 id="65-文件系统是如何工作的？"><a href="#65-文件系统是如何工作的？" class="headerlink" title="65.文件系统是如何工作的？"></a>65.文件系统是如何工作的？</h3><p><strong>1.数据存储和组织</strong><br>文件系统将数据存储在存储设备上（如硬盘、SSD），并为这些数据提供了一种逻辑上的组织方式。通常，文件系统会将存储设备分为多个<strong>扇区或块</strong>，每个扇区&#x2F;块都是存储数据的基本单位。文件系统通过将文件分割成多个数据块，并在磁盘上分散存储来管理数据。<br><strong>2.文件元数据</strong><br>每个文件都有<strong>元数据</strong>，用于描述文件的信息，如文件名、大小、权限、创建时间和修改时间等。文件系统使用一些数据结构来存储这些元数据和数据块的位置。常见的数据结构包括：</p>
<ul>
<li>索引节点（Inode）：在 Unix 系统中，Inode 存储文件的元数据和文件内容所在数据块的指针。每个文件都有一个唯一的 Inode。</li>
<li>文件分配表（FAT）：在 FAT 文件系统中，FAT 记录每个文件的数据块链表的地址，用于定位文件的数据。</li>
</ul>
<p><strong>3.文件访问和路径分析</strong><br>当用户或应用程序请求访问某个文件时，文件系统需要解析路径并找到对应文件的物理存储位置。这个过程通常包括以下步骤：</p>
<ul>
<li>解析路径：文件系统会将文件的路径分解为多个目录名和文件名。例如，&#x2F;home&#x2F;user&#x2F;docs&#x2F;file.txt 会被解析为 home、user、docs 和 file.txt。</li>
<li>查找目录：文件系统会从根目录开始，通过查找每一级目录的元数据，找到文件对应的 Inode 或分配表条目。</li>
<li>读取数据：根据文件元数据中的指针，文件系统会找到文件的实际数据块，将数据从磁盘读取到内存。</li>
</ul>
<p><strong>4.文件读写操作</strong><br><strong>5.文件分配和管理</strong><br>文件系统需要有效地管理磁盘空间，常见的文件系统分配方法包括：</p>
<ul>
<li>连续分配</li>
<li>链表分配</li>
<li>索引分配：通过<strong>索引节点</strong>（如 Inode）记录文件的多个数据块的地址，读取文件时先从索引节点获取数据块地址，再从磁盘读取相应数据。</li>
</ul>
<p><strong>6.常见的文件系统类型</strong></p>
<ul>
<li><strong>FAT32</strong>：一种老式的文件系统，兼容性好，广泛应用于 USB 设备，但对单个文件的最大大小有限制。</li>
<li>NTFS：NTFS：Windows 系统中的文件系统，支持文件压缩、加密、权限控制等高级特性。</li>
<li><strong>ext4</strong>：Linux 系统中的常见文件系统，支持大文件、日志记录、快照等功能。</li>
<li>HFS+&#x2F;APFS：macOS 系统中的文件系统，支持时间机器备份、加密等特性。</li>
</ul>
<h3 id="66-页缓存是什么？有什么作用？"><a href="#66-页缓存是什么？有什么作用？" class="headerlink" title="66.页缓存是什么？有什么作用？"></a>66.页缓存是什么？有什么作用？</h3><p><strong>页缓存</strong>是操作系统用来加速磁盘 I&#x2F;O（输入&#x2F;输出）操作的一种机制。它是一个在内存中的缓冲区，用于缓存文件系统中的数据页。页缓存可以显著提高文件系统的性能，减少对磁盘的访问次数，因为磁盘 I&#x2F;O 通常是比内存操作慢得多的操作。</p>
<p><strong>有什么作用？</strong></p>
<ul>
<li><strong>加速文件读取与写入</strong><br>因为页表是存在磁盘上的，所以应该尽量避免直接访问磁盘。读取或者写入之前，操作系统会查找该文件数据是否已经在页缓存中。如果已经在页缓存中（<strong>缓存命中</strong>）操作系统直接从内存中返回数据。如果<strong>缓存未命中</strong>，操作系统会从磁盘读取数据，并将数据加载到页缓存中，以便后续读取时可以直接从缓存中获取。</li>
<li><strong>减少磁盘磨损</strong><br>由于磁盘的读写速度相对较慢，并且频繁的写操作可能导致硬盘的物理磨损，页缓存可以通过减少磁盘的写入频率来延长磁盘寿命。数据可以在内存中暂时保留，并在适当的时间点（如系统空闲时）批量写入磁盘。</li>
</ul>
<p><em><strong>页缓存是存放在内存中的吗？那和缓存有什么区别呢？</strong></em><br>页缓存是操作系统内存管理的一部分。页缓存（Page Cache）是操作系统中的一种内存管理机制，用于<strong>缓存磁盘数据到内存</strong>（RAM），以提高文件系统的访问性能。它的作用是将磁盘上的文件数据保存在内存中，这样当系统再次访问相同的数据时，可以直接从内存中读取，而无需再次访问较慢的磁盘设备。<br><strong>区别</strong>：</p>
<ul>
<li>页缓存作用范围：页缓存主要用于文件系统和磁盘之间的交互。操作系统通过在内存中缓存文件数据，减少频繁的磁盘读取请求，从而提高文件系统的性能。</li>
<li>缓存测磁更广：缓存不仅仅是文件系统中的数据缓存。缓存可以是 CPU 和内存之间的 CPU 缓存（L1&#x2F;L2&#x2F;L3），也可以是内存和磁盘之间的缓存（如内存数据库缓存），甚至可以是网络传输中的缓存（如浏览器缓存）。</li>
<li>更新机制不同：页缓存使用的是“<strong>延迟写</strong>”机制，即数据写入页缓存后，<strong>不会立即写入磁盘</strong>，而是在系统允许的时机将数据批量写回。而 CPU 缓存可以使用“写直达”（数据立即写入下一层存储）或“写回”（数据在缓存中暂时保留，只有在替换时才写入下一层存储）的策略。</li>
</ul>
<h3 id="67-嵌入式平台上如何提升计算性能"><a href="#67-嵌入式平台上如何提升计算性能" class="headerlink" title="67.嵌入式平台上如何提升计算性能"></a>67.嵌入式平台上如何提升计算性能</h3><p>嵌入式平台上计算资源和内存都是被限制住的。代码的优化很重要：<br>1.算法优化</p>
<ul>
<li>高性能的算法：选择时间复杂度小的算法</li>
</ul>
<p>2.代码优化</p>
<ul>
<li>使用内联</li>
</ul>
<p>3.内存优化</p>
<ul>
<li>看情况也可以使用int8_t等来代替int和float，节省内存空间。</li>
<li>使用栈而非堆</li>
<li>内存对齐</li>
</ul>
<p>5.功耗</p>
<ul>
<li>优化中断使用</li>
<li>降低处理器频率</li>
</ul>
<p>6.编译器优化</p>
<ul>
<li>-O1、-O2、-O3：不同级别的优化，-O3 通常提供最高的性能优化，但也可能增大代码体积。</li>
<li>Os：专注于减少代码大小的优化选项，适用于内存资源有限的嵌入式平台。</li>
</ul>
<p><em><strong>详细介绍一下</strong></em><br><strong>-O0（无优化）</strong></p>
<ul>
<li>表示 不进行任何优化。</li>
<li>效果：编译速度快，代码运行速度慢。</li>
</ul>
<p><strong>-O1 或 -O（基本优化）</strong><br><strong>特点：</strong>-O1 开启了 基本的优化，它试图在不明显增加编译时间和代码大小的情况下，提高程序的运行速度。</p>
<ul>
<li>优化内容：消除不必要的代码（如死代码）。简化控制流（如将简单的分支和循环优化）。局部变量优化（如常量折叠）。减少寄存器压力（让常用变量放到寄存器中）。</li>
<li>效果：编译时间略有增加，但生成的代码比 -O0 运行得更快，同时保持了较好的可调试性。</li>
</ul>
<p><strong>-O2（常用优化）</strong><br><strong>特点：</strong>-O2 是常用的优化级别，启用了更为激进的优化，同时仍然保持较好的编译时间和代码的大小。</p>
<ul>
<li>效果：代码运行得更快，编译时间和代码体积略有增加，但不会显著增大。</li>
</ul>
<p><strong>-O3（最高级别优化）</strong><br><strong>特点：</strong>-O3 启用了 -O2 中的所有优化，并额外加入了更多的高级优化，目标是使程序尽可能快。</p>
<ul>
<li><strong>优化内容：</strong>启用更具侵入性的优化策略，比如 循环矢量化 和 自动并行化。更多的函数<strong>内联</strong>，甚至可能会内联较大的函数。使用更复杂的优化算法来重新排序代码，提高指令流水线的效率。尽量将计算移出循环，减少不必要的计算。</li>
<li><strong>效果：</strong>程序的运行速度可以显著提高，但编译时间和生成代码的体积也会<strong>大幅增加</strong>。此外，代码的可调试性会降低，可能在某些场景下导致代码行为的微小变化。</li>
</ul>
<p><strong>-Os（为代码体积优化）</strong><br><strong>特点：</strong>-Os 是专门为减少代码体积而设计的优化级别。它启用了 -O2 中的大多数优化，但会禁用那些会增加代码体积的优化。</p>
<ul>
<li><strong>优化内容</strong>：保留 -O2 中对性能影响较大的优化。禁用那些会显著增加代码体积的优化（如<strong>循环展开</strong>、函数内联等）。效果：代码体积尽量减小，适用于嵌入式系统或内存资源受限的环境，同时在性能上有所平衡。</li>
<li>效果：代码体积尽量减小，适用于嵌入式系统或内存资源受限的环境，同时在性能上有所平衡。</li>
</ul>
<p><strong>-Og（为调试优化）</strong><br><strong>特点：</strong>-Og 是为调试而设计的优化等级，它在进行部分优化的同时，尽量保持代码的可调试性。</p>
<ul>
<li>优化内容：启用一些基础优化（如常量折叠、消除死代码等）。保持调试信息和代码行为尽可能一致，减少优化带来的调试困难。</li>
<li>效果：在保留调试信息的情况下，生成的代码相比 -O0 运行速度更快，但不会进行像 -O2 和 -O3 那样的激进优化。</li>
</ul>
<p>7.并行和任务调度优化</p>
<ul>
<li>优化任务的优先级，确保任务的相应时间</li>
<li>多核平台可以使用并行化，计算任务并行化</li>
<li>异步操作：传输数据使用DMA</li>
</ul>
<p>8.减少IO操作</p>
<ul>
<li>批量处理数据减少每次IO的时间</li>
<li>中断驱动IO：相较于轮询，使用中断驱动的 I&#x2F;O 操作可以减少 CPU 占用和功耗。</li>
</ul>
<h3 id="68-ARM的启动流程"><a href="#68-ARM的启动流程" class="headerlink" title="68.ARM的启动流程"></a>68.ARM的启动流程</h3><p>1.上电复位：将所有的寄存器和状态都置为一个已知的值<br>2.BootROM（固化启动代码）：最基本的硬件初始化操作，如设置堆栈指针、关闭中断、跳转到下一步引导程序的加载地址等。<br>3.bootloader 1：<br>初级引导程序</p>
<ul>
<li>初始化内存控制器（DRAM、SRAM等）</li>
<li>初始化 CPU 时钟、系统定时器和串行端口等基本外设。</li>
</ul>
<p>4.bootloader 2：</p>
<ul>
<li>在这一阶段，Bootloader 第二阶段（通常是 U-Boot 等）会被加载到内存并开始执行。它负责进一步初始化系统，包括：</li>
<li>初始化更多的外设（如网卡、USB 控制器等）。</li>
<li>加载文件系统、解压内核映像（如 zImage 或 uImage）到内存。</li>
<li>加载设备树（Device Tree）以描述硬件配置（对现代 ARM 设备尤为重要）。</li>
</ul>
<p>5.加载内核：</p>
<ul>
<li>Bootloader 完成初始化后，将内核映像加载到内存中，并将控制权转交给内核启动代码。</li>
<li>ARM 处理器会通过跳转到内核的入口点（通常是 0x8000 或者 0x00080000 地址）来执行内核代码。</li>
<li>在执行内核之前，Bootloader 通常还会向内核传递一些启动参数，如内存布局、命令行参数和设备树的地址。</li>
</ul>
<p>6.内核初始化</p>
<ul>
<li>初始化内存管理单元（MMU）和页表。</li>
<li>初始化各种硬件驱动程序。</li>
<li>初始化文件系统。</li>
<li>识别和加载必要的内核模块。</li>
<li>初始化各种子系统（如进程调度、内存管理、I&#x2F;O 子系统等）。</li>
</ul>
<p>7.启动用户空间</p>
<h3 id="69-响应优先级和抢占优先级的区别"><a href="#69-响应优先级和抢占优先级的区别" class="headerlink" title="69.响应优先级和抢占优先级的区别"></a>69.响应优先级和抢占优先级的区别</h3><p><strong>1.响应优先级</strong><br>响应优先级主要是指系统在处理任务时，不同任务或中断请求之间的处理顺序。它决定了当系统空闲或者当前任务结束时，哪个任务将被优先响应。<br><strong>特点</strong>：</p>
<ul>
<li>处理顺序：任务或中断会按照响应优先级的顺序进行处理。当多个任务处于等待状态时，系统会根据响应优先级选择优先处理的任务。</li>
<li>非抢占：响应优先级通常不涉及任务的中途抢占。即便当前正在执行低优先级的任务，高优先级的任务也不会打断它，而是在当前任务完成后执行。</li>
</ul>
<p><strong>2.抢占优先级</strong><br>抢占优先级指的是高优先级任务可以<strong>打断</strong>（抢占）当前正在执行的低优先级任务。它决定了系统是否允许某个高优先级任务立即打断低优先级任务的执行。<br><strong>特点：</strong></p>
<ul>
<li>实时性保障：抢占优先级确保高优先级任务可以在系统繁忙时也能及时得到处理，非常适合需要实时响应的场景。</li>
<li>使用场景：常见于抢占式调度，如实时操作系统（RTOS）、带有严格实时要求的系统（如嵌入式控制系统、操作系统中的中断处理等）。</li>
</ul>
<h3 id="70-linux和windows的区别"><a href="#70-linux和windows的区别" class="headerlink" title="70.linux和windows的区别"></a>70.linux和windows的区别</h3><p>开源不开源<br>权限</p>
<h3 id="71-什么情况用到的是物理地址什么情况用的是虚拟地址"><a href="#71-什么情况用到的是物理地址什么情况用的是虚拟地址" class="headerlink" title="71.什么情况用到的是物理地址什么情况用的是虚拟地址"></a>71.什么情况用到的是物理地址什么情况用的是虚拟地址</h3><p>使用物理地址情况</p>
<ul>
<li><strong>硬件层面的操作</strong>：设备驱动程序、硬件控制器等直接操作物理内存时，通常需要使用物理地址。例如：DMA、硬件与内存之间的数据传输时。设备驱动访问外设寄存器。</li>
<li>裸机开发</li>
<li><strong>内核空间的某些部分</strong>：虽然内核通常也使用虚拟地址，但在与<strong>硬件交互</strong>时，操作系统的内核代码可能需要将虚拟地址转换为物理地址，并在某些情况下直接使用物理地址。</li>
</ul>
<p>使用虚拟地址情况</p>
<ul>
<li>用户态程序：绝大多数用户态程序运行时，访问的都是虚拟地址。操作系统通过内存管理单元（MMU）将虚拟地址映射到物理地址，用户程序不需要也不能直接操作物理地址。</li>
<li>内核态程序：即使是在内核中，大多数情况下操作系统也使用虚拟地址。内核可以通过分页机制进行内存管理，操作系统通过转换虚拟地址访问物理内存。</li>
</ul>
<p><em><strong>这里来解释一下：为什么设备驱动访问外设寄存器需要使用物理地址映射</strong></em><br>MMU（内存管理单元）主要负责管理虚拟地址到物理地址的转换，它允许操作系统为每个进程提供独立的虚拟地址空间，并将这些虚拟地址映射到物理内存。MMU管理文件系统。<br>外设的输入通常并不通过文件系统进行，而是通过设备寄存器或内存映射 I&#x2F;O 进行直接的硬件交互。在这种情况下，确实通常需要使用物理地址进行访问，原因如下：</p>
<ul>
<li>1.<strong>设备寄存器和内存映射 I&#x2F;O (MMIO)</strong><br>硬件设备（例如网卡、串口、USB 控制器等）通常通过特殊的物理地址暴露它们的寄存器。这些寄存器是用于与设备进行配置、状态查询以及数据传输的。在没有 MMU 的介入下，设备只能通过物理地址来访问其硬件寄存器。例如，使用 ioremap() 可以将物理地址映射到内核的虚拟地址空间，以便驱动程序通过内核虚拟地址访问硬件设备的寄存器。</li>
<li>2.<strong>直接内存访问（DMA）</strong><br>设备与内存的直接交互通常通过 DMA 进行。DMA 控制器可以绕过 CPU，直接在物理内存中读取或写入数据。因为 DMA 控制器是硬件设备，它不能理解虚拟地址，只能理解物理地址。因此，驱动程序需要向 DMA 控制器提供物理内存地址。</li>
<li>3.<strong>设备文件 vs. 内存映射 I&#x2F;O</strong>：<br>虽然文件系统中的设备文件（如 &#x2F;dev&#x2F;ttyS0）可以抽象化设备访问，但实际上设备的操作（读&#x2F;写寄存器、数据传输等）是通过物理地址来实现的。Linux 的设备驱动程序通过内存映射 I&#x2F;O（MMIO）或者端口 I&#x2F;O 来直接与设备通信，这种交互实际上是基于物理地址的。</li>
<li>4.<strong>I&#x2F;O 内存和 MMU 的差异</strong>：<br>MMU 通常用于内存管理，即管理 RAM 的虚拟地址与物理地址的映射。外设的寄存器或设备内存（如显卡的帧缓冲区）则是通过 MMIO 映射到 CPU 的地址空间，但这些地址可能不经过 MMU 进行虚拟地址转换，设备访问寄存器时仍然使用物理地址。</li>
</ul>
<h3 id="72-负载均衡"><a href="#72-负载均衡" class="headerlink" title="72.负载均衡"></a>72.负载均衡</h3><p>Linux 调度器中的一个机制，它会动态地将任务在各个 CPU 核心之间重新分配，以均衡每个核心的负载。<br>例如，如果某个 CPU 核心的负载较高，而其他核心空闲，调度器会将某些任务迁移到空闲的核心上，以提高整体系统性能。</p>
<h3 id="73-从物理地址映射到内核空间的函数"><a href="#73-从物理地址映射到内核空间的函数" class="headerlink" title="73.从物理地址映射到内核空间的函数"></a>73.从物理地址映射到内核空间的函数</h3><ul>
<li>kmalloc<br><strong>用途</strong>： 为内核分配连续的物理内存，并返回对应的内核虚拟地址。<br><strong>特点</strong>：内核分配的内存是<strong>物理上连续的</strong>（但不保证是高位地址），适合分配小块内存</li>
<li>ioremap<br><strong>用途</strong>: 用于将<strong>设备寄存器的物理地址</strong>（如内存映射 I&#x2F;O）映射到内核虚拟地址空间。<br><strong>特点</strong>: 常用于将硬件设备的寄存器或设备内存映射到内核地址空间，以便进行访问。</li>
<li>vmalloc<br><strong>用途</strong>: 为内核分配虚拟地址空间，并在必要时将多个物理页映射到连续的虚拟地址空间。<br><strong>特点</strong>: 分配的虚拟地址是连续的，但底层的物理内存<strong>不需要是连续的</strong>。</li>
<li>vmap<br><strong>用途</strong>: 将已有的一组物理页（通常通过 struct page 表示）映射到连续的虚拟地址空间。</li>
</ul>
<h3 id="74-字符设备与块设备"><a href="#74-字符设备与块设备" class="headerlink" title="74.字符设备与块设备"></a>74.字符设备与块设备</h3><h4 id="块设备"><a href="#块设备" class="headerlink" title="块设备"></a>块设备</h4><p>块设备以“块”为单位进行数据传输，通常每次读写的数据量较大。典型的块设备包括硬盘、SSD、SD 卡等。块设备支持随机访问，意味着可以直接访问设备上的任意块。块设备通常用于存储文件系统，Linux 中的文件系统通常构建在块设备之上。</p>
<h4 id="字符设备"><a href="#字符设备" class="headerlink" title="字符设备"></a>字符设备</h4><p>字符设备以“字符”为单位进行数据传输，每次读写的数据量较小。典型的字符设备包括串口设备（如 UART）、键盘、鼠标、打印机等。字符设备通常支持顺序访问，即一次读取一个字节或多个连续的字节。字符设备更适合处理小规模的数据流，比如从键盘输入数据、读取串口信息等。</p>
<h1 id="linux问题："><a href="#linux问题：" class="headerlink" title="linux问题："></a>linux问题：</h1><h3 id="1-如何查看进程以及其中包含的线程"><a href="#1-如何查看进程以及其中包含的线程" class="headerlink" title="1.如何查看进程以及其中包含的线程"></a>1.如何查看进程以及其中包含的线程</h3><p>查看进程 ps -aux 或者 使用 top<br>top 和 ps 都是常用的命令行工具，用于查看 Linux 系统中的进程和线程信息，但它们的用途和功能上有一些重要区别：</p>
<ul>
<li>top是<strong>实时</strong>的，而ps现实的是<strong>静态</strong>的</li>
<li>top: top 默认显示的内容较为简洁，包括进程&#x2F;线程的 PID、用户、CPU 和内存使用率、运行时间等。它可以动态调整显示的列、排序方式等。top 更适合实时监控系统性能和找出高资源消耗的进程。ps: ps 的输出内容更为灵活和详细。通过不同的选项组合，你可以定制输出结果，获取非常详细的进程信息，例如启动时间、命令行参数、环境变量等。ps 常用于脚本或分析当前系统状态。<br>ps：</li>
<li>查看进程：ps -aux </li>
<li>查看线程：ps -Lf -p <PID>可以查看特定进程的线程</li>
</ul>
<p>top：</p>
<ul>
<li>查看进程：top</li>
<li>查看线程：进入top之后使用大写H，会显示CPU消耗</li>
</ul>
<p><em><strong>top常见命令</strong></em><br>1.输入top指令，进入top<br>2.常见的top指令</p>
<ul>
<li>h：切换线程显示</li>
<li>q：退出top</li>
<li>k：杀死进程</li>
<li>M：内存使用资源排序显示</li>
<li>N：以PID排序显示</li>
<li>P：CPU使用资源排序显示</li>
<li>r：给pid定义一个新的优先级</li>
</ul>
<h3 id="2-GDB调试指令"><a href="#2-GDB调试指令" class="headerlink" title="2.GDB调试指令"></a>2.GDB调试指令</h3><ul>
<li>1.启动gdb<br>gdb &lt;executable&gt;</li>
<li>2.运行程序<br>run</li>
<li>3.设置断点<br>break 25</li>
<li>4.删除断电<br>delete 编号的断点</li>
<li>5.查看设置的所有断点<br>info break</li>
<li>6.单步执行<br>step：单步执行代码<br>next：单步执行代码</li>
<li>7.查看变量<br>print</li>
<li>8.查看堆栈<br>backtrace 查看当前的堆栈</li>
</ul>
<h3 id="3-xargs指令是什么用的？"><a href="#3-xargs指令是什么用的？" class="headerlink" title="3.xargs指令是什么用的？"></a>3.xargs指令是什么用的？</h3><p>xargs 是 Linux 和 Unix 系统中的一个非常有用的命令，它用于从<strong>标准输入或其他命令的输出</strong>构建并执行命令行。这意味着它可以将输入数据作为命令行参数传递给另一个命令。<br>举几个例子：</p>
<ul>
<li><p>1.删除大量文件<br>这里便是找到后缀都为.tmp的文件，输入给xargs然后删除掉</p>
<pre><code>find . -name &quot;*.tmp&quot; | xargs rm -f
</code></pre>
</li>
<li><p>2.将多个文件内容连接到一个文件中<br>使用 xargs 可以将多个文件的内容组合到一个文件中。<br>将当前目录下所有 .txt 文件的内容组合到一个文件 all_texts.txt 中。</p>
<pre><code>ls *.txt | xargs cat &gt; all_texts.txt
</code></pre>
</li>
</ul>
<h3 id="4-vmalloc和kmalloc这两个指令是干什么用的"><a href="#4-vmalloc和kmalloc这两个指令是干什么用的" class="headerlink" title="4.vmalloc和kmalloc这两个指令是干什么用的"></a>4.vmalloc和kmalloc这两个指令是干什么用的</h3><p>vmalloc 是 Linux 内核中提供的一种内存分配函数，用于在内核空间分配虚拟连续的内存区域。</p>
<ul>
<li><strong>kmalloc</strong>：分配的是物理上连续的内存，适用于分配较小内存块或者对性能要求高的场景。</li>
<li><strong>vmalloc</strong>：分配的是虚拟地址连续的内存，适用于需要分配较大内存块且对性能要求不高的场景。</li>
</ul>
<h3 id="5-内存泄漏检测命令"><a href="#5-内存泄漏检测命令" class="headerlink" title="5.内存泄漏检测命令"></a>5.内存泄漏检测命令</h3><p>valgrind 是一个强大的工具，用于检测和调试程序中的内存错误、线程问题以及性能瓶颈。它在开发和调试 C、C++ 程序（以及其他使用类似内存模型的语言）时特别有用，帮助开发者识别和修复难以发现的内存管理和并发问题。通过使用 valgrind，开发者可以提高程序的稳定性、性能和可靠性。</p>
<ul>
<li><p>1.写一个有内存泄漏的代码并gcc编译为可执行代码</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;

void memory_leak_example() &#123;
    char *leak = (char *)malloc(100 * sizeof(char));
    if (leak == NULL) &#123;
        perror(&quot;Failed to allocate memory&quot;);
        exit(EXIT_FAILURE);
    &#125;

    strcpy(leak, &quot;This is a memory leak example.&quot;);

    printf(&quot;Allocated memory and copied string: %s\n&quot;, leak);

    // 注意：这里没有调用 free() 来释放分配的内存，这会导致内存泄漏
&#125;

int main() &#123;
    memory_leak_example();

    printf(&quot;End of program.\n&quot;);

    return 0;
&#125;
</code></pre>
</li>
<li><p>2.使用valgrind指令检测内存泄漏情况</p>
<pre><code>valgrind --leak-check=full --track-origins=yes ./memory_leak_example
</code></pre>
</li>
<li><p>3.使用valgrind检测内存泄漏的位置</p>
<p>valgrind –leak-check&#x3D;full .&#x2F;my_program</p>
</li>
<li><p>提供详细的内存泄漏信息，包括堆栈发生的位置，例如输出：</p>
<pre><code>==12345== 40 bytes in 1 blocks are definitely lost in loss record 2 of 5
==12345==    at 0x4C2FA3F: malloc (vg_replace_malloc.c:309)
==12345==    by 0x4005AD: main (example.c:7)
</code></pre>
</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240822165123.png"></p>
<p>解释一下输出的结果：<br>HEAP SUMMARY：</p>
<ul>
<li>这个部分总结了程序在退出时的堆内存使用情况。</li>
<li>“in use at exit” 表示程序结束时仍然分配的内存量，意味着这部分内存没有被释放</li>
</ul>
<p>LEAK SUMMARY：</p>
<ul>
<li>“definitely lost” 表示确实丢失的内存，通常是忘记释放的内存。</li>
<li>“indirectly lost” 表示由 “definitely lost” 内存指向的内存。</li>
<li>“still reachable” 表示仍然可以访问的内存，但程序在退出前没有释放它，这不一定是错误，但通常也需要清理。</li>
</ul>
<h3 id="6-linux的free指令"><a href="#6-linux的free指令" class="headerlink" title="6.linux的free指令"></a>6.linux的free指令</h3><p>free 是 Linux 系统中用于显示内存使用情况的命令。它可以帮助我们查看系统的总内存、已用内存、可用内存、交换分区等的情况。free 命令通过读取 &#x2F;proc&#x2F;meminfo 文件来提供这些信息。下面是 free 命令的详细介绍，包括输出和常用选项。</p>
<p>free命令会显示如下信息：</p>
<pre><code>$ free
              total        used        free      shared  buff/cache   available
Mem:        16348084     6258896     6127020      464384     3969268    9180036
Swap:       16777212           0    16777212
</code></pre>
<h3 id="7-perf指令"><a href="#7-perf指令" class="headerlink" title="7.perf指令"></a>7.perf指令</h3><h4 id="1-什么是perf"><a href="#1-什么是perf" class="headerlink" title="1.什么是perf"></a>1.什么是perf</h4><p>perf 是内核自带的性能分析工具，它利用硬件性能计数器和内核的跟踪功能，来捕获各种性能相关的事件。通过 perf，你可以收集并分析如下信息：</p>
<ul>
<li>CPU 使用情况（用户态&#x2F;内核态时间）</li>
<li>缓存命中率</li>
<li>分支预测命中率</li>
<li>I&#x2F;O 访问</li>
<li>上下文切换等</li>
</ul>
<h4 id="2-常用指令"><a href="#2-常用指令" class="headerlink" title="2.常用指令"></a>2.常用指令</h4><ul>
<li><p>1.perf stat<br>perf stat 是最常用的子命令之一，用于统计系统或进程的性能数据。它可以统计 CPU 时钟周期、指令数、缓存引用次数、缓存缺失次数、分支预测命中率等。</p>
</li>
<li><p>2.perf record和perf report<br>perf record 用于记录程序执行期间发生的性能事件，并将其保存在文件中。然后可以使用 perf report 来查看这些事件，帮助分析<strong>性能瓶颈</strong>。</p>
</li>
<li><p>3.perf top<br>类似于top指令，可以实时显示当前系统中性能事件时间的分布情况。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240923223323.png"></p>
</li>
<li><p>4.perf list<br>perf list 列出当前系统支持的所有事件，这些事件可以是硬件计数器事件、内核事件或软件事件。</p>
</li>
<li><p>5.perf annotate<br>如果你想查看具体的代码行或汇编指令，哪些部分导致了性能瓶颈，可以使用 perf annotate。这个命令会显示源代码（如果可用）或汇编代码的热区，帮助你定位最耗费资源的代码部分。</p>
</li>
</ul>
<h4 id="3-做一个实验"><a href="#3-做一个实验" class="headerlink" title="3.做一个实验"></a>3.做一个实验</h4><p>写一个矩阵乘法的例子来看性能瓶颈^^，太神奇了</p>
<pre><code>#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;time.h&gt;

// 定义矩阵的维度
#define N 1000

void matrix_multiply(double** a, double** b, double** result) &#123;
    for (int i = 0; i &lt; N; i++) &#123;
        for (int j = 0; j &lt; N; j++) &#123;
            result[i][j] = 0;
            for (int k = 0; k &lt; N; k++) &#123;
                result[i][j] += a[i][k] * b[k][j];
            &#125;
        &#125;
    &#125;
&#125;

int main() &#123;
    // 分配动态内存用于矩阵
    double** a = (double**)malloc(N * sizeof(double*));
    double** b = (double**)malloc(N * sizeof(double*));
    double** result = (double**)malloc(N * sizeof(double*));
    for (int i = 0; i &lt; N; i++) &#123;
        a[i] = (double*)malloc(N * sizeof(double));
        b[i] = (double*)malloc(N * sizeof(double));
        result[i] = (double*)malloc(N * sizeof(double));
    &#125;

    // 初始化矩阵
    srand(time(NULL));
    for (int i = 0; i &lt; N; i++) &#123;
        for (int j = 0; j &lt; N; j++) &#123;
            a[i][j] = rand() % 100;
            b[i][j] = rand() % 100;
        &#125;
    &#125; 

    // 计算矩阵乘法
    clock_t start = clock();
    matrix_multiply(a, b, result);
    clock_t end = clock();

    printf(&quot;Matrix multiplication took %lf seconds.\n&quot;, (double)(end - start) / CLOCKS_PER_SEC);

    // 释放动态分配的内存
    for (int i = 0; i &lt; N; i++) &#123;
        free(a[i]);
        free(b[i]);
        free(result[i]);
    &#125;
    free(a);
    free(b);
    free(result);

    return 0;
&#125;
</code></pre>
<ul>
<li><p>1.gcc 编译：-g为了方便后面的annotate，否则后面annotate就会显示汇编。-O2优化后才能显示为下面的样子，否则O0 0优化不会显示代码调试就会很痛苦 &gt;&lt; 。<br>加了-g（代码+汇编）：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240923231216.png"></p>
<p>  gcc -g -o -O2 try1 1.c</p>
</li>
<li><p>2.run+记录：perf record .&#x2F;try1</p>
</li>
<li><p>3.生成报告看一眼：perf report<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240923231843.png"></p>
</li>
<li><p>4.显示代码+对应汇编耗时占比perf annotate：显示哪一条指令占比最大。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240923232000.png"></p>
</li>
</ul>
<h3 id="8-Linux中的常见段错误可能的原因有哪些？以及如何排查？"><a href="#8-Linux中的常见段错误可能的原因有哪些？以及如何排查？" class="headerlink" title="8.Linux中的常见段错误可能的原因有哪些？以及如何排查？"></a>8.Linux中的常见段错误可能的原因有哪些？以及如何排查？</h3><p>段错误是一种常见的错误，它通常出现在程序试图访问非法的内存区域时。段错误发生时，操作系统会终止程序，并生成一个错误信号 SIGSEGV，表示<strong>程序试图访问未被允许的内存区域</strong>。</p>
<p>常见原因，其实也就是访问到不该访问的内存地址了：空指针引用，数组元素访问越界，使用已经释放的内存</p>

            </div>

            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2024/05/05/linux%20camera%E9%A1%B9%E7%9B%AE%E5%AE%9E%E7%8E%B0/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">linux camera项目实现</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2024/01/01/%E3%80%8A%E7%BD%91%E7%BB%9C%E6%98%AF%E6%80%8E%E6%A0%B7%E8%BF%9E%E6%8E%A5%E7%9A%84%E3%80%8B/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">《网络是怎样连接的》</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
        </div>

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2020</span> -
            
            2024
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">caijiQAQ</a>
            
        </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>










<div class="post-scripts">
    
        
<script src="/js/post-helper.js"></script>

        
        
    
</div>



</body>
</html>
