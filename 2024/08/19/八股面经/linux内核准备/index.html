<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    <meta name="keywords" content="Hexo Theme Keep">
    <meta name="description" content="Hexo Theme Keep">
    <meta name="author" content="caijiQAQ">
    
    <title>
        
            linux内核准备 |
        
        学习笔记
    </title>
    
<link rel="stylesheet" href="/css/style.css">

    <link rel="shortcut icon" href="/images/logo.svg">
    
<link rel="stylesheet" href="/font/css/fontawesome.min.css">

    
<link rel="stylesheet" href="/font/css/regular.min.css">

    
<link rel="stylesheet" href="/font/css/solid.min.css">

    
<link rel="stylesheet" href="/font/css/brands.min.css">

    <script id="hexo-configurations">
    let KEEP = window.KEEP || {}
    KEEP.hexo_config = {"hostname":"caiji-qaq.github.io","root":"/","language":"en"}
    KEEP.theme_config = {"toc":{"enable":false,"number":false,"expand_all":false,"init_open":false},"style":{"primary_color":"#0066cc","logo":"/images/logo.svg","favicon":"/images/logo.svg","avatar":"/images/avatar.svg","font_size":null,"font_family":null,"hover":{"shadow":false,"scale":false},"first_screen":{"enable":false,"header_transparent":false,"background_img":"/images/bg.svg","description":"Keep writing and Keep loving.","font_color":null,"hitokoto":false},"scroll":{"progress_bar":false,"percent":false}},"local_search":{"enable":false,"preload":false},"code_copy":{},"code_block":{"tools":{"enable":false,"style":"default"},"highlight_theme":"default"},"side_tools":{},"pjax":{"enable":false},"lazyload":{"enable":false},"comment":{"enable":false,"use":"valine","valine":{"appid":null,"appkey":null,"server_urls":null,"placeholder":null},"gitalk":{"github_id":null,"github_admins":null,"repository":null,"client_id":null,"client_secret":null,"proxy":null},"twikoo":{"env_id":null,"region":null,"version":"1.6.8"},"waline":{"server_url":null,"reaction":false,"version":2}},"post":{"author_label":{"enable":true,"auto":true,"custom_label_list":["Trainee","Engineer","Architect"]},"word_count":{"enable":false,"wordcount":false,"min2read":false},"img_align":"left","copyright_info":false},"version":"3.6.1"}
    KEEP.language_ago = {"second":"%s seconds ago","minute":"%s minutes ago","hour":"%s hours ago","day":"%s days ago","week":"%s weeks ago","month":"%s months ago","year":"%s years ago"}
    KEEP.language_code_block = {"copy":"Copy code","copied":"Copied","fold":"Fold code block","folded":"Folded"}
    KEEP.language_copy_copyright = {"copy":"Copy copyright info","copied":"Copied","title":"Original article title","author":"Original article author","link":"Original article link"}
  </script>
<meta name="generator" content="Hexo 6.3.0"></head>


<body>
<div class="progress-bar-container">
    

    
</div>


<main class="page-container">

    

    <div class="page-main-content">

        <div class="page-main-content-top">
            
<header class="header-wrapper">

    <div class="header-content">
        <div class="left">
            
                <a class="logo-image" href="/">
                    <img src="/images/logo.svg">
                </a>
            
            <a class="logo-title" href="/">
               学习笔记
            </a>
        </div>

        <div class="right">
            <div class="pc">
                <ul class="menu-list">
                    
                        <li class="menu-item">
                            <a class=""
                               href="/"
                            >
                                HOME
                            </a>
                        </li>
                    
                        <li class="menu-item">
                            <a class=""
                               href="/archives"
                            >
                                ARCHIVES
                            </a>
                        </li>
                    
                    
                </ul>
            </div>
            <div class="mobile">
                
                <div class="icon-item menu-bar">
                    <div class="menu-bar-middle"></div>
                </div>
            </div>
        </div>
    </div>

    <div class="header-drawer">
        <ul class="drawer-menu-list">
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/">HOME</a>
                </li>
            
                <li class="drawer-menu-item flex-center">
                    <a class=""
                       href="/archives">ARCHIVES</a>
                </li>
            
        </ul>
    </div>

    <div class="window-mask"></div>

</header>


        </div>

        <div class="page-main-content-middle">

            <div class="main-content">

                
                    <div class="fade-in-down-animation">
    <div class="post-page-container">
        <div class="article-content-container">

            <div class="article-title">
                <span class="title-hover-animation">linux内核准备</span>
            </div>

            
                <div class="article-header">
                    <div class="avatar">
                        <img src="/images/avatar.svg">
                    </div>
                    <div class="info">
                        <div class="author">
                            <span class="name">caijiQAQ</span>
                            
                                <span class="author-label">Lv3</span>
                            
                        </div>
                        <div class="meta-info">
                            
<div class="article-meta-info">
    <span class="article-date article-meta-item">
        
            <i class="fa-regular fa-calendar-plus"></i>&nbsp;
        
        <span class="pc">2024-08-19 17:14:58</span>
        <span class="mobile">2024-08-19 17:14</span>
    </span>
    
        <span class="article-update-date article-meta-item">
        <i class="fas fa-file-pen"></i>&nbsp;
        <span class="pc">2024-10-14 10:57:18</span>
    </span>
    
    
    

    
    
    
    
</div>

                        </div>
                    </div>
                </div>
            

            <div class="article-content keep-markdown-body">
                

                <h1 id="1-Linux内核"><a href="#1-Linux内核" class="headerlink" title="1.Linux内核"></a>1.Linux内核</h1><p>Linux 系统的核心是内核。内核控制着计算机系统上的所有硬件和软件，在必要时分配硬件，并根据需要执行软件。下面将从下面5个方面来准备。</p>
<ul>
<li><p><strong>1、系统内存管理</strong><br>Linux内核负责管理系统内存，包括内存的分配与回收、虚拟内存管理、分页（paging）和交换（swapping）等。内核确保不同进程能够安全有效地使用内存，同时提供内存保护和共享机制。</p>
</li>
<li><p><strong>2、进程管理</strong><br>内核负责创建、调度和终止进程，处理进程之间的通信与同步。内核还管理系统资源的分配和使用（例如CPU时间、内存等），以确保系统的多任务处理能力。应用程序是运行在用户空间的程序，而内核主要管理的是进程的生命周期和资源调度。</p>
</li>
<li><p><strong>3、硬件设备管理</strong><br>这是正确的。Linux内核通过设备<strong>驱动程序</strong>（Device Drivers）与硬件设备进行交互。内核为用户空间提供了一个<strong>抽象层</strong>，使得应用程序可以使用标准化的接口与各种硬件设备进行交互，而不需要了解底层硬件的具体细节。</p>
</li>
<li><p><strong>4、文件系统管理</strong><br>Linux内核负责管理文件系统，包括文件的创建、删除、读写操作，以及磁盘的管理。内核支持多种文件系统类型，并提供统一的文件系统接口，使得应用程序可以通过标准系统调用来操作文件。</p>
</li>
<li><p><strong>5、中断和异常处理</strong><br>内核处理硬件中断和异常，确保系统正常运行</p>
</li>
</ul>
<h1 id="2-深入理解Linux系统内存管理"><a href="#2-深入理解Linux系统内存管理" class="headerlink" title="2.深入理解Linux系统内存管理"></a>2.深入理解Linux系统内存管理</h1><h2 id="1-内核态和用户态的区别？"><a href="#1-内核态和用户态的区别？" class="headerlink" title="1.内核态和用户态的区别？"></a>1.内核态和用户态的区别？</h2><ul>
<li>内核态：处于内核态的 CPU 可以访问<strong>任意的数据</strong>，包括外围设备，比如网卡、硬盘等，处于内核态的 CPU 可以从一个程序切换到另外一个程序，并且该状态下占用 CPU 不会发生<strong>被抢占情况</strong>，一般处于特权级 0 的状态我们称之为内核态。该状态下用来运行操作系统程序，操作硬件。</li>
<li>用户态：用户态的CPU只能受限地访问内存，并且不允许访问外围设备，用户态下的CPU也不允许独占，也就是说 CPU 能够被其他程序获取。该状态下用来运行用户程序。</li>
</ul>
<h2 id="2-虚拟内存地址"><a href="#2-虚拟内存地址" class="headerlink" title="2.虚拟内存地址"></a>2.虚拟内存地址</h2><p>64位的虚拟地址格式：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819195631.png"></p>
<p><em><strong>为什么要用虚拟地址？</strong></em><br>首先是如果程序全都使用物理地址这样的话需要知道每一个变量都被安排到了什么位置，同时也要注意多个进程同时使用的时候，不能同时使用一个地址，否则会发生冲突。如果使用地址的话，每个进程可以拥有属于自己的一块独立的虚拟地址空间，进程和进程之间的变量就不会相互干扰了。可以全部丢给内存管理模块，无需去考虑物理地址的部分了。</p>
<h3 id="2-1-用户态虚拟内存空间"><a href="#2-1-用户态虚拟内存空间" class="headerlink" title="2.1 用户态虚拟内存空间"></a>2.1 用户态虚拟内存空间</h3><p>这里就先不看内核态的虚拟空间，只看用户态的虚拟内存空间。</p>
<p>从下到上如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819200551.png"></p>
<ul>
<li>代码段：已经编译好的二进制机器指令。</li>
<li>数据段：已被初始化好值的全局变量以及静态变量</li>
<li>BSS段：没有被初始化好值的全局变量以及静态变量</li>
<li>堆段：在运行过程中需要动态声明的申请内存</li>
<li>文件映射与匿名映射区：用于存放动态链接库以及内存映射区域。内存文件映射的系统调用 mmap，会将文件与内存进行映射，那么映射的这块内存（虚拟内存）也需要在虚拟地址空间中有一块区域存储。</li>
<li>栈：存放用于函数调用过程中的局部变量和函数参数。</li>
</ul>
<p><em><strong>注：运行过程中需要调用的动态链接库，也有自己对应的代码段、数据段这些。尽管共享一个进程地址空间，但动态链接库有自己的独立的代码段和数据段。这些段在内存中有独立的地址空间，可以与主程序的代码段和数据段分离开来。</strong></em></p>
<h3 id="2-2-64位机器上进程虚拟内存空间分布"><a href="#2-2-64位机器上进程虚拟内存空间分布" class="headerlink" title="2.2 64位机器上进程虚拟内存空间分布"></a>2.2 64位机器上进程虚拟内存空间分布</h3><p>在目前的 64 位系统下只使用了 48 位来描述虚拟内存空间，寻址范围为 2^48^ ，所能表达的虚拟内存空间为 256TB。<br>其中低 128 T 表示用户态虚拟内存空间，虚拟内存地址范围为：<br>0x0000 0000 0000 0000 - 0x0000 7FFF FFFF F000 。<br>高 128 T 表示内核态虚拟内存空间，虚拟内存地址范围为：<br>0xFFFF 8000 0000 0000 - 0xFFFF FFFF FFFF FFFF 。<br>这里也就形成了一段空白的地址空间，这样将空洞叫做canonical address空洞。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819203015.png"></p>
<p>因此可以说内核态虚拟内存高16位全都为1，如果试图访问内核虚拟地址的高16位不全为1则，这个访问一定是违法的。<br>因此真实的虚拟内存空间分布情况就是：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819203253.png"></p>
<ul>
<li>64位的虚拟地址分布中，代码段和数据段中间还有一段不可以读写的<strong>保护段</strong>，作用是防止程序在读写数据段时越界访问到代码段。</li>
</ul>
<h2 id="3-虚拟内存空间的管理"><a href="#3-虚拟内存空间的管理" class="headerlink" title="3.虚拟内存空间的管理"></a>3.虚拟内存空间的管理</h2><p>内核中的描述符 task_struct结构</p>
<pre><code>struct task_struct &#123;
        // 进程id
        pid_t                pid;
        // 用于标识线程所属的进程 pid
        pid_t                tgid;
        // 进程打开的文件信息
        struct files_struct        *files;
        // 内存描述符表示进程虚拟地址空间
        struct mm_struct        *mm;

        .......... 省略 .......
&#125;
</code></pre>
<p>在进程描述符 task_struct 结构中，有一个<strong>专门描述进程虚拟地址空间</strong>的内存描述符 mm_struct 结构，这个结构体中包含了前边几个小节中介绍的进程虚拟内存空间的全部信息。</p>
<p>每个进程都有唯一的 mm_struct 结构体，也就是前边提到的每个进程的虚拟地址空间都是独立，互不干扰的。</p>
<p>当我们调用 <strong>fork()</strong> 函数创建进程的时候，表示<strong>进程地址空间</strong>的 mm_struct 结构会随着进程描述符 task_struct 的创建而创建。</p>
<p>随后会在 copy_process 函数中创建 task_struct 结构，并拷贝父进程的相关资源到新进程的 task_struct 结构里，其中就<strong>包括拷贝父进程的虚拟内存空间</strong> mm_struct 结构。这里可以看出子进程在新创建出来之后它的虚拟内存空间是和父进程的虚拟内存空间<strong>一模一样</strong>的，直接拷贝过来。</p>
<p>如果使用**clone()**，子进程共享了父进程的虚拟内存空间，这样子进程就变成了我们熟悉的线程，是否共享地址空间几乎是进程和线程之间的本质区别。Linux 内核并不区别对待它们，线程对于内核来说仅仅是一个共享特定资源的进程而已。</p>
<p><em><strong>内核线程与用户线程的区别</strong></em><br>当一个内核线程被调度时，它会发现自己的虚拟地址空间为 Null，虽然它不会访问用户态的内存，但是它会访问内核内存，聪明的内核会将调度之前的上一个用户态进程的虚拟内存空间 mm_struct 直接赋值给内核线程，因为内核线程不会访问用户空间的内存，&#x3D;&#x3D;它仅仅只会访问内核空间的内存&#x3D;&#x3D;（内核地址与用户空间地址相隔），所以直接复用上一个用户态进程的虚拟地址空间就可以避免为内核线程分配 mm_struct 和相关页表的开销，以及避免内核线程之间调度时地址空间的切换开销。</p>
<p><strong>父进程与子进程的区别，进程与线程的区别，以及内核线程与用户态线程的区别其实都是围绕着这个 mm_struct 展开的。</strong></p>
<h3 id="3-1-内核如何划分用户态和内核态虚拟内存空间"><a href="#3-1-内核如何划分用户态和内核态虚拟内存空间" class="headerlink" title="3.1 内核如何划分用户态和内核态虚拟内存空间"></a>3.1 内核如何划分用户态和内核态虚拟内存空间</h3><p>进程的虚拟内存空间分为两个部分：一部分是用户态虚拟内存空间，另一部分是内核态虚拟内存空间。那么用户态的地址空间和内核态的地址空间在内核中是如何被划分的呢？<br>这就用到了进程的内存描述符 mm_struct 结构体中的 task_size 变量，task_size 定义了用户态地址空间与内核态地址空间之间的分界线。</p>
<h3 id="3-2-如何布局虚拟内存地址空间"><a href="#3-2-如何布局虚拟内存地址空间" class="headerlink" title="3.2 如何布局虚拟内存地址空间"></a>3.2 如何布局虚拟内存地址空间</h3><p>内核中采用了一个叫做内存描述符的 mm_struct 结构体来表示进程虚拟内存空间的全部信息。</p>
<pre><code>struct mm_struct &#123;
    unsigned long task_size;    /* size of task vm space */
    unsigned long start_code, end_code, start_data, end_data;
    unsigned long start_brk, brk, start_stack;
    unsigned long arg_start, arg_end, env_start, env_end;
    unsigned long mmap_base;  /* base of mmap area */
    unsigned long total_vm;    /* Total pages mapped */
    unsigned long locked_vm;  /* Pages that have PG_mlocked set */
    unsigned long pinned_vm;  /* Refcount permanently increased */
    unsigned long data_vm;    /* VM_WRITE &amp; ~VM_SHARED &amp; ~VM_STACK */
    unsigned long exec_vm;    /* VM_EXEC &amp; ~VM_WRITE &amp; ~VM_STACK */
    unsigned long stack_vm;    /* VM_STACK */

      ...... 省略 ........
&#125;
</code></pre>
<p>对应的是下面这个图：</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819210113.png"></p>
<h3 id="3-3-虚拟内存区域结构体"><a href="#3-3-虚拟内存区域结构体" class="headerlink" title="3.3 虚拟内存区域结构体"></a>3.3 虚拟内存区域结构体</h3><p>内核是通过一个mm_struct结构体，我们知道内核是通过一个 mm_struct 结构的内存描述符来表示进程的虚拟内存空间的，并通过 task_size 域来划分用户态虚拟内存空间和内核态虚拟内存空间。<br>&#x3D;&#x3D;虚拟内存区域结构体 VMA&#x3D;&#x3D;</p>
<pre><code>struct vm_area_struct &#123;

    unsigned long vm_start;        /* Our start address within vm_mm. */
    unsigned long vm_end;        /* The first byte after our end address
                      within vm_mm. */
    /*
    * Access permissions of this VMA.
    */
    pgprot_t vm_page_prot;
    unsigned long vm_flags;    

    struct anon_vma *anon_vma;    /* Serialized by page_table_lock */
    struct file * vm_file;        /* File we map to (can be NULL). */
    unsigned long vm_pgoff;        /* Offset (within vm_file) in PAGE_SIZE
                      units */    
    void * vm_private_data;        /* was vm_pte (shared mem) */
    /* Function pointers to deal with this struct. */
    const struct vm_operations_struct *vm_ops;
&#125;
</code></pre>
<p>每个 vm_area_struct 结构对应于虚拟内存空间中的唯一虚拟内存区域 VMA，vm_start 指向了这块虚拟内存区域的起始地址（最低地址），vm_start 本身包含在这块虚拟内存区域内。vm_end 指向了这块虚拟内存区域的结束地址（最高地址），而 vm_end 本身包含在这块虚拟内存区域之外，所以 vm_area_struct 结构描述的是 [vm_start，vm_end) 这样一段左闭右开的虚拟内存区域。</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819210800.png"></p>
<h3 id="3-4-定义虚拟内存区域的访问权限和行为规范"><a href="#3-4-定义虚拟内存区域的访问权限和行为规范" class="headerlink" title="3.4 定义虚拟内存区域的访问权限和行为规范"></a>3.4 定义虚拟内存区域的访问权限和行为规范</h3><p>vm_page_prot 和 vm_flags 都是用来标记 vm_area_struct 结构表示的这块虚拟内存区域的访问权限和行为规范。</p>
<ul>
<li>vm_page_prot 偏向于定义底层内存管理架构中页这一级别的访问控制权限，它可以直接应用在<strong>底层页表</strong>中，它是一个具体的概念。</li>
<li>vm_flags <strong>偏向于定于整个虚拟内存区域的访问权限以及行为规范</strong>。描述的是虚拟内存区域中的整体信息，而不是虚拟内存区域中具体的某个独立页面。</li>
</ul>
<p>参数有以下几个：<br>VM_READ	可读<br>VM_WRITE	可写<br>VM_EXEC	可执行<br>VM_SHARD	可多进程之间共享<br>VM_IO	可映射至设备 IO 空间<br>VM_RESERVED	内存区域不可被换出<br>VM_SEQ_READ	内存区域可能被顺序访问<br>VM_RAND_READ	内存区域可能被随机访问<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819211044.png"></p>
<h3 id="3-5虚拟内存区域在内核中如何被组织的？"><a href="#3-5虚拟内存区域在内核中如何被组织的？" class="headerlink" title="3.5虚拟内存区域在内核中如何被组织的？"></a>3.5虚拟内存区域在内核中如何被组织的？</h3><p>struct vm_area_struct 结构的双向链表将虚拟内存空间中的这些虚拟内存区域 VMA 串联起来的。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240819212619.png"></p>
<h3 id="4-程序编译后的二进制文件如何映射到虚拟内存空间中"><a href="#4-程序编译后的二进制文件如何映射到虚拟内存空间中" class="headerlink" title="4.程序编译后的二进制文件如何映射到虚拟内存空间中"></a>4.程序编译后的二进制文件如何映射到虚拟内存空间中</h3><p>我们写的程序代码编译之后会生成一个 ELF 格式的二进制文件，这个二进制文件中包含了程序运行时所需要的元信息，比如程序的机器码，程序中的全局变量以及静态变量等。<br>这个 ELF 格式的二进制文件中的布局和我们前边讲的虚拟内存空间中的布局类似，也是一段一段的，每一段包含了不同的元数据。<br><strong>磁盘文件中的段我们叫做 Section，内存中的段我们叫做 Segment，也就是内存区域。</strong><br>通常是多个 Section 映射到一个 Segment。<br>比如磁盘文件中的 .text，.rodata 等一些只读的 Section，会被映射到内存的一个只读可执行的 Segment 里（代码段）。而 .data，.bss 等一些可读写的 Section，则会被映射到内存的一个具有读写权限的 Segment 里（数据段，BSS 段）。<br>映射过程用到的函数：&#x3D;&#x3D;load__elf_binary&#x3D;&#x3D;<br><strong>映射的步骤</strong></p>
<ul>
<li><strong>设置内存映射地址</strong>：setup_new_exec 设置虚拟内存空间中的内存映射区域起始地址 mmap_base</li>
<li><strong>初始化栈</strong>：setup_arg_pages 创建并初始化栈对应的 vm_area_struct 结构。置 mm-&gt;start_stack 就是栈的起始地址也就是栈底，并将 mm-&gt;arg_start 是指向栈底的。</li>
<li><strong>将二进制文件中的不同部分映射到虚拟空间代码段</strong>：elf_map 将 ELF 格式的二进制文件中.text ，.data，.bss 部分映射到虚拟内存空间中的代码段，数据段，BSS 段中。</li>
<li><strong>初始化堆</strong>：set_brk 创建并初始化堆对应的的 vm_area_struct 结构，设置 current-&gt;mm-&gt;start_brk &#x3D; current-&gt;mm-&gt;brk，设置堆的起始地址 start_brk，结束地址 brk。 起初两者相等表示堆是空的。</li>
<li><strong>初始化内存映射区域</strong>：load_elf_interp 将进程依赖的动态链接库 .so 文件映射到虚拟内存空间中的内存映射区域</li>
<li><strong>初始化内存描述符</strong> mm_struct</li>
</ul>
<h2 id="4-内核虚拟内存空间"><a href="#4-内核虚拟内存空间" class="headerlink" title="4.内核虚拟内存空间"></a>4.内核虚拟内存空间</h2><p>之前在介绍进程虚拟内存空间的时候，我提到不同进程之间的虚拟内存空间是<strong>相互隔离</strong>的，彼此之间<strong>相互独立</strong>，相互感知不到其他进程的存在。使得进程以为自己拥有所有的内存资源。<br>而内核态虚拟内存空间是所有进程共享的，不同进程进入内核态之后看到的&#x3D;&#x3D;虚拟内存空间全部是一样&#x3D;&#x3D;的。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820101724.png"><br>比如上图中的进程 a，进程 b，进程 c 分别在各自的用户态虚拟内存空间中访问虚拟地址 x 。由于进程之间的用户态虚拟内存空间是相互隔离相互独立的，虽然在进程a，进程b，进程c 访问的都是虚拟地址 x 但是看到的内容却是不一样的（背后可能映射到不同的物理内存中）。</p>
<p>但是当进程 a，进程 b，进程 c 进入到内核态之后情况就不一样了，由于内核虚拟内存空间是<strong>各个进程共享的</strong>，所以它们在内核空间中看到的内容全部是一样的，比如进程 a，进程 b，进程 c 在内核态都去访问虚拟地址 y。这时它们看到的内容就是一样的了。</p>
<p><em><strong>但是也不要想成：由于内核会涉及到物理内存的管理，所以很多人会想当然地认为只要进入了内核态就开始使用物理地址了！进程进入内核态之后使用的仍然是虚拟内存地址，只不过在内核中使用的虚拟内存地址被限制在了内核态虚拟内存空间范围中</strong></em></p>
<h3 id="4-1-32-位体系内核虚拟内存空间布局"><a href="#4-1-32-位体系内核虚拟内存空间布局" class="headerlink" title="4.1 32 位体系内核虚拟内存空间布局"></a>4.1 32 位体系内核虚拟内存空间布局</h3><p>内核空间也就是之前介绍的高地址的0xC000 0000——0xFFFF FFFF这个1GB的地址空间内。</p>
<h4 id="4-1-1-直接映射区"><a href="#4-1-1-直接映射区" class="headerlink" title="4.1.1 直接映射区"></a>4.1.1 直接映射区</h4><p>在总共大小 1G 的内核虚拟内存空间中，位于最前边有一块 896M 大小的区域，我们称之为直接映射区或者线性映射区。这块连续的虚拟内存地址会映射到 0 - 896M <strong>这块连续的物理内存</strong>上。<strong>这块区域中的虚拟内存地址直接减去 0xC000 0000 (3G) 就得到了物理内存地址。</strong><br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820102456.png"></p>
<p>当进程被创建完毕之后，在内核运行的过程中，会涉及内核栈的分配，内核会为每个进程分配一个固定大小的内核栈（一般是两个页大小，依赖具体的体系结构，一般来说1页大小时4kB）。与进程用户空间中的栈不同的是，<strong>内核栈容量小而且是固定的</strong>，用户空间中的栈容量大而且可以动态扩展。内核栈的溢出危害非常巨大，它会直接悄无声息的覆盖相邻内存区域中的数据，破坏数据。</p>
<p>正常来说任何数据页都可以放在任何页框中，但是没有限制，但是实际的计算机体系收到了硬件方面的限制，这样就会导致限制了页框的使用方式。例如：在 X86 体系结构下，ISA 总线的 DMA （直接内存存取）控制器，只能对内存的前16M 进行寻址，这就导致了 ISA 设备不能在整个 32 位地址空间中执行 DMA，只能使用物理内存的前 16M 进行 DMA 操作。直接映射区的前 16M 专门让内核用来为 DMA 分配内存，这块 16M 大小的内存区域我们称之为 ZONE_DMA。这样来看的话<strong>用于DMA的内存就必须要从ZONE_DMA区域中分配出来</strong>。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820103054.png"></p>
<h3 id="4-1-2-ZONE-HIGHMEM高端内存"><a href="#4-1-2-ZONE-HIGHMEM高端内存" class="headerlink" title="4.1.2 ZONE_HIGHMEM高端内存"></a>4.1.2 ZONE_HIGHMEM高端内存</h3><p>物理内存 896M 以上的区域被内核划分为 ZONE_HIGHMEM 区域，我们称之为高端内存。</p>
<p>由于内核虚拟内存空间中的前 896M 虚拟内存已经被直接映射区所占用，而在 32 体系结构下内核虚拟内存空间总共也就 1G 的大小，这样一来内核剩余可用的虚拟内存空间就变为了 1G - 896M &#x3D; 128M。</p>
<p>显然物理内存中 3200M 大小的 ZONE_HIGHMEM 区域无法继续通过直接映射的方式映射到这 128M 大小的虚拟内存空间中。</p>
<p>这样一来物理内存中的 ZONE_HIGHMEM 区域就只能采用动态映射的方式映射到 128M 大小的内核虚拟内存空间中，也就是说只能动态的一部分一部分的分批映射，先映射正在使用的这部分，使用完毕解除映射，接着映射其他部分。</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820103608.png"></p>
<p>内核虚拟内存空间中的 3G + 896M 这块地址在内核中定义为 high_memory，high_memory 往上有一段 8M 大小的内存空洞。空洞范围为：high_memory 到 <strong>VMALLOC_START</strong> 。</p>
<h3 id="4-1-3-vmalloc动态映射区"><a href="#4-1-3-vmalloc动态映射区" class="headerlink" title="4.1.3 vmalloc动态映射区"></a>4.1.3 vmalloc动态映射区</h3><p>接下来 VMALLOC_START 到 VMALLOC_END 之间的这块区域成为动态映射区。</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820103830.png"></p>
<p>和用户态进程使用 malloc 申请内存一样，在这块动态映射区内核是使用 vmalloc 进行内存分配。由于之前介绍的动态映射的原因，vmalloc 分配的内存在虚拟内存上是连续的，但是物理内存是不连续的。通过页表来建立物理内存与虚拟内存之间的映射关系，从而可以将不连续的物理内存映射到连续的虚拟内存上。</p>
<h3 id="4-1-4-永久映射区"><a href="#4-1-4-永久映射区" class="headerlink" title="4.1.4 永久映射区"></a>4.1.4 永久映射区</h3><p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820103932.png"><br>PKMAP_BASE 到 FIXADDR_START 之间的这段空间称为永久映射区。在内核的这段虚拟地址空间中允许建立与物理高端内存的长期映射关系。比如内核通过 alloc_pages() 函数在物理内存的高端内存中申请获取到的物理内存页，这些物理内存页可以通过调用 kmap 映射到永久映射区中。</p>
<h3 id="4-1-5-固定映射区"><a href="#4-1-5-固定映射区" class="headerlink" title="4.1.5 固定映射区"></a>4.1.5 固定映射区</h3><p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820105020.png"></p>
<p>在内核虚拟内存空间的直接映射区中，直接映射区中的虚拟内存地址与物理内存前 896M 的空间的映射关系都是预设好的，一比一映射。</p>
<p><strong>注</strong>：<br>与动态映射区以及永久映射区不同的是，在固定映射区中虚拟地址是固定的，而被映射的物理地址是可以改变的。也就是说，有些<strong>虚拟地址在编译的时候就固定下来</strong>了，是在内核启动过程中被确定的，而这些虚拟地址对应的物理地址不是固定的。</p>
<p><em><strong>那为什么会有固定映射这个概念呢？</strong></em><br>比如：在内核的启动过程中，有些模块需要使用虚拟内存并映射到指定的物理地址上，而且这些模块也&#x3D;&#x3D;没有办法等待完整的内存管理模块初始化之后再进行地址映射&#x3D;&#x3D;。因此，内核固定分配了一些虚拟地址，这些地址有固定的用途，使用该地址的模块在初始化的时候，将这些固定分配的虚拟地址映射到指定的物理地址上去。</p>
<h3 id="4-1-6-临时映射区"><a href="#4-1-6-临时映射区" class="headerlink" title="4.1.6 临时映射区"></a>4.1.6 临时映射区</h3><p>内核虚拟内存空间中的最后一块区域为临时映射区，给我的感觉临时映射区更像是，当只允许虚拟地址传输时手里只有物理地址，因此需要映射得到一个虚拟地址。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820105420.png"></p>
<h3 id="5-物理内存"><a href="#5-物理内存" class="headerlink" title="5 物理内存"></a>5 物理内存</h3><h4 id="5-1-RAM"><a href="#5-1-RAM" class="headerlink" title="5.1 RAM"></a>5.1 RAM</h4><p>RAM分两种</p>
<ul>
<li>静态RAM（SRAM）这类 SRAM <strong>用于 CPU 高速缓存</strong> L1Cache，L2Cache，L3Cache。其特点是访问速度快，访问速度为 1 - 30 个时钟周期，但是容量小，造价高。</li>
<li>动态RAM（DRAM）这类 DRAM 用于我们常说的主存上，其特点的是访问速度慢（相对高速缓存），访问速度为 50 - 200 个时钟周期，但是容量大，造价便宜些（相对高速缓存）。</li>
</ul>
<p><em><strong>为什么叫静态和动态？</strong></em><br>SRAM：被称为静态是因为其存储的数据<strong>在电源不断的情况下</strong>不需要刷新操作，因此数据存储是“静态”的。<br>DRAM：被称为动态是因为其存储的数据需要<strong>定期刷新操作</strong>来保持数据的完整性，因此数据存储是“动态”的。</p>
<h1 id="3-进程管理"><a href="#3-进程管理" class="headerlink" title="3.进程管理"></a>3.进程管理</h1><h2 id="1-进程"><a href="#1-进程" class="headerlink" title="1. 进程"></a>1. 进程</h2><p>编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个<strong>运行中的程序，就被称为「进程」（Process）</strong>。</p>
<p><em><strong>并发和并行的关系：</strong></em></p>
<ul>
<li>并发是指在单个处理器上交替执行多个任务，操作系统通过快速切换任务的执行，使得多个任务看起来像是同时运行。</li>
<li>并行指的是在多个处理器或多个处理器核心上同时执行多个任务。每个任务在独立的处理器或核心上运行，因此它们真正地“同时”执行。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820110932.png"></li>
</ul>
<h3 id="1-1-进程状态"><a href="#1-1-进程状态" class="headerlink" title="1.1 进程状态"></a>1.1 进程状态</h3><p>5种状态：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820111405.png"></p>
<p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间<strong>换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存</strong>。</p>
<p>那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。<br>另外，挂起状态可以分为两种：<br><strong>阻塞挂起状态</strong>：进程在外存（硬盘）并<strong>等待某个事件的出现</strong>；<br><strong>就绪挂起状态</strong>：进程在外存（硬盘），但只要进入内存，即刻立刻运行；<br>因此两种挂起状态加上之前的5种状态，就变成了7种状态：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820111731.png"></p>
<p>进程挂起的原因也不一定是进程所使用的内存空间不在物理内存</p>
<ul>
<li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>
<li>用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程；</li>
</ul>
<h3 id="1-2-进程的控制结构（进程控制块，PCB）"><a href="#1-2-进程的控制结构（进程控制块，PCB）" class="headerlink" title="1.2 进程的控制结构（进程控制块，PCB）"></a>1.2 进程的控制结构（进程控制块，PCB）</h3><p>在操作系统中，是用<strong>进程控制块</strong>（process control block，PCB）数据结构来描述进程的。<br><strong>PCB 是进程存在的唯一标识</strong>，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p>
<p><em><strong>PCB具体包含什么信息呢？</strong></em><br>进程描述信息：</p>
<ul>
<li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li>
<li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li>
</ul>
<p>进程控制和管理信息：</p>
<ul>
<li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li>
<li>进程优先级：进程抢占 CPU 时的优先级；</li>
</ul>
<p>资源分配清单：</p>
<ul>
<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</li>
</ul>
<p>CPU 相关信息：</p>
<ul>
<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>
</ul>
<p><em><strong>每个PCB是如何组织的呢？</strong></em><br>通常是通过<strong>链表</strong>的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如：</p>
<ul>
<li>将所有处于就绪状态的进程链在一起，称为就绪队列；</li>
<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；</li>
<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>
<li>原因：进程创建销毁等调度会导致进程状态发生改变，而链表可以更加灵活的插入和删除。</li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820112522.png"></p>
<h3 id="1-3-进程的控制"><a href="#1-3-进程的控制" class="headerlink" title="1.3 进程的控制"></a>1.3 进程的控制</h3><p><strong>进程的控制包括：</strong>创建、终止、阻塞、唤醒**<br>（1）控制进程**<br>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。<br>创建进程的过程如下：</p>
<ul>
<li><strong>申请PCB块</strong>：申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；</li>
<li><strong>分配资源</strong>：为该进程分配运行时所必需的资源，比如内存资源；</li>
<li><strong>插入就绪队列</strong>：将 PCB 插入到就绪队列，等待被调度运行；</li>
</ul>
<p><strong>（2）终止进程</strong><br>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。</p>
<p>当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。</p>
<p>终止进程的过程如下：</p>
<ul>
<li>查找需要终止的进程的 PCB；</li>
<li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li>
<li>如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；</li>
<li>将该进程所拥有的全部资源都归还给操作系统；</li>
<li>将其从 PCB 所在队列中删除；</li>
</ul>
<p><strong>（3）阻塞进程</strong><br>当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。<br>阻塞进程的过程如下：</p>
<ul>
<li>找到将要被阻塞进程标识号对应的 PCB；</li>
<li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li>
<li>将该 PCB 插入到阻塞队列中去；</li>
</ul>
<p><strong>（4）唤醒进程</strong><br>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。<br>如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。<br>唤醒进程的过程如下：</p>
<ul>
<li>在该事件的阻塞队列中找到相应进程的 PCB；</li>
<li>将其从阻塞队列中移出，并置其状态为就绪状态；</li>
<li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li>
</ul>
<p>感觉这些进程过程基本都是：找到&#x2F;创建PCB序列号——&gt;保护现场——&gt;移动队列</p>
<h3 id="1-4-进程的上下文切换"><a href="#1-4-进程的上下文切换" class="headerlink" title="1.4 进程的上下文切换"></a>1.4 进程的上下文切换</h3><p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为<strong>进程的上下文切换</strong>。</p>
<p><em><strong>CPU上下文切换</strong></em></p>
<p>任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器（用于记录程序运行到哪一步）。CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 <strong>CPU 上下文</strong>。<br>CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。<br>系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。<br>根据任务的不同，把 CPU 上下文切换分成：<strong>进程上下文切换、线程上下文切换和中断上下文切换</strong>。</p>
<p><em><strong>进程的上下文切换到底是切换什么呢？</strong></em></p>
<p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。<br>所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。<br>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行，如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820144435.png"></p>
<p><em><strong>进程上下文切换的场景</strong></em></p>
<ul>
<li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的<strong>时间片</strong>，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li>
<li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li>
<li>当进程通过<strong>睡眠函数</strong> sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li>
<li>当有<strong>优先级更高的进程</strong>运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li>
<li>发生<strong>硬件中断</strong>时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li>
</ul>
<h2 id="2-线程"><a href="#2-线程" class="headerlink" title="2.线程"></a>2.线程</h2><p>更小的能独立运行的基本单位，也就是线程。</p>
<h3 id="2-1-什么是线程"><a href="#2-1-什么是线程" class="headerlink" title="2.1 什么是线程"></a>2.1 什么是线程</h3><p><strong>线程是进程中的一条执行流程。</strong><br>同一个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有一套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。</p>
<h3 id="2-2-线程与进程的比较"><a href="#2-2-线程与进程的比较" class="headerlink" title="2.2 线程与进程的比较"></a>2.2 线程与进程的比较</h3><p>进程与线程比较：</p>
<ul>
<li>进程是资源分配的单位，线程是CPU调度的单位。</li>
<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>
<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>
<li>线程能减少并发执行的时间和空间开销；</li>
</ul>
<p>线程相比进程能减少开销，体现在：</p>
<ul>
<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>
<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>
<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>
<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>
</ul>
<h3 id="2-3-线程的上下文切换"><a href="#2-3-线程的上下文切换" class="headerlink" title="2.3 线程的上下文切换"></a>2.3 线程的上下文切换</h3><p>操作系统的任务调度，实际上的调度对象是线程，而进程只是给线程提供了<strong>虚拟内存、全局变量</strong>等资源。</p>
<p>对于线程和进程，我们可以这么理解：</p>
<ul>
<li>当进程只有一个线程时，可以认为进程就等于线程；</li>
<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是<strong>不需要修改的</strong>；</li>
</ul>
<p><em><strong>线程上下文切换的是什么？</strong></em><br>这还得看线程是不是属于同一个进程：</p>
<ul>
<li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；</li>
<li>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，<strong>虚拟内存这些资源就保持不动</strong>，只需要切换线程的私有数据、寄存器等不共享的数据；</li>
</ul>
<p>所以，线程的上下文切换相比进程，开销要小很多。</p>
<h3 id="2-4-线程实现"><a href="#2-4-线程实现" class="headerlink" title="2.4 线程实现"></a>2.4 线程实现</h3><h4 id="三种实现的方式："><a href="#三种实现的方式：" class="headerlink" title="三种实现的方式："></a><em><strong>三种实现的方式</strong></em>：</h4><ul>
<li>用户线程：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li>
<li>内核线程：在内核中实现的线程，是由内核管理的线程；</li>
<li>轻量级进程：在内核中来支持用户线程；</li>
</ul>
<h4 id="用户线程和内核线程的对应关系："><a href="#用户线程和内核线程的对应关系：" class="headerlink" title="用户线程和内核线程的对应关系："></a><em><strong>用户线程和内核线程的对应关系</strong></em>：</h4><ul>
<li>多对一关系：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820151903.png"></li>
<li>一对一关系：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820151911.png"></li>
<li>多对多关系：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820151928.png"></li>
</ul>
<h4 id="x3D-x3D-用户线程如何理解？存在什么优势和缺陷？-x3D-x3D"><a href="#x3D-x3D-用户线程如何理解？存在什么优势和缺陷？-x3D-x3D" class="headerlink" title="&#x3D;&#x3D;用户线程如何理解？存在什么优势和缺陷？&#x3D;&#x3D;"></a>&#x3D;&#x3D;<em><strong>用户线程如何理解？存在什么优势和缺陷？</strong></em>&#x3D;&#x3D;</h4><p>用户线程是基于用户态的线程管理库来实现的，那么<strong>线程控制块</strong>（Thread Control Block,<strong>TCB</strong>） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。</p>
<p>所以，<strong>用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等</strong>。</p>
<p><strong>用户线程优点</strong>：</p>
<ul>
<li><strong>库函数维护</strong>：每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li>
<li><strong>无需内核态切换速度快</strong>：用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li>
</ul>
<p><strong>用户线程的缺点</strong>：</p>
<ul>
<li>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</li>
<li><strong>其他线程无法打断当前线程</strong>：当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</li>
<li><strong>资源调度单位是进程，所以相较其他进程时间片要少</strong>：由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；</li>
</ul>
<h4 id="x3D-x3D-那内核线程如何理解？存在什么优势和缺陷？-x3D-x3D"><a href="#x3D-x3D-那内核线程如何理解？存在什么优势和缺陷？-x3D-x3D" class="headerlink" title="&#x3D;&#x3D;那内核线程如何理解？存在什么优势和缺陷？&#x3D;&#x3D;"></a>&#x3D;&#x3D;<em><strong>那内核线程如何理解？存在什么优势和缺陷？</strong></em>&#x3D;&#x3D;</h4><p>内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。</p>
<p><strong>优点：</strong></p>
<ul>
<li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li>
<li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li>
</ul>
<p><strong>缺点：</strong></p>
<ul>
<li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li>
<li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；</li>
</ul>
<h4 id="x3D-x3D-轻量级进程-x3D-x3D"><a href="#x3D-x3D-轻量级进程-x3D-x3D" class="headerlink" title="&#x3D;&#x3D;轻量级进程&#x3D;&#x3D;"></a>&#x3D;&#x3D;<em><strong>轻量级进程</strong></em>&#x3D;&#x3D;</h4><p>轻量级进程（Light-weight process，LWP）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程<strong>一对一映射的</strong>，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820153810.png"></p>
<p><strong>1:1模式</strong><br>一个线程对应一个LWP在对应一个内核线程</p>
<ul>
<li>优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；</li>
<li>缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。</li>
</ul>
<p><strong>N:1模式</strong><br>多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。</p>
<ul>
<li>优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；</li>
<li>缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。</li>
</ul>
<p><strong>M : N 模式</strong><br>根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。</p>
<ul>
<li>优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。</li>
</ul>
<h2 id="3-调度"><a href="#3-调度" class="headerlink" title="3. 调度"></a>3. 调度</h2><p>进程都希望自己能够占用 CPU 进行工作，那么这涉及到前面说过的进程上下文切换。<br>一旦操作系统把进程切换到运行状态，也就意味着该进程占用着 CPU 在执行，但是当操作系统把进程切换到其他状态时，那就不能在 CPU 中执行了，于是操作系统会选择下一个要运行的进程。<br>选择一个进程运行这一功能是在操作系统中完成的，通常称为<strong>调度程序</strong>（scheduler）。</p>
<h3 id="3-1-调度算法分类"><a href="#3-1-调度算法分类" class="headerlink" title="3.1 调度算法分类"></a>3.1 调度算法分类</h3><p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p>
<p>如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p>
<ul>
<li><strong>非抢占式调度算法</strong>：挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说<strong>不会理时钟中断</strong>这个事情。</li>
<li><strong>抢占式调度算法</strong>：挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要<strong>在时间间隔的末端发生时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。</li>
</ul>
<h3 id="3-2-调度原则"><a href="#3-2-调度原则" class="headerlink" title="3.2 调度原则"></a>3.2 调度原则</h3><ul>
<li><strong>CPU 利用率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>
<li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>
<li><strong>周转时间</strong>：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>
<li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，而是&#x3D;&#x3D;进程处于就绪队列&#x3D;&#x3D;的时间，等待的时间越长，用户越不满意；</li>
<li><strong>响应时间</strong>：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>
</ul>
<h3 id="3-3-调度算法"><a href="#3-3-调度算法" class="headerlink" title="3.3 调度算法"></a>3.3 调度算法</h3><p>接下来，说说在<strong>单核 CPU 系统中常见的调度算法</strong>。</p>
<h4 id="01-先来先服务算法（FCFS）"><a href="#01-先来先服务算法（FCFS）" class="headerlink" title="01 先来先服务算法（FCFS）"></a>01 先来先服务算法（FCFS）</h4><p><strong>非抢占式的先来先服务（First Come First Serve, FCFS）算法</strong><br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820161537.png"><br>先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。说白了FCFS就是一旦开始运行就会直到运行结束或者是运行到主观的一个阻塞状态，并不是时间片的阻塞。</p>
<p>这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。</p>
<p>FCFS 对长作业有利，适用于 <strong>CPU 繁忙型作业的系统</strong>，而不适用于 <strong>I&#x2F;O 繁忙型作业的系统</strong>。</p>
<h4 id="02-最短作业优先调度算法（SJF）"><a href="#02-最短作业优先调度算法（SJF）" class="headerlink" title="02 最短作业优先调度算法（SJF）"></a>02 最短作业优先调度算法（SJF）</h4><p><strong>最短作业优先（Shortest Job First, SJF）</strong>调度算法同样也是顾名思义，它会<strong>优先选择运行时间最短的进程</strong>来运行，这有助于提高系统的吞吐量。</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820162027.png"></p>
<p>这显然对长作业不利，很容易造成一种极端现象。</p>
<p>比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。</p>
<h4 id="03-高响应比优先调度算法（HRRN）"><a href="#03-高响应比优先调度算法（HRRN）" class="headerlink" title="03 高响应比优先调度算法（HRRN）"></a>03 高响应比优先调度算法（HRRN）</h4><p>高响应比优先 （<strong>Highest Response Ratio Next, HRRN</strong>）调度算法主要是权衡了短作业和长作业。</p>
<p>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820162321.png"><br>由上面的公式可以得到：</p>
<ul>
<li>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；</li>
<li>如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；</li>
</ul>
<p><em><strong>注：要求服务时间不可预知，所以这只是一个理想的调度算法，现实中无法实现</strong></em></p>
<h4 id="04-时间片轮转调度算法（RR）"><a href="#04-时间片轮转调度算法（RR）" class="headerlink" title="04 时间片轮转调度算法（RR）"></a>04 时间片轮转调度算法（RR）</h4><p>最古老、最简单、最公平且使用最广的算法就是<strong>时间片轮转</strong>（Round Robin, RR）调度算法。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820162524.png"></p>
<p><strong>进程被分配一个时间段，称为时间片，允许进程在时间段中运行</strong></p>
<ul>
<li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li>
<li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li>
</ul>
<p>另外，时间片的长度就是一个很关键的点：</p>
<ul>
<li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li>
<li>如果设得太长又可能引起对短作业进程的响应时间变长。<br>一般来说，时间片设为 &#x3D;&#x3D;20ms~50ms&#x3D;&#x3D; 通常是一个比较合理的折中值。</li>
</ul>
<h4 id="05-最高优先级调度算法（HPF）"><a href="#05-最高优先级调度算法（HPF）" class="headerlink" title="05 最高优先级调度算法（HPF）"></a>05 最高优先级调度算法（HPF）</h4><p>对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为<strong>最高优先级（Highest Priority First，HPF）调度算法</strong>。</p>
<p>进程的优先级可以分为，静态优先级和动态优先级：</p>
<ul>
<li><strong>静态优先级</strong>：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li>
<li><strong>动态优先级</strong>：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。</li>
</ul>
<p>该算法也有两种处理优先级高的方法，非抢占式和抢占式：</p>
<ul>
<li>非抢占式：当就绪队列中出现优先级高的进程，<strong>运行完</strong>当前进程，再选择优先级高的进程。</li>
<li>抢占式：当就绪队列中出现优先级高的进程，<strong>当前进程挂起</strong>，调度优先级高的进程运行。</li>
</ul>
<p>但是依然有缺点，可能会导致低优先级的进程永远不会运行。</p>
<h4 id="06-多级反馈队列调度算法（MFQ）"><a href="#06-多级反馈队列调度算法（MFQ）" class="headerlink" title="06 多级反馈队列调度算法（MFQ）"></a>06 多级反馈队列调度算法（MFQ）</h4><p>多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>
<ul>
<li>「多级」表示有多个队列，每个队列优先级从高到低，同时<strong>优先级越高时间片越短</strong>。</li>
<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820163011.png"></li>
</ul>
<p><em><strong>如何工作的：</strong></em></p>
<ul>
<li>设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；</li>
<li>新的进程会被放入到第一级队列的末尾，按&#x3D;&#x3D;先来先服务的原则&#x3D;&#x3D;排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li>
<li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li>
</ul>
<p><em><strong>高优先级队列中的进程可以在其时间片内运行，如果它未能在时间片内完成，将被移动到更低优先级的队列中，或者被继续调度执行。使用多级反馈队列调度算法时，无法由用户或进程直接输入或设置其自身的优先级</strong></em></p>
<p>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。</p>
<p><strong>举个例子：</strong><br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820163641.png"></p>
<ul>
<li>银行设置了多个排队（就绪）队列，每个队列都有不同的优先级，各个队列优先级从高到低，同时每个队列执行时间片的长度也不同，优先级越高的时间片越短。</li>
<li>新客户（进程）来了，先进入第一级队列的末尾，按先来先服务原则排队等待被叫号（运行）。如果时间片用完客户的业务还没办理完成，则让客户进入到下一级队列的末尾，以此类推，直至客户业务办理完成。</li>
<li>当第一级队列没人排队时，就会叫号二级队列的客户。如果客户办理业务过程中，有新的客户加入到较高优先级的队列，那么此时办理中的客户需要停止办理，回到原队列的末尾等待再次叫号，因为要把窗口让给刚进入较高优先级队列的客户。</li>
</ul>
<h3 id="3-4-锁"><a href="#3-4-锁" class="headerlink" title="3.4 锁"></a>3.4 锁</h3><h4 id="3-4-1-死锁的产生需要满足4个条件"><a href="#3-4-1-死锁的产生需要满足4个条件" class="headerlink" title="3.4.1 死锁的产生需要满足4个条件"></a>3.4.1 死锁的产生需要满足4个条件</h4><ul>
<li>互斥条件：多个线程不能同时使用同一个资源</li>
<li>持有并等待条件：线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1</li>
<li>不可剥夺条件：无法强制夺取资源，用完之前无法被其他线程夺取</li>
<li>环路等待条件：两个线程获取资源的顺序构成了环形链</li>
</ul>
<h4 id="3-4-2-锁的种类"><a href="#3-4-2-锁的种类" class="headerlink" title="3.4.2 锁的种类"></a>3.4.2 锁的种类</h4><p>常见的几种锁：互斥锁、自旋锁、读写锁、悲观锁、乐观锁</p>
<p><em><strong>互斥锁与自旋锁</strong></em></p>
<ul>
<li>互斥锁加锁失败后，线程会释放 CPU ，给其他线程；</li>
<li>自旋锁加锁失败后，线程会忙等待，直到它拿到锁；</li>
</ul>
<p>互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。</p>
<p><em><strong>读写锁</strong></em><br>读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁</p>
<p><em><strong>乐观锁与悲观锁</strong></em></p>
<ul>
<li>悲观锁：多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。</li>
<li>乐观锁：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。</li>
</ul>
<p>这里举一个场景例子：在线文档。<br>我们都知道在线文档可以同时多人编辑的，如果使用了悲观锁，那么只要有一个用户正在编辑文档，此时其他用户就无法打开相同的文档了，这用户体验当然不好了。<br>那实现多人同时编辑，实际上是用了乐观锁，它允许多个用户打开同一个文档进行编辑，编辑完提交之后才验证修改的内容是否有冲突。</p>
<p><strong>服务端要怎么验证是否冲突了呢？通常方案如下：</strong><br>由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；<br>当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。</p>
<p><em><strong>一个线程可以创建多少个线程</strong></em></p>
<ul>
<li>32 位系统的内核空间占用 1G ，位于最高处，剩下的 3G 是用户空间;</li>
<li>64 位系统的内核空间和用户空间都是 128T ，分别占据整个内存空间的最高和最低处，剩下的中 间部分是未定义的。</li>
</ul>
<p>其中能创造多少个线程跟两个东西有关系：一个是虚拟内存的上限，另一个是系统参数的限制。<br>我们先看看，在进程里创建一个线程需要消耗多少虚拟内存大小？<br>我们可以执行 ulimit -a 这条命令，查看进程创建线程时默认分配的栈空间大小，比如我这台服务器默认分配给线程的栈空间大小为 8M。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820171422.png"></p>
<p><strong>32位系统</strong>：<br>一个进程的虚拟空间是 4G，内核分走了1G，留给用户用的只有 3G。那么假设创建一个线程需要占用 10M 虚拟内存，总共有 3G 虚拟内存可以使用。于是我们可以算出，最多可以创建差不多 300 个（3G&#x2F;10M）左右的线程。</p>
<p><strong>64位系统</strong>:<br>64 位系统意味着用户空间的虚拟内存最大值是 128T，这个数值是很大的，如果按创建一个线程需占用 10M 栈空间的情况来算，那么理论上可以创建 128T&#x2F;10M 个线程，也就是 1000多万个线程，有点魔幻！<br>下面这三个内核参数的大小，都会影响创建线程的上限：<br>proc&#x2F;sys&#x2F;kernel&#x2F;threads-max，表示系统支持的最大线程数，默认值是 14553；</p>
<p><em><strong>线程崩溃进程一定会崩溃嘛？</strong></em><br>一般来说如果线程是因为非法访问内存引起的崩溃，那么进程肯定会崩溃，为什么系统要让进程崩溃呢，这主要是因为在进程中，<strong>各个线程的地址空间是共享的</strong>，既然是共享，那么某个线程对地址的非法访问就会导致内存的不确定性，进而可能会影响到其他线程，这种操作是危险的，操作系统会认为这很可能导致一系列严重的后果，于是干脆让整个进程崩溃。</p>
<h1 id="4-文件系统"><a href="#4-文件系统" class="headerlink" title="4.文件系统"></a>4.文件系统</h1><h2 id="4-1-文件IO"><a href="#4-1-文件IO" class="headerlink" title="4.1 文件IO"></a>4.1 文件IO</h2><p>文件的IO种类很多常见的有：</p>
<ul>
<li>缓冲与非缓冲IO</li>
<li>直接与非直接IO</li>
<li>阻塞与非阻塞IO</li>
<li>同步与异步IO</li>
</ul>
<h3 id="4-1-1-缓冲IO与非缓冲IO"><a href="#4-1-1-缓冲IO与非缓冲IO" class="headerlink" title="4.1.1 缓冲IO与非缓冲IO"></a>4.1.1 缓冲IO与非缓冲IO</h3><p>文件操作的标准库是可以实现数据的缓存，那么根据「是否利用标准库缓冲」，可以把文件 I&#x2F;O 分为缓冲 I&#x2F;O 和非缓冲 I&#x2F;O：</p>
<ul>
<li>缓冲 I&#x2F;O，利用的是标准库的缓存实现文件的加速访问，而标准库再通过系统调用访问文件。</li>
<li>非缓冲 I&#x2F;O，直接通过系统调用访问文件，不经过标准库缓存。</li>
</ul>
<p>比方说，很多程序遇到换行时才真正输出，而换行前的内容，其实就是被标准库暂时缓存了起来，这样做的目的是，减少系统调用的次数，毕竟系统调用是有 CPU 上下文切换的开销的。</p>
<h3 id="4-1-2-直接与非直接IO"><a href="#4-1-2-直接与非直接IO" class="headerlink" title="4.1.2 直接与非直接IO"></a>4.1.2 直接与非直接IO</h3><p>我们都知道磁盘 I&#x2F;O 是非常慢的，所以 Linux 内核为了减少磁盘 I&#x2F;O 次数，在系统调用后，会把用户数据拷贝到内核中缓存起来，这个内核缓存空间也就是「页缓存」，只有当缓存满足某些条件的时候，才发起磁盘 I&#x2F;O 的请求。<br>那么，根据「<strong>是否利用操作系统的缓存</strong>」，可以把文件 I&#x2F;O 分为直接 I&#x2F;O 与非直接 I&#x2F;O：</p>
<ul>
<li><strong>直接 I&#x2F;O</strong>，不会发生内核缓存和用户程序之间数据复制，而是直接经过文件系统访问磁盘。</li>
<li><strong>非直接 I&#x2F;O</strong>，读操作时，数据从内核缓存中拷贝给用户程序，写操作时，数据从用户程序拷贝给<strong>内核缓存</strong>，再由内核决定什么时候写入数据到磁盘。</li>
</ul>
<h3 id="4-1-3-阻塞与非阻塞IO-和-同步与异步IO"><a href="#4-1-3-阻塞与非阻塞IO-和-同步与异步IO" class="headerlink" title="4.1.3 阻塞与非阻塞IO 和 同步与异步IO"></a>4.1.3 阻塞与非阻塞IO 和 同步与异步IO</h3><p>阻塞 I&#x2F;O，当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。<br>注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。过程如下图：</p>
<ul>
<li><strong>阻塞IO</strong>等待的是「<strong>内核数据准备好</strong>」和「<strong>数据从内核态拷贝到用户态</strong>」这两个过程。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820221140.png"></li>
<li><strong>非阻塞IO</strong>的read在数据未准备好的情况下立刻返回，可以立刻执行，应用程序不断轮询，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。过程如下图：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820221334.png"></li>
</ul>
<p>为了解决很呆的轮询方式，多路复用技术就出现了，如select和poll，当内核数据准备好时，再通知应用程序。</p>
<p>selectIO多路复用：<strong>read读取过程中也是一个同步的过程</strong><br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820221548.png"><br>实际上，无论是阻塞 I&#x2F;O、非阻塞 I&#x2F;O，还是基于非阻塞 I&#x2F;O 的多路复用<strong>都是同步调用。因为它们在 read 调用时，内核将数据从内核空间拷贝到应用程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间</strong>。</p>
<p>真正的异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820221750.png"></p>
<p><em><strong>为什么selcet&#x2F;poll都不是异步通知</strong></em></p>
<ul>
<li>调用 select 或 poll 函数，传入需要监视的文件描述符列表。</li>
<li>如果没有文件描述符准备好，调用者会阻塞，直到至少一个文件描述符变为可读、可写，或发生错误。</li>
<li>一旦返回，调用者可以对准备好的文件描述符进行相应的I&#x2F;O操作。</li>
</ul>
<p>举个你去饭堂吃饭的例子，你好比用户程序，饭堂好比操作系统。</p>
<p><strong>阻塞 I&#x2F;O</strong> 好比，你去饭堂吃饭，但是饭堂的菜还没做好，然后你就一直在那里等啊等，等了好长一段时间终于等到饭堂阿姨把菜端了出来（数据准备的过程），但是你还得继续等阿姨把菜（内核空间）打到你的饭盒里（用户空间），经历完这两个过程，你才可以离开。</p>
<p><strong>非阻塞 I&#x2F;O</strong> 好比，你去了饭堂，问阿姨菜做好了没有，阿姨告诉你没，你就离开了，过几十分钟，你又来饭堂问阿姨，阿姨说做好了，于是阿姨帮你把菜打到你的饭盒里，这个过程你是得等待的。</p>
<p><strong>基于非阻塞的 I&#x2F;O 多路复用</strong>好比，你去饭堂吃饭，发现有一排窗口，饭堂阿姨告诉你这些窗口都还没做好菜，等做好了再通知你，于是等啊等（select 调用中），过了一会阿姨通知你菜做好了，但是不知道哪个窗口的菜做好了，你自己看吧。于是你只能一个一个窗口去确认，后面发现 5 号窗口菜做好了，于是你让 5 号窗口的阿姨帮你打菜到饭盒里，这个打菜的过程你是要等待的，虽然时间不长。打完菜后，你自然就可以离开了。</p>
<p><strong>异步 I&#x2F;O</strong> 好比，你让饭堂阿姨将菜做好并把菜打到饭盒里后，把饭盒送到你面前，整个过程你都不需要任何等待。</p>
<h1 id="5-硬件设备管理"><a href="#5-硬件设备管理" class="headerlink" title="5.硬件设备管理"></a>5.硬件设备管理</h1><p>例子是：键盘敲入A字母，操作系统期间做了什么？</p>
<h2 id="5-1-设备控制器"><a href="#5-1-设备控制器" class="headerlink" title="5.1 设备控制器"></a>5.1 设备控制器</h2><p>为了屏蔽设备之间的差异，每个设备都有一个叫设备控制器（Device Control） 的组件，比如硬盘有硬盘控制器、显示器有视频控制器等。</p>
<p><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820223405.png"></p>
<p>设备控制器里有芯片，它可执行自己的逻辑，也有自己的寄存器，用来与 CPU 进行通信，比如：</p>
<ul>
<li>通过写入这些寄存器，操作系统可以命令设备发送数据、接收数据、开启或关闭，或者执行某些其他操作。</li>
<li>通过读取这些寄存器，操作系统可以了解设备的状态，是否准备好接收一个新的命令等。</li>
</ul>
<p>实际上，控制器是有三类寄存器，它们分别是<strong>状态寄存器（Status Register）、 命令寄存器（Command Register）以及数据寄存器（Data Register</strong>），如下图：<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820223505.png"></p>
<ul>
<li>数据寄存器，CPU 向 I&#x2F;O 设备写入需要传输的数据，比如要打印的内容是「Hello」，CPU 就要先发送一个 H 字符给到对应的 I&#x2F;O 设备。</li>
<li>命令寄存器，CPU 发送一个命令，告诉 I&#x2F;O 设备，要进行输入&#x2F;输出操作，于是就会交给 I&#x2F;O 设备去工作，任务完成后，会把状态寄存器里面的状态标记为完成。</li>
<li>状态寄存器，目的是告诉 CPU ，现在已经在工作或工作已经完成，如果已经在工作状态，CPU 再发送数据或者命令过来，都是没有用的，直到前面的工作已经完成，状态寄存标记成已完成，CPU 才能发送下一个字符和命令。</li>
</ul>
<h3 id="5-2-输入输出设备分类"><a href="#5-2-输入输出设备分类" class="headerlink" title="5.2 输入输出设备分类"></a>5.2 输入输出设备分类</h3><p> 输入输出设备可分为两大类 ：块设备（Block Device）和字符设备（Character Device）。</p>
<ul>
<li><strong>块设备</strong>，把数据存储在固定大小的块中，每个块有自己的地址，硬盘、USB 是常见的块设备。</li>
<li><strong>字符设备</strong>，以字符为单位发送或接收一个字符流，字符设备是不可寻址的，也没有任何寻道操作，鼠标是常见的字符设备。</li>
</ul>
<p>块设备通常传输的数据量会非常大，于是控制器设立了一个可读写的数据缓冲区。</p>
<ul>
<li>CPU <strong>写入</strong>数据到控制器的缓冲区时，当缓冲区的数据囤够了一部分，才会发给设备。</li>
<li>CPU 从控制器的缓冲区<strong>读取</strong>数据时，也需要缓冲区囤够了一部分，才拷贝到内存。</li>
</ul>
<p>这样做是为了，减少对设备的频繁操作。</p>
<h3 id="5-3-IO控制方式"><a href="#5-3-IO控制方式" class="headerlink" title="5.3 IO控制方式"></a>5.3 IO控制方式</h3><p>设备管理器如何通知CPU的呢？<br>答：中断</p>
<p><em><strong>中断种类</strong></em></p>
<ul>
<li>软中断：<br>由软件触发，通常由操作系统或应用程序显式发出。软中断是通过执行特定的指令来引发的，比如在x86架构中通过 INT 指令触发。软中断通常用于切换上下文、系统调用等。<br> <strong>用途</strong>：用于软件层面的任务调度、系统调用、错误处理、异常处理等。例如，操作系统可能使用软中断来实现进程调度，或者处理系统调用。</li>
<li>硬中断：<br>由外部硬件设备触发。当硬件设备需要与CPU通信时（例如，当网络适配器接收到数据包，或者当定时器到期），硬件会向CPU发送一个中断信号。CPU收到硬件中断信号后，立即暂停当前执行的指令序列，转而处理中断。<br><strong>用途</strong>：主要用于处理与外部硬件设备的交互。当设备需要CPU的注意时，比如输入设备有数据需要处理，或者计时器到了设定的时间，就会触发硬中断。</li>
</ul>
<p><em><strong>上半部与下半部</strong></em></p>
<ul>
<li><p><strong>上半部</strong>：上半部是中断发生时首先执行的部分，也就是<strong>中断服务程序</strong>（ISR）。它在中断发生时立即执行，通常需要快速完成以尽可能少地占用CPU时间。<br><strong>特点</strong>：</p>
<ul>
<li><strong>实时性高</strong>：上半部必须非常快速地执行，因为在执行上半部时，中断通常是被屏蔽的（即不能响应其他中断），以避免嵌套中断的复杂性。</li>
<li><strong>任务简单</strong>：上半部主要用于处理一些关键、紧急的任务，如确认中断源、读取或写入硬件寄存器、触发必要的信号或标志。</li>
<li><strong>不能阻塞</strong>：上半部不能进行复杂的操作，如访问慢速设备、内存分配、睡眠等待等，因为这些操作可能会导致上半部阻塞，从而影响系统的实时性。</li>
</ul>
</li>
<li><p><strong>下半部</strong>：下半部是上半部之后执行的部分，用于处理那些不需要立即处理的任务。它们可以在中断退出后或稍后执行，通常在系统允许的情况下以较低优先级运行。<br><strong>特点：</strong></p>
<ul>
<li>延迟执行：下半部不需要立即执行，它可以稍后执行，以减轻中断处理对系统性能的影响。</li>
<li>复杂任务处理：下半部可以进行相对复杂的操作，如数据处理、内存分配、与用户空间的交互等。</li>
<li>可以阻塞：下半部允许进行阻塞操作，如等待资源、睡眠等，因为它们不要求实时性。</li>
</ul>
</li>
<li><p>例子：<br><strong>上半部</strong>：当网络接口接收到数据包时，硬件触发一个中断，进入上半部。上半部快速读取数据包头部信息并将其存放到内存缓冲区，然后触发下半部处理。<br><strong>下半部</strong>：在下半部（可能是通过软中断或tasklet），数据包被进一步处理，如协议栈的处理、错误检查等，最后将处理结果交给内核或用户空间的网络栈。</p>
</li>
</ul>
<p><em><strong>DMA</strong></em><br>如果中断总是打断CPU的话一定会占用CPU的大量时间，保证CPU不参与的情况下将IO数据放入到内存中。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820225625.png"></p>
<p>工作方式如下：</p>
<ul>
<li>CPU 需对 DMA 控制器下发指令，告诉它想读取多少数据，读完的数据放在内存的某个地方就可以了；</li>
<li>接下来，DMA 控制器会向磁盘控制器发出指令，通知它从磁盘读数据到其内部的缓冲区中，接着磁盘控制器将缓冲区的数据传输到内存；</li>
<li>当磁盘控制器把数据传输到内存的操作完成后，磁盘控制器在总线上发出一个确认成功的信号到 DMA 控制器；</li>
<li>DMA 控制器收到信号后，&#x3D;&#x3D;DMA 控制器发中断通知 CPU 指令完成&#x3D;&#x3D;，CPU 就可以直接用内存里面现成的数据了；</li>
</ul>
<h3 id="5-1-4-设备驱动"><a href="#5-1-4-设备驱动" class="headerlink" title="5.1.4 设备驱动"></a>5.1.4 设备驱动</h3><h3 id="5-1-5-通用块层"><a href="#5-1-5-通用块层" class="headerlink" title="5.1.5 通用块层"></a>5.1.5 通用块层</h3><p>对于块设备，为了减少不同块设备的差异带来的影响，Linux 通过一个统一的通用块层，来管理不同的块设备。<br>通用块层是处于文件系统和磁盘驱动中间的一个块设备抽象层，它主要有两个功能：</p>
<ul>
<li>第一个功能，向上为文件系统和应用程序，提供访问块设备的标准接口，向下把各种不同的磁盘设备抽象为统一的块设备，并在内核层面，提供一个框架来管理这些设备的驱动程序；</li>
<li>第二功能，通用层还会给文件系统和应用程序发来的 I&#x2F;O 请求排队，接着会对队列重新排序、请求合并等方式，也就是 I&#x2F;O 调度，主要目的是为了提高磁盘读写的效率。</li>
</ul>
<p>Linux 内存支持 5 种 I&#x2F;O 调度算法，分别是：</p>
<ul>
<li>没有调度算法</li>
<li>先入先出调度算法</li>
<li>完全公平调度算法</li>
<li>优先级调度</li>
<li>最终期限调度算法</li>
</ul>
<p>第一种，没有调度算法，是的，你没听错，它不对文件系统和应用程序的 I&#x2F;O 做任何处理，这种算法常用在虚拟机 I&#x2F;O 中，此时磁盘 I&#x2F;O 调度算法交由物理机系统负责。</p>
<p>第二种，先入先出调度算法，这是最简单的 I&#x2F;O 调度算法，先进入 I&#x2F;O 调度队列的 I&#x2F;O 请求先发生。</p>
<p>第三种，完全公平调度算法，大部分系统都把这个算法作为默认的 I&#x2F;O 调度器，它为每个进程维护了一个 I&#x2F;O 调度队列，并按照<strong>时间片</strong>来均匀分布每个进程的 I&#x2F;O 请求。</p>
<p>第四种，优先级调度算法，顾名思义，优先级高的 I&#x2F;O 请求先发生， 它适用于运行大量进程的系统，像是桌面环境、多媒体应用等。</p>
<p>第五种，最终期限调度算法，分别为读、写请求创建了不同的 I&#x2F;O 队列，这样可以提高机械磁盘的吞吐量，并确保达到最终期限的请求被优先处理，适用于在 I&#x2F;O 压力比较大的场景，比如数据库等。</p>
<h3 id="5-1-6存储系统IO软件分层"><a href="#5-1-6存储系统IO软件分层" class="headerlink" title="5.1.6存储系统IO软件分层"></a>5.1.6存储系统IO软件分层</h3><p>可以把 Linux 存储系统的 I&#x2F;O 由上到下可以分为三个层次，分别是<strong>文件系统层、通用块层、设备层</strong>。<br><img src="https://cdn.jsdelivr.net/gh/caiji-QAQ/PICGO@master/20240820230058.png"></p>
<ul>
<li>文件系统层，包括虚拟文件系统和其他文件系统的具体实现，它向上为应用程序统一提供了标准的文件访问接口，向下会通过通用块层来存储和管理磁盘数据。</li>
<li>通用块层，包括块设备的 I&#x2F;O 队列和 I&#x2F;O 调度器，它会对文件系统的 I&#x2F;O 请求进行排队，再通过 I&#x2F;O 调度器，选择一个 I&#x2F;O 发给下一层的设备层。</li>
<li>设备层，包括硬件设备、设备控制器和驱动程序，负责最终物理设备的 I&#x2F;O 操作。</li>
</ul>

            </div>

            

            

            
                <div class="article-nav">
                    
                        <div class="article-prev">
                            <a class="prev"
                               rel="prev"
                               href="/2024/08/29/xreal/"
                            >
                            <span class="left arrow-icon flex-center">
                              <i class="fas fa-chevron-left"></i>
                            </span>
                                <span class="title flex-center">
                                <span class="post-nav-title-item">xreal</span>
                                <span class="post-nav-item">Prev posts</span>
                            </span>
                            </a>
                        </div>
                    
                    
                        <div class="article-next">
                            <a class="next"
                               rel="next"
                               href="/2024/08/19/%E5%85%AB%E8%82%A1%E9%9D%A2%E7%BB%8F/%E5%B5%8C%E5%85%A5%E5%BC%8F%E7%A1%AC%E4%BB%B6%E5%87%86%E5%A4%87/"
                            >
                            <span class="title flex-center">
                                <span class="post-nav-title-item">嵌入式硬件准备</span>
                                <span class="post-nav-item">Next posts</span>
                            </span>
                                <span class="right arrow-icon flex-center">
                              <i class="fas fa-chevron-right"></i>
                            </span>
                            </a>
                        </div>
                    
                </div>
            

            
        </div>

        
    </div>
</div>


                
            </div>

        </div>

        <div class="page-main-content-bottom">
            
<footer class="footer">
    <div class="info-container">
        <div class="copyright-info info-item">
            &copy;
            
                <span>2020</span> -
            
            2024
            
                &nbsp;<i class="fas fa-heart icon-animate"></i>
                &nbsp;<a href="/">caijiQAQ</a>
            
        </div>
        
        <div class="theme-info info-item">
            Powered by <a target="_blank" href="https://hexo.io">Hexo</a>&nbsp;|&nbsp;Theme&nbsp;<a class="theme-version" target="_blank" href="https://github.com/XPoet/hexo-theme-keep">Keep v3.6.1</a>
        </div>
        
        
    </div>
</footer>

        </div>
    </div>

    
        <div class="post-tools">
            <div class="post-tools-container">
    <ul class="tools-list">
        <!-- TOC aside toggle -->
        

        <!-- go comment -->
        
    </ul>
</div>

        </div>
    

    <div class="right-bottom-side-tools">
        <div class="side-tools-container">
    <ul class="side-tools-list">
        <li class="tools-item tool-font-adjust-plus flex-center">
            <i class="fas fa-search-plus"></i>
        </li>

        <li class="tools-item tool-font-adjust-minus flex-center">
            <i class="fas fa-search-minus"></i>
        </li>

        <li class="tools-item tool-dark-light-toggle flex-center">
            <i class="fas fa-moon"></i>
        </li>

        <!-- rss -->
        

        
            <li class="tools-item tool-scroll-to-top flex-center">
                <i class="fas fa-arrow-up"></i>
            </li>
        

        <li class="tools-item tool-scroll-to-bottom flex-center">
            <i class="fas fa-arrow-down"></i>
        </li>
    </ul>

    <ul class="exposed-tools-list">
        <li class="tools-item tool-toggle-show flex-center">
            <i class="fas fa-cog fa-spin"></i>
        </li>
        
    </ul>
</div>

    </div>

    <div class="zoom-in-image-mask">
    <img class="zoom-in-image">
</div>


    

</main>




<script src="/js/utils.js"></script>

<script src="/js/main.js"></script>

<script src="/js/header-shrink.js"></script>

<script src="/js/back2top.js"></script>

<script src="/js/dark-light-toggle.js"></script>










<div class="post-scripts">
    
        
<script src="/js/post-helper.js"></script>

        
        
    
</div>



</body>
</html>
